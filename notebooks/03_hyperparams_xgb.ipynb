{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from backpack_predictor import prepare_data, target_encoding\n",
    "from backpack_predictor.features import target, baseline_features, feature_list, cat_cols\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from datetime import datetime\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import skew, chisquare, kruskal, ks_2samp, chi2_contingency\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "from sklearn.preprocessing import TargetEncoder\n",
    "\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "from optuna.integration import XGBoostPruningCallback, CatBoostPruningCallback\n",
    "import optuna\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "test_df = pd.read_csv(r'..//data//test.csv')\n",
    "train_df = pd.read_csv(r'..//data//train.csv')\n",
    "train_extra_df = pd.read_csv(r'..//data//training_extra.csv')\n",
    "train_df = pd.concat([train_df, train_extra_df], ignore_index=True)\n",
    "\n",
    "\n",
    "# Apply function to train and test datasets\n",
    "train_df = prepare_data(train_df, is_train=True)\n",
    "test_df = prepare_data(test_df, is_train=False)\n",
    "\n",
    "\n",
    "X = train_df.drop(target, axis=1)\n",
    "y = train_df[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_str = \"xgb_\"\n",
    "cols_to_transform = [\"weight_capacity\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "data_splits = []\n",
    "\n",
    "for train_index, val_index in kf.split(train_df):\n",
    "    train_fold = train_df.iloc[train_index]\n",
    "    val_fold = train_df.iloc[val_index]\n",
    "\n",
    "    te = TargetEncoder(target_type=\"continuous\", smooth=20)\n",
    "    train_te = te.fit_transform(train_fold[cols_to_transform], train_fold[target])\n",
    "    val_te = te.transform(val_fold[cols_to_transform])\n",
    "\n",
    "    dtrain = xgb.DMatrix(train_te, label=train_fold[target], enable_categorical=True)\n",
    "    dvalid = xgb.DMatrix(val_te, label=val_fold[target], enable_categorical=True)\n",
    "\n",
    "    data_splits.append((dtrain, dvalid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-11 15:08:29,847] A new study created in RDB with name: xgb_2025-02-11_15-08\n",
      "[I 2025-02-11 15:14:06,818] Trial 0 finished with value: 38.73365097045898 and parameters: {'colsample_bylevel': 0.5678503325094608, 'colsample_bytree': 0.8251379275713693, 'learning_rate': 0.006185577585793067, 'max_depth': 5, 'min_child_weight': 31, 'gamma': 0.9171064429665166, 'subsample': 0.8169908452321606, 'reg_alpha': 0.9859042075630137, 'reg_lambda': 0.01126475787970589}. Best is trial 0 with value: 38.73365097045898.\n",
      "[I 2025-02-11 15:17:25,210] Trial 1 finished with value: 38.71481628417969 and parameters: {'colsample_bylevel': 0.5719372648437332, 'colsample_bytree': 0.6559887976189518, 'learning_rate': 0.06598159175089427, 'max_depth': 9, 'min_child_weight': 27, 'gamma': 0.4184783867346572, 'subsample': 0.2720422373166196, 'reg_alpha': 0.0016624184725545466, 'reg_lambda': 9.492872733630189e-05}. Best is trial 1 with value: 38.71481628417969.\n",
      "[I 2025-02-11 15:23:47,121] Trial 2 finished with value: 38.71858940124512 and parameters: {'colsample_bylevel': 0.8153063311837714, 'colsample_bytree': 0.6146319708642376, 'learning_rate': 0.010247973836111863, 'max_depth': 9, 'min_child_weight': 30, 'gamma': 0.33739151984785853, 'subsample': 0.9766059650933379, 'reg_alpha': 0.009257146156865573, 'reg_lambda': 7.593076516901548e-05}. Best is trial 1 with value: 38.71481628417969.\n",
      "[I 2025-02-11 15:25:20,294] Trial 3 finished with value: 38.714783096313475 and parameters: {'colsample_bylevel': 0.35358679440816393, 'colsample_bytree': 0.9660654074092471, 'learning_rate': 0.1579891062762685, 'max_depth': 9, 'min_child_weight': 38, 'gamma': 0.7821952449792383, 'subsample': 0.6511476245597627, 'reg_alpha': 0.008952986625964532, 'reg_lambda': 0.00020050785003752854}. Best is trial 3 with value: 38.714783096313475.\n",
      "[I 2025-02-11 15:31:44,781] Trial 4 finished with value: 38.790856170654294 and parameters: {'colsample_bylevel': 0.761564114260842, 'colsample_bytree': 0.9215774470733115, 'learning_rate': 0.0027135897511635977, 'max_depth': 14, 'min_child_weight': 10, 'gamma': 0.3809967197542691, 'subsample': 0.9546126065265323, 'reg_alpha': 0.005578924803387361, 'reg_lambda': 0.0001479299598019543}. Best is trial 3 with value: 38.714783096313475.\n",
      "[I 2025-02-11 15:38:20,233] Trial 5 finished with value: 38.71518669128418 and parameters: {'colsample_bylevel': 0.829539310643183, 'colsample_bytree': 0.5282494659017224, 'learning_rate': 0.01593058493790503, 'max_depth': 9, 'min_child_weight': 34, 'gamma': 0.455969708026728, 'subsample': 0.6967531632124178, 'reg_alpha': 0.02710388873182031, 'reg_lambda': 0.0008197196722416011}. Best is trial 3 with value: 38.714783096313475.\n"
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "    params = {\n",
    "        \"objective\": \"reg:squarederror\",\n",
    "        \"eval_metric\": \"rmse\",\n",
    "        \"seed\": 42,\n",
    "        \"verbosity\": 0,\n",
    "        'device': \"cuda\",\n",
    "\n",
    "        # \"grow_policy\", trial.suggest_categorical(\"grow_policy\", [\"depthwise\", \"lossguide\"]),\n",
    "        \n",
    "        \"colsample_bylevel\": trial.suggest_float(\"colsample_bylevel\", 0.3, 1.0),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.5, 1.0),\n",
    "\n",
    "        \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.25),\n",
    "\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 14),\n",
    "        \n",
    "        \"min_child_weight\": trial.suggest_int(\"min_child_weight\", 1, 50),\n",
    "\n",
    "        \"gamma\": trial.suggest_float(\"gamma\", 0.1, 1),\n",
    "\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.2, 1.0),\n",
    "\n",
    "        \"reg_alpha\": trial.suggest_loguniform(\"reg_alpha\", 1e-6, 2.0),\n",
    "        \"reg_lambda\": trial.suggest_loguniform(\"reg_lambda\", 1e-6, 1),\n",
    "        \n",
    "    }\n",
    "    rmse_list = []\n",
    "    num_boost_round_list = []\n",
    "    for i, (dtrain_fold, dvalid_fold) in enumerate(data_splits, 1):\n",
    "    \n",
    "        bst = xgb.train(\n",
    "            params=params,\n",
    "            dtrain=dtrain_fold,\n",
    "            num_boost_round=200,\n",
    "            evals=[(dtrain_fold, \"train\"), (dvalid_fold, \"validation_0\")],\n",
    "            early_stopping_rounds=20,\n",
    "            verbose_eval=False,\n",
    "            callbacks=[XGBoostPruningCallback(trial, observation_key=\"validation_0-rmse\") ]\n",
    "        )\n",
    "        y_pred = bst.predict(dvalid_fold)\n",
    "        rmse = root_mean_squared_error(dvalid_fold.get_label(), y_pred)\n",
    "        rmse_list.append(rmse)\n",
    "        num_boost_round_list.append(bst.best_iteration)\n",
    "\n",
    "    params[\"num_boost_round\"] = int(np.mean(num_boost_round_list)) \n",
    "\n",
    "    return np.mean(rmse_list)\n",
    "\n",
    "\n",
    "study = optuna.create_study(\n",
    "        storage=f\"sqlite:///..//optuna//{model_str}db.sqlite3\",\n",
    "        study_name=model_str + datetime.now().strftime(\"%Y-%m-%d_%H-%M\"),\n",
    "        direction=\"minimize\"\n",
    ")\n",
    "study.optimize(objective, n_trials=500)\n",
    "\n",
    "print(\"\\n=========================\")\n",
    "print(\"Number of finished trials:\", len(study.trials))\n",
    "print(\"Best trial:\", study.best_trial.number)\n",
    "print(\"Best value (RMSE):\", study.best_trial.value)\n",
    "print(\"Best hyperparameters:\", study.best_trial.params)\n",
    "best_params = study.best_trial.params\n",
    "best_params[\"random_state\"] = 42\n",
    "best_params[\"verbose\"] = 0\n",
    "best_params[\"eval_metric\"] = \"rmse\"\n",
    "best_params[\"device\"] = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kf = KFold(n_splits=3, shuffle=True, random_state=42)\n",
    "# data_splits = []\n",
    "# for fold, (train_index, test_index) in enumerate(kf.split(X), 1):\n",
    "\n",
    "#     X_train, X_val = X.iloc[train_index], X.iloc[test_index]\n",
    "#     y_train, y_val = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "#     X_train, X_val = preprocess_weight_capacity(pd.concat([X_train, y_train], axis=1), X_val)\n",
    "\n",
    "#     X_train, X_val, encoded_cols = target_encoding(\n",
    "#         train_df=X_train,\n",
    "#         cat_cols=cat_cols,\n",
    "#         test_df=X_val, \n",
    "#         target=y_train.name,\n",
    "#     )\n",
    "#     X_train = X_train.drop(columns=[target])\n",
    "\n",
    "#     dtrain = xgb.DMatrix(X_train[feature_list], label=y_train, enable_categorical=True)\n",
    "#     dvalid = xgb.DMatrix(X_val[feature_list], label=y_val, enable_categorical=True)\n",
    "\n",
    "#     data_splits.append((dtrain, dvalid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-10 17:58:11,484] A new study created in RDB with name: xgb_2025-02-10_17-58\n",
      "[I 2025-02-10 18:02:22,262] Trial 0 finished with value: 38.88390858968099 and parameters: {'colsample_bylevel': 0.3770332132909111, 'colsample_bytree': 0.925433219160883, 'learning_rate': 0.006731247661034507, 'max_depth': 9, 'min_child_weight': 19, 'gamma': 0.14754639167939806, 'subsample': 0.39588112881150334, 'reg_alpha': 0.00398721715837438, 'reg_lambda': 0.0005241777153905113}. Best is trial 0 with value: 38.88390858968099.\n",
      "[I 2025-02-10 18:04:29,463] Trial 1 finished with value: 38.903541564941406 and parameters: {'colsample_bylevel': 0.3809149221328341, 'colsample_bytree': 0.556560301372043, 'learning_rate': 0.006618639501270042, 'max_depth': 3, 'min_child_weight': 15, 'gamma': 0.9534603316030553, 'subsample': 0.9745157741091026, 'reg_alpha': 0.0011527170737815685, 'reg_lambda': 0.0023682137096427166}. Best is trial 0 with value: 38.88390858968099.\n",
      "[I 2025-02-10 18:06:40,552] Trial 2 finished with value: 38.90007400512695 and parameters: {'colsample_bylevel': 0.8741799501900687, 'colsample_bytree': 0.5775608086332924, 'learning_rate': 0.005425380197348054, 'max_depth': 4, 'min_child_weight': 43, 'gamma': 0.9170731477715461, 'subsample': 0.6201408132714891, 'reg_alpha': 6.926417146800101e-06, 'reg_lambda': 0.013484323240500445}. Best is trial 0 with value: 38.88390858968099.\n",
      "[I 2025-02-10 18:08:13,210] Trial 3 finished with value: 38.8786366780599 and parameters: {'colsample_bylevel': 0.9802449195503289, 'colsample_bytree': 0.8526223638614605, 'learning_rate': 0.20321367567712545, 'max_depth': 3, 'min_child_weight': 40, 'gamma': 0.6385732133958736, 'subsample': 0.8480497903139357, 'reg_alpha': 0.0036331961049255886, 'reg_lambda': 0.004308104293186403}. Best is trial 3 with value: 38.8786366780599.\n",
      "[I 2025-02-10 18:11:36,684] Trial 4 finished with value: 38.89776738484701 and parameters: {'colsample_bylevel': 0.9512266644382452, 'colsample_bytree': 0.9015526856748151, 'learning_rate': 0.0031780361782573273, 'max_depth': 8, 'min_child_weight': 49, 'gamma': 0.7034538785687513, 'subsample': 0.7872789190524823, 'reg_alpha': 0.0012475372041598906, 'reg_lambda': 0.04529518977029478}. Best is trial 3 with value: 38.8786366780599.\n",
      "[I 2025-02-10 18:16:08,721] Trial 5 finished with value: 38.88780212402344 and parameters: {'colsample_bylevel': 0.8485188651229576, 'colsample_bytree': 0.5573592552198886, 'learning_rate': 0.004912100385300727, 'max_depth': 11, 'min_child_weight': 43, 'gamma': 0.8067399040817201, 'subsample': 0.7611333353801732, 'reg_alpha': 0.5462826855630668, 'reg_lambda': 2.3038522162043017e-05}. Best is trial 3 with value: 38.8786366780599.\n",
      "[I 2025-02-10 18:17:59,547] Trial 6 finished with value: 38.892415364583336 and parameters: {'colsample_bylevel': 0.3418340692111206, 'colsample_bytree': 0.5105936325602096, 'learning_rate': 0.04085471986765031, 'max_depth': 14, 'min_child_weight': 4, 'gamma': 0.4466703383808943, 'subsample': 0.7267251962507686, 'reg_alpha': 7.28412752412489e-06, 'reg_lambda': 0.001680172293495669}. Best is trial 3 with value: 38.8786366780599.\n",
      "[I 2025-02-10 18:18:28,948] Trial 7 finished with value: 38.9003537495931 and parameters: {'colsample_bylevel': 0.9311132069211523, 'colsample_bytree': 0.7672165290237412, 'learning_rate': 0.16252875963603816, 'max_depth': 8, 'min_child_weight': 36, 'gamma': 0.315937234430523, 'subsample': 0.202488214732682, 'reg_alpha': 0.00028677097527446356, 'reg_lambda': 0.025442028948660995}. Best is trial 3 with value: 38.8786366780599.\n",
      "[I 2025-02-10 18:20:35,158] Trial 8 finished with value: 38.88752365112305 and parameters: {'colsample_bylevel': 0.7446580509420442, 'colsample_bytree': 0.5440625620104391, 'learning_rate': 0.013373744879912703, 'max_depth': 4, 'min_child_weight': 19, 'gamma': 0.5128401277853348, 'subsample': 0.7153342911788143, 'reg_alpha': 8.637478500711809e-06, 'reg_lambda': 0.004029026080971814}. Best is trial 3 with value: 38.8786366780599.\n",
      "[I 2025-02-10 18:20:35,490] Trial 9 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:21:09,721] Trial 10 finished with value: 38.88260142008463 and parameters: {'colsample_bylevel': 0.5629382166476666, 'colsample_bytree': 0.7902308155152201, 'learning_rate': 0.1861148892314834, 'max_depth': 6, 'min_child_weight': 31, 'gamma': 0.6531080822167155, 'subsample': 0.44678049730496167, 'reg_alpha': 0.19030032986892859, 'reg_lambda': 1.6022890957538047e-06}. Best is trial 3 with value: 38.8786366780599.\n",
      "[I 2025-02-10 18:21:39,667] Trial 11 finished with value: 38.884813944498696 and parameters: {'colsample_bylevel': 0.5546023010531126, 'colsample_bytree': 0.7895158663462603, 'learning_rate': 0.20966956554022825, 'max_depth': 6, 'min_child_weight': 31, 'gamma': 0.6736223556038613, 'subsample': 0.4143709213552541, 'reg_alpha': 0.3347061703175307, 'reg_lambda': 1.7624131483330033e-06}. Best is trial 3 with value: 38.8786366780599.\n",
      "[I 2025-02-10 18:23:28,058] Trial 12 finished with value: 38.87702306111654 and parameters: {'colsample_bylevel': 0.549503699907588, 'colsample_bytree': 0.8396707177252272, 'learning_rate': 0.06732014240507404, 'max_depth': 6, 'min_child_weight': 35, 'gamma': 0.6597968232742509, 'subsample': 0.44771113574304455, 'reg_alpha': 0.050140997193512823, 'reg_lambda': 8.980459592673471e-05}. Best is trial 12 with value: 38.87702306111654.\n",
      "[I 2025-02-10 18:25:21,630] Trial 13 finished with value: 38.880568186442055 and parameters: {'colsample_bylevel': 0.5185884904961098, 'colsample_bytree': 0.9880527013226863, 'learning_rate': 0.06022247123849205, 'max_depth': 3, 'min_child_weight': 40, 'gamma': 0.4048927156754434, 'subsample': 0.5325133153597305, 'reg_alpha': 0.04614422525833731, 'reg_lambda': 0.00010560833378804033}. Best is trial 12 with value: 38.87702306111654.\n",
      "[I 2025-02-10 18:27:06,202] Trial 14 finished with value: 38.875240325927734 and parameters: {'colsample_bylevel': 0.7042399860352442, 'colsample_bytree': 0.6700664404290344, 'learning_rate': 0.06431217687710553, 'max_depth': 6, 'min_child_weight': 48, 'gamma': 0.8026187053731907, 'subsample': 0.8883384798896046, 'reg_alpha': 0.00020737803353933882, 'reg_lambda': 0.00012965526480433523}. Best is trial 14 with value: 38.875240325927734.\n",
      "[I 2025-02-10 18:28:36,258] Trial 15 finished with value: 38.88131968180338 and parameters: {'colsample_bylevel': 0.6548787318654585, 'colsample_bytree': 0.6794900973077056, 'learning_rate': 0.054712454101602845, 'max_depth': 7, 'min_child_weight': 50, 'gamma': 0.8201817839589289, 'subsample': 0.23652562011115097, 'reg_alpha': 0.00010964580046773348, 'reg_lambda': 4.6657131036453346e-05}. Best is trial 14 with value: 38.875240325927734.\n",
      "[I 2025-02-10 18:28:36,745] Trial 16 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:29:40,080] Trial 17 finished with value: 38.894273122151695 and parameters: {'colsample_bylevel': 0.6821138394558665, 'colsample_bytree': 0.6957646430062508, 'learning_rate': 0.07992375451916871, 'max_depth': 11, 'min_child_weight': 35, 'gamma': 0.5708628975962123, 'subsample': 0.3377300281981557, 'reg_alpha': 5.046342702607564e-05, 'reg_lambda': 0.0002440004798956703}. Best is trial 14 with value: 38.875240325927734.\n",
      "[I 2025-02-10 18:29:40,556] Trial 18 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:29:56,173] Trial 19 pruned. Trial was pruned at iteration 31.\n",
      "[I 2025-02-10 18:29:56,634] Trial 20 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:31:29,522] Trial 21 finished with value: 38.87623596191406 and parameters: {'colsample_bylevel': 0.6112280879260711, 'colsample_bytree': 0.8631407260746833, 'learning_rate': 0.11436796271001884, 'max_depth': 5, 'min_child_weight': 39, 'gamma': 0.6327011364852214, 'subsample': 0.9012320152209666, 'reg_alpha': 0.004308419915179258, 'reg_lambda': 0.7448971863233596}. Best is trial 14 with value: 38.875240325927734.\n",
      "[I 2025-02-10 18:33:25,057] Trial 22 finished with value: 38.87683614095052 and parameters: {'colsample_bylevel': 0.626480145590133, 'colsample_bytree': 0.8785677022881054, 'learning_rate': 0.08214950939367462, 'max_depth': 5, 'min_child_weight': 36, 'gamma': 0.7419969115684896, 'subsample': 0.6351963835617307, 'reg_alpha': 0.009373103938348766, 'reg_lambda': 0.42558524444899876}. Best is trial 14 with value: 38.875240325927734.\n",
      "[I 2025-02-10 18:34:54,565] Trial 23 finished with value: 38.876729329427086 and parameters: {'colsample_bylevel': 0.6321692821804203, 'colsample_bytree': 0.9062026577637177, 'learning_rate': 0.11522830270418852, 'max_depth': 5, 'min_child_weight': 45, 'gamma': 0.8503802260415944, 'subsample': 0.8675849462737432, 'reg_alpha': 0.006202551870161175, 'reg_lambda': 0.5003696054957053}. Best is trial 14 with value: 38.875240325927734.\n",
      "[I 2025-02-10 18:36:24,985] Trial 24 finished with value: 38.87667973836263 and parameters: {'colsample_bylevel': 0.6976369536500313, 'colsample_bytree': 0.9626200927059221, 'learning_rate': 0.12250305144572808, 'max_depth': 5, 'min_child_weight': 45, 'gamma': 0.9988095638058265, 'subsample': 0.9076516567938403, 'reg_alpha': 0.000640164468209393, 'reg_lambda': 0.9389507842836512}. Best is trial 14 with value: 38.875240325927734.\n",
      "[I 2025-02-10 18:36:25,413] Trial 25 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:37:30,888] Trial 26 finished with value: 38.87633260091146 and parameters: {'colsample_bylevel': 0.8092844661429216, 'colsample_bytree': 0.9468034615686934, 'learning_rate': 0.11317758040253122, 'max_depth': 7, 'min_child_weight': 47, 'gamma': 0.9197232402296287, 'subsample': 0.99409369386718, 'reg_alpha': 4.5264161035793525e-05, 'reg_lambda': 0.09491762415335585}. Best is trial 14 with value: 38.875240325927734.\n",
      "[I 2025-02-10 18:37:31,396] Trial 27 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:37:32,032] Trial 28 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:37:32,531] Trial 29 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:38:35,932] Trial 30 finished with value: 38.876879374186196 and parameters: {'colsample_bylevel': 0.8303344490432629, 'colsample_bytree': 0.9154318173044096, 'learning_rate': 0.09911062702207443, 'max_depth': 7, 'min_child_weight': 46, 'gamma': 0.497903184991941, 'subsample': 0.7107852445018992, 'reg_alpha': 0.0036360576897444485, 'reg_lambda': 0.06526473353482323}. Best is trial 14 with value: 38.875240325927734.\n",
      "[I 2025-02-10 18:40:01,131] Trial 31 finished with value: 38.876172383626304 and parameters: {'colsample_bylevel': 0.698509595136423, 'colsample_bytree': 0.9547018573302234, 'learning_rate': 0.1352632798974653, 'max_depth': 5, 'min_child_weight': 45, 'gamma': 0.9985904865105076, 'subsample': 0.916650204608035, 'reg_alpha': 0.0006295097369325971, 'reg_lambda': 0.8814179359165232}. Best is trial 14 with value: 38.875240325927734.\n",
      "[I 2025-02-10 18:40:49,541] Trial 32 finished with value: 38.87856801350912 and parameters: {'colsample_bylevel': 0.7506711677078229, 'colsample_bytree': 0.9392644457007447, 'learning_rate': 0.24763972791671554, 'max_depth': 4, 'min_child_weight': 47, 'gamma': 0.8927908951939396, 'subsample': 0.9972332441550079, 'reg_alpha': 0.0023060084681618847, 'reg_lambda': 0.33712227093118374}. Best is trial 14 with value: 38.875240325927734.\n",
      "[I 2025-02-10 18:41:47,209] Trial 33 finished with value: 38.87731170654297 and parameters: {'colsample_bylevel': 0.6723709340640314, 'colsample_bytree': 0.8812686172662859, 'learning_rate': 0.15507046242543507, 'max_depth': 6, 'min_child_weight': 43, 'gamma': 0.946308763988011, 'subsample': 0.9312429343841702, 'reg_alpha': 0.0005628211933099656, 'reg_lambda': 0.017812879888762085}. Best is trial 14 with value: 38.875240325927734.\n",
      "[I 2025-02-10 18:42:33,013] Trial 34 finished with value: 38.88186264038086 and parameters: {'colsample_bylevel': 0.6012923365333412, 'colsample_bytree': 0.9967529262488846, 'learning_rate': 0.1421226264388174, 'max_depth': 9, 'min_child_weight': 38, 'gamma': 0.8647198573548743, 'subsample': 0.8313777959043817, 'reg_alpha': 0.00015338431125515, 'reg_lambda': 0.08515843623755984}. Best is trial 14 with value: 38.875240325927734.\n",
      "[I 2025-02-10 18:42:33,351] Trial 35 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:42:33,752] Trial 36 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:42:34,634] Trial 37 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:42:35,162] Trial 38 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:42:35,977] Trial 39 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:42:47,454] Trial 40 pruned. Trial was pruned at iteration 54.\n",
      "[I 2025-02-10 18:44:15,173] Trial 41 finished with value: 38.87660217285156 and parameters: {'colsample_bylevel': 0.7118672029740427, 'colsample_bytree': 0.9664440870292835, 'learning_rate': 0.11552949182528462, 'max_depth': 5, 'min_child_weight': 45, 'gamma': 0.9816505844858135, 'subsample': 0.8962648816400507, 'reg_alpha': 0.0008678842106705642, 'reg_lambda': 0.8512456077269545}. Best is trial 14 with value: 38.875240325927734.\n",
      "[I 2025-02-10 18:44:57,533] Trial 42 finished with value: 38.87931823730469 and parameters: {'colsample_bylevel': 0.6872927359445878, 'colsample_bytree': 0.9741585511437603, 'learning_rate': 0.24709297957557005, 'max_depth': 5, 'min_child_weight': 38, 'gamma': 0.9034602692295592, 'subsample': 0.877045650605322, 'reg_alpha': 0.0018605227527719547, 'reg_lambda': 0.17967505419616353}. Best is trial 14 with value: 38.875240325927734.\n",
      "[I 2025-02-10 18:44:58,023] Trial 43 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:45:43,163] Trial 44 finished with value: 38.87937672932943 and parameters: {'colsample_bylevel': 0.7102253228608454, 'colsample_bytree': 0.9275506526003618, 'learning_rate': 0.18434515139360458, 'max_depth': 6, 'min_child_weight': 47, 'gamma': 0.8476502462530355, 'subsample': 0.7541304474899341, 'reg_alpha': 0.0002097986804156966, 'reg_lambda': 0.05961653723651791}. Best is trial 14 with value: 38.875240325927734.\n",
      "[I 2025-02-10 18:45:43,532] Trial 45 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:45:43,874] Trial 46 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:45:44,312] Trial 47 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:46:51,911] Trial 48 finished with value: 38.87763341267904 and parameters: {'colsample_bylevel': 0.731486419407753, 'colsample_bytree': 0.6000951200733187, 'learning_rate': 0.19356426676856353, 'max_depth': 5, 'min_child_weight': 48, 'gamma': 0.7767567676972194, 'subsample': 0.9088043079618795, 'reg_alpha': 0.0033168387309361258, 'reg_lambda': 0.25364060765490265}. Best is trial 14 with value: 38.875240325927734.\n",
      "[I 2025-02-10 18:47:50,076] Trial 49 finished with value: 38.87820307413737 and parameters: {'colsample_bylevel': 0.514578003038089, 'colsample_bytree': 0.6956576562544132, 'learning_rate': 0.10840936689878834, 'max_depth': 8, 'min_child_weight': 37, 'gamma': 0.6880948968445455, 'subsample': 0.7872076486092466, 'reg_alpha': 0.0002618699705627549, 'reg_lambda': 0.9811719654957209}. Best is trial 14 with value: 38.875240325927734.\n",
      "[I 2025-02-10 18:47:50,510] Trial 50 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:48:55,309] Trial 51 finished with value: 38.877096811930336 and parameters: {'colsample_bylevel': 0.69735887065386, 'colsample_bytree': 0.9609412360171432, 'learning_rate': 0.1644966958648577, 'max_depth': 5, 'min_child_weight': 45, 'gamma': 0.9983037551700601, 'subsample': 0.8893288846238506, 'reg_alpha': 0.0006762715794706331, 'reg_lambda': 0.5152474951644945}. Best is trial 14 with value: 38.875240325927734.\n",
      "[I 2025-02-10 18:48:55,692] Trial 52 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:48:56,112] Trial 53 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:49:54,411] Trial 54 finished with value: 38.87617619832357 and parameters: {'colsample_bylevel': 0.750593185228948, 'colsample_bytree': 0.8030747784053958, 'learning_rate': 0.11907803312217398, 'max_depth': 6, 'min_child_weight': 46, 'gamma': 0.8304485159920368, 'subsample': 0.8943564621425234, 'reg_alpha': 0.0001642720611879684, 'reg_lambda': 0.04021047869794546}. Best is trial 14 with value: 38.875240325927734.\n",
      "[I 2025-02-10 18:49:54,852] Trial 55 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:50:34,302] Trial 56 finished with value: 38.8783073425293 and parameters: {'colsample_bylevel': 0.7538319995737757, 'colsample_bytree': 0.8090192690960127, 'learning_rate': 0.1903141848866079, 'max_depth': 6, 'min_child_weight': 47, 'gamma': 0.7884636116265001, 'subsample': 0.8479107146981616, 'reg_alpha': 0.016382884043207476, 'reg_lambda': 0.014372220830926428}. Best is trial 14 with value: 38.875240325927734.\n",
      "[I 2025-02-10 18:50:34,732] Trial 57 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:50:35,161] Trial 58 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:50:35,565] Trial 59 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:50:36,000] Trial 60 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:50:36,377] Trial 61 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:50:36,742] Trial 62 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:50:37,126] Trial 63 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:51:16,270] Trial 64 finished with value: 38.8787841796875 and parameters: {'colsample_bylevel': 0.743727180912227, 'colsample_bytree': 0.775229743085807, 'learning_rate': 0.2185343621841188, 'max_depth': 5, 'min_child_weight': 48, 'gamma': 0.872866491382889, 'subsample': 0.9113411260286367, 'reg_alpha': 0.00021015163694894216, 'reg_lambda': 0.6416786291881433}. Best is trial 14 with value: 38.875240325927734.\n",
      "[I 2025-02-10 18:51:16,629] Trial 65 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:52:05,776] Trial 66 finished with value: 38.87776565551758 and parameters: {'colsample_bylevel': 0.7703436075796719, 'colsample_bytree': 0.8599752350515624, 'learning_rate': 0.1625482987767962, 'max_depth': 6, 'min_child_weight': 39, 'gamma': 0.9774448409328628, 'subsample': 0.9408926635566036, 'reg_alpha': 0.0001602973743504724, 'reg_lambda': 0.15734219187601606}. Best is trial 14 with value: 38.875240325927734.\n",
      "[I 2025-02-10 18:52:06,158] Trial 67 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:52:06,492] Trial 68 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:52:06,890] Trial 69 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:52:16,747] Trial 70 pruned. Trial was pruned at iteration 35.\n",
      "[I 2025-02-10 18:52:17,136] Trial 71 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:52:22,601] Trial 72 pruned. Trial was pruned at iteration 25.\n",
      "[I 2025-02-10 18:52:22,991] Trial 73 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:53:09,493] Trial 74 finished with value: 38.87767664591471 and parameters: {'colsample_bylevel': 0.5745558407373661, 'colsample_bytree': 0.8718147213225917, 'learning_rate': 0.17741810306452852, 'max_depth': 6, 'min_child_weight': 50, 'gamma': 0.8211639576981835, 'subsample': 0.9569114343792078, 'reg_alpha': 0.0007746062571680483, 'reg_lambda': 0.09517545793909027}. Best is trial 14 with value: 38.875240325927734.\n",
      "[I 2025-02-10 18:54:06,824] Trial 75 finished with value: 38.87651697794596 and parameters: {'colsample_bylevel': 0.5385905387008048, 'colsample_bytree': 0.9509599835985558, 'learning_rate': 0.109669306594208, 'max_depth': 7, 'min_child_weight': 43, 'gamma': 0.72937268901728, 'subsample': 0.9815609555173787, 'reg_alpha': 0.01035475004363024, 'reg_lambda': 0.455573770147416}. Best is trial 14 with value: 38.875240325927734.\n",
      "[I 2025-02-10 18:54:58,825] Trial 76 finished with value: 38.87729008992513 and parameters: {'colsample_bylevel': 0.5349429329696676, 'colsample_bytree': 0.9558288459459585, 'learning_rate': 0.14249561042744383, 'max_depth': 7, 'min_child_weight': 43, 'gamma': 0.7113505855699622, 'subsample': 0.9776412930896424, 'reg_alpha': 0.04926329187261792, 'reg_lambda': 0.27184449361677704}. Best is trial 14 with value: 38.875240325927734.\n",
      "[I 2025-02-10 18:54:59,263] Trial 77 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:54:59,771] Trial 78 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:55:00,264] Trial 79 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:55:00,687] Trial 80 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:55:01,084] Trial 81 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:55:08,775] Trial 82 pruned. Trial was pruned at iteration 32.\n",
      "[I 2025-02-10 18:55:09,335] Trial 83 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:55:09,701] Trial 84 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:55:10,140] Trial 85 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:55:10,523] Trial 86 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:55:10,883] Trial 87 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:55:11,304] Trial 88 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:55:11,685] Trial 89 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:55:36,859] Trial 90 pruned. Trial was pruned at iteration 57.\n",
      "[I 2025-02-10 18:55:37,242] Trial 91 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:55:37,609] Trial 92 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:56:23,178] Trial 93 finished with value: 38.877296447753906 and parameters: {'colsample_bylevel': 0.6461461527331311, 'colsample_bytree': 0.8633825578537949, 'learning_rate': 0.12395078460129559, 'max_depth': 7, 'min_child_weight': 18, 'gamma': 0.7013256906724634, 'subsample': 0.8716467388689768, 'reg_alpha': 0.002263327829639346, 'reg_lambda': 0.454604040369717}. Best is trial 14 with value: 38.875240325927734.\n",
      "[I 2025-02-10 18:56:23,526] Trial 94 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:56:29,323] Trial 95 pruned. Trial was pruned at iteration 22.\n",
      "[I 2025-02-10 18:56:32,306] Trial 96 pruned. Trial was pruned at iteration 11.\n",
      "[I 2025-02-10 18:56:32,701] Trial 97 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:56:33,112] Trial 98 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:56:33,541] Trial 99 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:56:33,884] Trial 100 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:56:34,320] Trial 101 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:56:34,808] Trial 102 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:56:43,202] Trial 103 pruned. Trial was pruned at iteration 35.\n",
      "[I 2025-02-10 18:56:43,580] Trial 104 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:56:44,082] Trial 105 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:56:44,511] Trial 106 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:56:44,918] Trial 107 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:56:45,538] Trial 108 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:56:46,506] Trial 109 pruned. Trial was pruned at iteration 3.\n",
      "[I 2025-02-10 18:56:46,897] Trial 110 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:56:47,341] Trial 111 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:56:47,782] Trial 112 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:56:48,184] Trial 113 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:56:49,270] Trial 114 pruned. Trial was pruned at iteration 3.\n",
      "[I 2025-02-10 18:56:49,664] Trial 115 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:56:50,082] Trial 116 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:56:50,478] Trial 117 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:56:50,920] Trial 118 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:56:51,341] Trial 119 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:56:53,746] Trial 120 pruned. Trial was pruned at iteration 9.\n",
      "[I 2025-02-10 18:56:54,328] Trial 121 pruned. Trial was pruned at iteration 1.\n",
      "[I 2025-02-10 18:56:54,699] Trial 122 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:57:43,205] Trial 123 finished with value: 38.87797927856445 and parameters: {'colsample_bylevel': 0.6969410849914436, 'colsample_bytree': 0.9269825489355829, 'learning_rate': 0.19556048666245818, 'max_depth': 5, 'min_child_weight': 44, 'gamma': 0.9901211251485865, 'subsample': 0.9057298089526933, 'reg_alpha': 0.0008202236704928657, 'reg_lambda': 0.34113246377131373}. Best is trial 14 with value: 38.875240325927734.\n",
      "[I 2025-02-10 18:58:45,436] Trial 124 finished with value: 38.87660217285156 and parameters: {'colsample_bylevel': 0.7307351405980169, 'colsample_bytree': 0.9522217693880144, 'learning_rate': 0.12385799427687333, 'max_depth': 6, 'min_child_weight': 43, 'gamma': 0.9960216362454428, 'subsample': 0.9459206613032634, 'reg_alpha': 0.0005208647799087561, 'reg_lambda': 0.793932739115909}. Best is trial 14 with value: 38.875240325927734.\n",
      "[I 2025-02-10 18:59:39,463] Trial 125 finished with value: 38.87700653076172 and parameters: {'colsample_bylevel': 0.7268176115824662, 'colsample_bytree': 0.9530624287465613, 'learning_rate': 0.12607261867534736, 'max_depth': 7, 'min_child_weight': 41, 'gamma': 0.9294519873641836, 'subsample': 0.9771380494823003, 'reg_alpha': 9.826682114460743e-05, 'reg_lambda': 0.7935984490083808}. Best is trial 14 with value: 38.875240325927734.\n",
      "[I 2025-02-10 19:00:23,900] Trial 126 finished with value: 38.878273010253906 and parameters: {'colsample_bylevel': 0.7362176410680742, 'colsample_bytree': 0.9411846225714979, 'learning_rate': 0.1267758491701228, 'max_depth': 8, 'min_child_weight': 41, 'gamma': 0.8920395517211824, 'subsample': 0.9653819275035063, 'reg_alpha': 5.1170227988334e-05, 'reg_lambda': 0.7271606451303182}. Best is trial 14 with value: 38.875240325927734.\n",
      "[I 2025-02-10 19:01:23,803] Trial 127 finished with value: 38.87663141886393 and parameters: {'colsample_bylevel': 0.7858050856551189, 'colsample_bytree': 0.9533388993665554, 'learning_rate': 0.11972058265822329, 'max_depth': 7, 'min_child_weight': 43, 'gamma': 0.9227410670516776, 'subsample': 0.9475709896279887, 'reg_alpha': 9.49634678620293e-05, 'reg_lambda': 0.8100954226169171}. Best is trial 14 with value: 38.875240325927734.\n",
      "[I 2025-02-10 19:01:56,273] Trial 128 finished with value: 38.881334940592446 and parameters: {'colsample_bylevel': 0.7884846886591877, 'colsample_bytree': 0.9707312724497829, 'learning_rate': 0.234445826410976, 'max_depth': 7, 'min_child_weight': 43, 'gamma': 0.9177088120409174, 'subsample': 0.9435255557286384, 'reg_alpha': 0.00022365598306475106, 'reg_lambda': 0.001107437283903556}. Best is trial 14 with value: 38.875240325927734.\n",
      "[I 2025-02-10 19:02:51,186] Trial 129 finished with value: 38.87675348917643 and parameters: {'colsample_bylevel': 0.7566488247566825, 'colsample_bytree': 0.926197924160267, 'learning_rate': 0.1405227912824331, 'max_depth': 6, 'min_child_weight': 43, 'gamma': 0.9625750538640523, 'subsample': 0.9178165200050872, 'reg_alpha': 7.31250114888499e-05, 'reg_lambda': 0.9479063044910344}. Best is trial 14 with value: 38.875240325927734.\n",
      "[I 2025-02-10 19:03:47,508] Trial 130 finished with value: 38.8774528503418 and parameters: {'colsample_bylevel': 0.7596629891175064, 'colsample_bytree': 0.9351010202350624, 'learning_rate': 0.1535547390080603, 'max_depth': 6, 'min_child_weight': 43, 'gamma': 0.9632951815852103, 'subsample': 0.9187576366259314, 'reg_alpha': 8.115435131380673e-05, 'reg_lambda': 0.5275736248049895}. Best is trial 14 with value: 38.875240325927734.\n",
      "[I 2025-02-10 19:03:47,927] Trial 131 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:04:47,270] Trial 132 finished with value: 38.87677892049154 and parameters: {'colsample_bylevel': 0.9995138962437675, 'colsample_bytree': 0.927022955985187, 'learning_rate': 0.1393235030708271, 'max_depth': 6, 'min_child_weight': 40, 'gamma': 0.8362309944121709, 'subsample': 0.9326119666757849, 'reg_alpha': 3.978161324590393e-05, 'reg_lambda': 0.9724294907547408}. Best is trial 14 with value: 38.875240325927734.\n",
      "[I 2025-02-10 19:05:51,830] Trial 133 finished with value: 38.875691731770836 and parameters: {'colsample_bylevel': 0.7095816102383666, 'colsample_bytree': 0.9489199562928184, 'learning_rate': 0.14022393294425378, 'max_depth': 6, 'min_child_weight': 42, 'gamma': 0.8237953155856425, 'subsample': 0.9301598008066451, 'reg_alpha': 6.684264164337908e-05, 'reg_lambda': 0.9502082888982551}. Best is trial 14 with value: 38.875240325927734.\n",
      "[I 2025-02-10 19:06:45,273] Trial 134 finished with value: 38.8765614827474 and parameters: {'colsample_bylevel': 0.9729523087597506, 'colsample_bytree': 0.9486736247546089, 'learning_rate': 0.14331111929927043, 'max_depth': 6, 'min_child_weight': 42, 'gamma': 0.836548410940662, 'subsample': 0.9367754802821011, 'reg_alpha': 6.451361840807901e-05, 'reg_lambda': 0.6316549292300437}. Best is trial 14 with value: 38.875240325927734.\n",
      "[I 2025-02-10 19:06:57,657] Trial 135 pruned. Trial was pruned at iteration 48.\n",
      "[I 2025-02-10 19:06:58,117] Trial 136 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:07:22,728] Trial 137 pruned. Trial was pruned at iteration 44.\n",
      "[I 2025-02-10 19:08:22,766] Trial 138 finished with value: 38.87746047973633 and parameters: {'colsample_bylevel': 0.9568206372555689, 'colsample_bytree': 0.9441132691154438, 'learning_rate': 0.1674940600402253, 'max_depth': 6, 'min_child_weight': 44, 'gamma': 0.8557665981052565, 'subsample': 0.9340574122128886, 'reg_alpha': 2.133795835296077e-05, 'reg_lambda': 0.558278249315217}. Best is trial 14 with value: 38.875240325927734.\n",
      "[I 2025-02-10 19:09:16,422] Trial 139 finished with value: 38.8769162495931 and parameters: {'colsample_bylevel': 0.6838497327060994, 'colsample_bytree': 0.958898861945692, 'learning_rate': 0.14158878409480233, 'max_depth': 6, 'min_child_weight': 47, 'gamma': 0.997186042576704, 'subsample': 0.8995274054588213, 'reg_alpha': 3.623230524590952e-05, 'reg_lambda': 0.9843043078110078}. Best is trial 14 with value: 38.875240325927734.\n",
      "[I 2025-02-10 19:09:16,911] Trial 140 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:09:17,363] Trial 141 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:10:19,867] Trial 142 finished with value: 38.87758763631185 and parameters: {'colsample_bylevel': 0.9782720749293276, 'colsample_bytree': 0.9289988164847556, 'learning_rate': 0.14460533356646527, 'max_depth': 6, 'min_child_weight': 39, 'gamma': 0.8090847289494437, 'subsample': 0.882823840782945, 'reg_alpha': 4.427367735344202e-05, 'reg_lambda': 0.4305756822135376}. Best is trial 14 with value: 38.875240325927734.\n",
      "[I 2025-02-10 19:10:20,317] Trial 143 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:10:22,003] Trial 144 pruned. Trial was pruned at iteration 5.\n",
      "[I 2025-02-10 19:10:22,417] Trial 145 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:10:22,864] Trial 146 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:10:23,273] Trial 147 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:11:25,015] Trial 148 finished with value: 38.87701288859049 and parameters: {'colsample_bylevel': 0.666275664293524, 'colsample_bytree': 0.7207249714416408, 'learning_rate': 0.15130578522922564, 'max_depth': 6, 'min_child_weight': 41, 'gamma': 0.8911912673253884, 'subsample': 0.9219135789627564, 'reg_alpha': 4.417364738357485e-05, 'reg_lambda': 0.5784243619497969}. Best is trial 14 with value: 38.875240325927734.\n",
      "[I 2025-02-10 19:11:37,996] Trial 149 pruned. Trial was pruned at iteration 37.\n",
      "[I 2025-02-10 19:11:46,956] Trial 150 pruned. Trial was pruned at iteration 31.\n",
      "[I 2025-02-10 19:11:47,364] Trial 151 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:11:47,794] Trial 152 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:11:48,198] Trial 153 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:11:48,650] Trial 154 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:12:39,341] Trial 155 finished with value: 38.87736892700195 and parameters: {'colsample_bylevel': 0.6881684981972415, 'colsample_bytree': 0.9320372433120439, 'learning_rate': 0.13774597733289975, 'max_depth': 7, 'min_child_weight': 44, 'gamma': 0.8303387311015301, 'subsample': 0.8924470748076383, 'reg_alpha': 1.5827001992575116, 'reg_lambda': 0.19940497549699426}. Best is trial 14 with value: 38.875240325927734.\n",
      "[I 2025-02-10 19:12:39,766] Trial 156 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:12:40,219] Trial 157 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:13:34,944] Trial 158 finished with value: 38.87736256917318 and parameters: {'colsample_bylevel': 0.7137131703879314, 'colsample_bytree': 0.980809551660996, 'learning_rate': 0.16299097577618976, 'max_depth': 6, 'min_child_weight': 46, 'gamma': 0.7947451617124426, 'subsample': 0.9570036397523534, 'reg_alpha': 1.3383148579509218e-05, 'reg_lambda': 0.46591608833756026}. Best is trial 14 with value: 38.875240325927734.\n",
      "[I 2025-02-10 19:13:35,335] Trial 159 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:13:35,760] Trial 160 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:14:29,177] Trial 161 finished with value: 38.87756474812826 and parameters: {'colsample_bylevel': 0.8172949220879682, 'colsample_bytree': 0.8912009791947019, 'learning_rate': 0.1313386906413584, 'max_depth': 7, 'min_child_weight': 24, 'gamma': 0.4913167681476634, 'subsample': 0.9412842591192971, 'reg_alpha': 0.004659312269249757, 'reg_lambda': 0.13988187517773182}. Best is trial 14 with value: 38.875240325927734.\n",
      "[I 2025-02-10 19:14:29,718] Trial 162 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:14:41,522] Trial 163 pruned. Trial was pruned at iteration 40.\n",
      "[I 2025-02-10 19:14:42,015] Trial 164 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:14:42,478] Trial 165 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:14:42,895] Trial 166 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:14:49,654] Trial 167 pruned. Trial was pruned at iteration 15.\n",
      "[I 2025-02-10 19:15:35,748] Trial 168 finished with value: 38.878668467203774 and parameters: {'colsample_bylevel': 0.9808609680454271, 'colsample_bytree': 0.7009086704006761, 'learning_rate': 0.1712249632471396, 'max_depth': 7, 'min_child_weight': 46, 'gamma': 0.8385278679652194, 'subsample': 0.9130540563957749, 'reg_alpha': 0.00014186732517244737, 'reg_lambda': 0.015296794826131947}. Best is trial 14 with value: 38.875240325927734.\n",
      "[I 2025-02-10 19:15:36,167] Trial 169 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:15:36,563] Trial 170 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:15:37,232] Trial 171 pruned. Trial was pruned at iteration 1.\n",
      "[I 2025-02-10 19:15:37,659] Trial 172 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:16:29,862] Trial 173 finished with value: 38.877062479654946 and parameters: {'colsample_bylevel': 0.6465053865691851, 'colsample_bytree': 0.9474515025565609, 'learning_rate': 0.15319311186907336, 'max_depth': 6, 'min_child_weight': 47, 'gamma': 0.99810994353182, 'subsample': 0.9053887438494481, 'reg_alpha': 6.914747769008758e-05, 'reg_lambda': 0.5960923777178807}. Best is trial 14 with value: 38.875240325927734.\n",
      "[I 2025-02-10 19:16:30,278] Trial 174 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:16:30,696] Trial 175 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:16:38,554] Trial 176 pruned. Trial was pruned at iteration 30.\n",
      "[I 2025-02-10 19:16:38,942] Trial 177 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:16:39,433] Trial 178 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:16:39,843] Trial 179 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:16:40,210] Trial 180 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:16:40,658] Trial 181 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:17:24,151] Trial 182 finished with value: 38.87805684407552 and parameters: {'colsample_bylevel': 0.7689310952435502, 'colsample_bytree': 0.9590035736958745, 'learning_rate': 0.14958044563634423, 'max_depth': 7, 'min_child_weight': 40, 'gamma': 0.9424264137198184, 'subsample': 0.9848991743415085, 'reg_alpha': 8.396552964950581e-05, 'reg_lambda': 0.6405898728764746}. Best is trial 14 with value: 38.875240325927734.\n",
      "[I 2025-02-10 19:17:24,598] Trial 183 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:17:25,089] Trial 184 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:17:25,483] Trial 185 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:17:25,897] Trial 186 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:17:31,411] Trial 187 pruned. Trial was pruned at iteration 21.\n",
      "[I 2025-02-10 19:17:31,895] Trial 188 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:17:32,342] Trial 189 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:17:34,243] Trial 190 pruned. Trial was pruned at iteration 2.\n",
      "[I 2025-02-10 19:17:34,660] Trial 191 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:17:37,865] Trial 192 pruned. Trial was pruned at iteration 11.\n",
      "[I 2025-02-10 19:17:38,272] Trial 193 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:17:38,690] Trial 194 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:17:40,405] Trial 195 pruned. Trial was pruned at iteration 6.\n",
      "[I 2025-02-10 19:18:27,967] Trial 196 finished with value: 38.87769317626953 and parameters: {'colsample_bylevel': 0.6371646994026239, 'colsample_bytree': 0.7897616595812644, 'learning_rate': 0.14583320856147236, 'max_depth': 7, 'min_child_weight': 45, 'gamma': 0.9253976425980784, 'subsample': 0.8821018054112074, 'reg_alpha': 6.350089134649214e-05, 'reg_lambda': 0.3654325930368673}. Best is trial 14 with value: 38.875240325927734.\n",
      "[I 2025-02-10 19:18:28,498] Trial 197 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:18:28,894] Trial 198 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:18:29,320] Trial 199 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:18:29,738] Trial 200 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:18:30,151] Trial 201 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:18:30,570] Trial 202 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:18:31,004] Trial 203 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:18:31,438] Trial 204 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:18:31,860] Trial 205 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:18:32,265] Trial 206 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:18:32,687] Trial 207 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:18:33,138] Trial 208 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:18:33,545] Trial 209 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:18:33,941] Trial 210 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:18:35,128] Trial 211 pruned. Trial was pruned at iteration 3.\n",
      "[I 2025-02-10 19:18:40,384] Trial 212 pruned. Trial was pruned at iteration 21.\n",
      "[I 2025-02-10 19:18:40,796] Trial 213 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:18:43,532] Trial 214 pruned. Trial was pruned at iteration 9.\n",
      "[I 2025-02-10 19:18:43,924] Trial 215 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:18:44,369] Trial 216 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:18:44,796] Trial 217 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:18:45,207] Trial 218 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:18:47,803] Trial 219 pruned. Trial was pruned at iteration 10.\n",
      "[I 2025-02-10 19:18:48,273] Trial 220 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:18:48,662] Trial 221 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:18:49,990] Trial 222 pruned. Trial was pruned at iteration 4.\n",
      "[I 2025-02-10 19:18:50,379] Trial 223 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:18:55,701] Trial 224 pruned. Trial was pruned at iteration 21.\n",
      "[I 2025-02-10 19:18:56,104] Trial 225 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:19:39,225] Trial 226 finished with value: 38.87803522745768 and parameters: {'colsample_bylevel': 0.5341263486935524, 'colsample_bytree': 0.8559597590307841, 'learning_rate': 0.16905299859740383, 'max_depth': 7, 'min_child_weight': 44, 'gamma': 0.7509433472172604, 'subsample': 0.9249415339837005, 'reg_alpha': 4.056917801649035e-05, 'reg_lambda': 0.3434870447932169}. Best is trial 14 with value: 38.875240325927734.\n",
      "[I 2025-02-10 19:19:39,636] Trial 227 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:19:40,078] Trial 228 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:19:40,493] Trial 229 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:19:41,085] Trial 230 pruned. Trial was pruned at iteration 1.\n",
      "[I 2025-02-10 19:20:28,623] Trial 231 finished with value: 38.87737909952799 and parameters: {'colsample_bylevel': 0.563945681510469, 'colsample_bytree': 0.9578540392766209, 'learning_rate': 0.13846884981779828, 'max_depth': 7, 'min_child_weight': 43, 'gamma': 0.7423843639122657, 'subsample': 0.9782017277919475, 'reg_alpha': 0.05105957802456843, 'reg_lambda': 0.276391273568361}. Best is trial 14 with value: 38.875240325927734.\n",
      "[I 2025-02-10 19:21:14,186] Trial 232 finished with value: 38.87715276082357 and parameters: {'colsample_bylevel': 0.5239843485717698, 'colsample_bytree': 0.9706311283666178, 'learning_rate': 0.14809401852258136, 'max_depth': 7, 'min_child_weight': 41, 'gamma': 0.7058044576811001, 'subsample': 0.9633503315868895, 'reg_alpha': 0.07241125454493032, 'reg_lambda': 0.49603862206472105}. Best is trial 14 with value: 38.875240325927734.\n",
      "[I 2025-02-10 19:21:22,290] Trial 233 pruned. Trial was pruned at iteration 27.\n",
      "[I 2025-02-10 19:21:22,721] Trial 234 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:21:23,180] Trial 235 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:21:27,998] Trial 236 pruned. Trial was pruned at iteration 19.\n",
      "[I 2025-02-10 19:21:28,461] Trial 237 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:21:28,859] Trial 238 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:22:15,247] Trial 239 finished with value: 38.87690099080404 and parameters: {'colsample_bylevel': 0.7405872880651493, 'colsample_bytree': 0.9590288890603896, 'learning_rate': 0.1580423397900682, 'max_depth': 6, 'min_child_weight': 41, 'gamma': 0.7297947902620671, 'subsample': 0.962547122111625, 'reg_alpha': 0.10570336592634949, 'reg_lambda': 0.09539114179640736}. Best is trial 14 with value: 38.875240325927734.\n",
      "[I 2025-02-10 19:22:15,687] Trial 240 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:23:11,365] Trial 241 finished with value: 38.87725830078125 and parameters: {'colsample_bylevel': 0.7306020574153486, 'colsample_bytree': 0.9610861436997188, 'learning_rate': 0.1587783286328298, 'max_depth': 6, 'min_child_weight': 41, 'gamma': 0.9969959511878038, 'subsample': 0.9736685521293992, 'reg_alpha': 0.12044243495922283, 'reg_lambda': 0.10846733063634335}. Best is trial 14 with value: 38.875240325927734.\n",
      "[I 2025-02-10 19:23:18,661] Trial 242 pruned. Trial was pruned at iteration 29.\n",
      "[I 2025-02-10 19:24:01,134] Trial 243 finished with value: 38.877543131510414 and parameters: {'colsample_bylevel': 0.8023996990808813, 'colsample_bytree': 0.9814149274414068, 'learning_rate': 0.1702650545771046, 'max_depth': 6, 'min_child_weight': 42, 'gamma': 0.6876936216304781, 'subsample': 0.9339079465995445, 'reg_alpha': 0.24174567295212315, 'reg_lambda': 0.0498964772795244}. Best is trial 14 with value: 38.875240325927734.\n",
      "[I 2025-02-10 19:24:01,568] Trial 244 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:24:01,958] Trial 245 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:24:02,402] Trial 246 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:24:56,589] Trial 247 finished with value: 38.87675094604492 and parameters: {'colsample_bylevel': 0.6855784817941212, 'colsample_bytree': 0.9519899307245177, 'learning_rate': 0.15477177319826815, 'max_depth': 6, 'min_child_weight': 45, 'gamma': 0.96468878086096, 'subsample': 0.9420025824928079, 'reg_alpha': 5.6996829744455654e-05, 'reg_lambda': 0.5104768947988123}. Best is trial 14 with value: 38.875240325927734.\n",
      "[I 2025-02-10 19:25:39,967] Trial 248 finished with value: 38.87756601969401 and parameters: {'colsample_bylevel': 0.6930495892777501, 'colsample_bytree': 0.9542200293356721, 'learning_rate': 0.19585406643748252, 'max_depth': 6, 'min_child_weight': 45, 'gamma': 0.9647613303969903, 'subsample': 0.9241890941800249, 'reg_alpha': 0.8058842555240397, 'reg_lambda': 0.1279768188384627}. Best is trial 14 with value: 38.875240325927734.\n",
      "[I 2025-02-10 19:25:40,724] Trial 249 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:26:39,731] Trial 250 finished with value: 38.87794876098633 and parameters: {'colsample_bylevel': 0.6707779755960709, 'colsample_bytree': 0.9288688364780664, 'learning_rate': 0.16131643044916508, 'max_depth': 6, 'min_child_weight': 44, 'gamma': 0.9682212314453468, 'subsample': 0.8754590733644333, 'reg_alpha': 0.00012293731853795114, 'reg_lambda': 0.6460789921434573}. Best is trial 14 with value: 38.875240325927734.\n",
      "[I 2025-02-10 19:26:40,179] Trial 251 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:26:40,587] Trial 252 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:26:40,997] Trial 253 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:26:41,430] Trial 254 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:26:41,818] Trial 255 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:26:42,233] Trial 256 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:27:29,255] Trial 257 finished with value: 38.877543131510414 and parameters: {'colsample_bylevel': 0.6633136629402487, 'colsample_bytree': 0.9487980960748341, 'learning_rate': 0.17061044953922896, 'max_depth': 6, 'min_child_weight': 45, 'gamma': 0.9996123862337676, 'subsample': 0.9324146103664528, 'reg_alpha': 0.00015819678617826579, 'reg_lambda': 0.9762339212781669}. Best is trial 14 with value: 38.875240325927734.\n",
      "[I 2025-02-10 19:27:32,088] Trial 258 pruned. Trial was pruned at iteration 11.\n",
      "[I 2025-02-10 19:27:32,471] Trial 259 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:27:32,855] Trial 260 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:27:33,258] Trial 261 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:27:33,686] Trial 262 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:28:17,018] Trial 263 finished with value: 38.87709045410156 and parameters: {'colsample_bylevel': 0.7459097244525019, 'colsample_bytree': 0.952723895664063, 'learning_rate': 0.15968072918663623, 'max_depth': 6, 'min_child_weight': 43, 'gamma': 0.9674768928591075, 'subsample': 0.919196736165486, 'reg_alpha': 7.427736535727854e-05, 'reg_lambda': 0.05894049890726151}. Best is trial 14 with value: 38.875240325927734.\n",
      "[I 2025-02-10 19:28:17,420] Trial 264 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:28:17,835] Trial 265 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:28:18,282] Trial 266 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:29:04,473] Trial 267 finished with value: 38.878134409586586 and parameters: {'colsample_bylevel': 0.7855262248712889, 'colsample_bytree': 0.8709744641788264, 'learning_rate': 0.18362349329094643, 'max_depth': 6, 'min_child_weight': 12, 'gamma': 0.8493018236598423, 'subsample': 0.9199029808052333, 'reg_alpha': 4.45988329013927e-05, 'reg_lambda': 0.06516474383948168}. Best is trial 14 with value: 38.875240325927734.\n",
      "[I 2025-02-10 19:29:11,192] Trial 268 pruned. Trial was pruned at iteration 19.\n",
      "[I 2025-02-10 19:29:11,638] Trial 269 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:29:12,070] Trial 270 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:29:12,519] Trial 271 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:29:12,928] Trial 272 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:29:13,342] Trial 273 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:30:02,610] Trial 274 finished with value: 38.87752024332682 and parameters: {'colsample_bylevel': 0.7174187943316175, 'colsample_bytree': 0.9054615666032667, 'learning_rate': 0.14178423268091983, 'max_depth': 7, 'min_child_weight': 21, 'gamma': 0.8821144552035654, 'subsample': 0.8814779241618481, 'reg_alpha': 0.007251232355132076, 'reg_lambda': 0.7830936734721434}. Best is trial 14 with value: 38.875240325927734.\n",
      "[I 2025-02-10 19:30:03,047] Trial 275 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:30:03,464] Trial 276 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:30:03,869] Trial 277 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:30:43,288] Trial 278 finished with value: 38.879295349121094 and parameters: {'colsample_bylevel': 0.8005053794311217, 'colsample_bytree': 0.9347014218570814, 'learning_rate': 0.18171701417930147, 'max_depth': 7, 'min_child_weight': 47, 'gamma': 0.6241326514302268, 'subsample': 0.8977182298108458, 'reg_alpha': 0.015789148681240883, 'reg_lambda': 0.030279402811473222}. Best is trial 14 with value: 38.875240325927734.\n",
      "[I 2025-02-10 19:30:44,767] Trial 279 pruned. Trial was pruned at iteration 3.\n",
      "[I 2025-02-10 19:30:45,127] Trial 280 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:30:45,531] Trial 281 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:30:45,947] Trial 282 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:30:46,383] Trial 283 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:30:46,775] Trial 284 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:30:51,068] Trial 285 pruned. Trial was pruned at iteration 17.\n",
      "[I 2025-02-10 19:30:51,497] Trial 286 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:30:51,893] Trial 287 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:30:52,344] Trial 288 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:30:52,753] Trial 289 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:30:53,182] Trial 290 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:31:00,004] Trial 291 pruned. Trial was pruned at iteration 24.\n",
      "[I 2025-02-10 19:31:00,432] Trial 292 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:31:00,843] Trial 293 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:31:01,241] Trial 294 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:31:06,044] Trial 295 pruned. Trial was pruned at iteration 18.\n",
      "[I 2025-02-10 19:31:06,543] Trial 296 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:31:06,998] Trial 297 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:31:07,399] Trial 298 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:31:07,820] Trial 299 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:31:08,322] Trial 300 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:31:11,495] Trial 301 pruned. Trial was pruned at iteration 13.\n",
      "[I 2025-02-10 19:31:12,120] Trial 302 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:31:12,552] Trial 303 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:31:51,338] Trial 304 finished with value: 38.87915929158529 and parameters: {'colsample_bylevel': 0.6038582435691556, 'colsample_bytree': 0.8450618598840048, 'learning_rate': 0.1851001580047677, 'max_depth': 7, 'min_child_weight': 49, 'gamma': 0.8926211187621845, 'subsample': 0.9636889993843126, 'reg_alpha': 0.005795422828275345, 'reg_lambda': 0.7884149291951167}. Best is trial 14 with value: 38.875240325927734.\n",
      "[I 2025-02-10 19:31:51,738] Trial 305 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:31:52,454] Trial 306 pruned. Trial was pruned at iteration 1.\n",
      "[I 2025-02-10 19:31:52,885] Trial 307 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:31:53,339] Trial 308 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:31:53,747] Trial 309 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:32:00,680] Trial 310 pruned. Trial was pruned at iteration 28.\n",
      "[I 2025-02-10 19:32:01,132] Trial 311 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:32:01,722] Trial 312 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:32:02,170] Trial 313 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:32:02,579] Trial 314 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:32:03,014] Trial 315 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:32:09,721] Trial 316 pruned. Trial was pruned at iteration 27.\n",
      "[I 2025-02-10 19:32:10,138] Trial 317 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:32:10,568] Trial 318 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:32:10,972] Trial 319 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:32:17,192] Trial 320 pruned. Trial was pruned at iteration 24.\n",
      "[I 2025-02-10 19:32:17,627] Trial 321 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:32:18,070] Trial 322 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:32:18,436] Trial 323 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:32:24,238] Trial 324 pruned. Trial was pruned at iteration 16.\n",
      "[I 2025-02-10 19:32:24,662] Trial 325 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:32:25,048] Trial 326 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:32:32,695] Trial 327 pruned. Trial was pruned at iteration 29.\n",
      "[I 2025-02-10 19:32:38,528] Trial 328 pruned. Trial was pruned at iteration 24.\n",
      "[I 2025-02-10 19:32:39,041] Trial 329 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:33:21,034] Trial 330 finished with value: 38.877394358317055 and parameters: {'colsample_bylevel': 0.6201460577943787, 'colsample_bytree': 0.9490469465958818, 'learning_rate': 0.1499283592850878, 'max_depth': 7, 'min_child_weight': 41, 'gamma': 0.9429708591265044, 'subsample': 0.9046391932167311, 'reg_alpha': 0.0014441128544187244, 'reg_lambda': 0.0640094546679411}. Best is trial 14 with value: 38.875240325927734.\n",
      "[I 2025-02-10 19:33:21,458] Trial 331 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:33:21,858] Trial 332 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:33:22,295] Trial 333 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:33:22,685] Trial 334 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:33:23,123] Trial 335 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:33:23,554] Trial 336 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:33:23,972] Trial 337 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:33:24,353] Trial 338 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:33:24,750] Trial 339 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:33:25,179] Trial 340 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:33:25,618] Trial 341 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:33:32,754] Trial 342 pruned. Trial was pruned at iteration 26.\n",
      "[I 2025-02-10 19:33:33,165] Trial 343 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:33:34,899] Trial 344 pruned. Trial was pruned at iteration 5.\n",
      "[I 2025-02-10 19:33:35,343] Trial 345 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:33:35,739] Trial 346 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:33:36,191] Trial 347 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:33:41,915] Trial 348 pruned. Trial was pruned at iteration 23.\n",
      "[I 2025-02-10 19:33:42,317] Trial 349 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:33:50,032] Trial 350 pruned. Trial was pruned at iteration 27.\n",
      "[I 2025-02-10 19:33:50,486] Trial 351 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:33:50,939] Trial 352 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:34:32,827] Trial 353 finished with value: 38.8774668375651 and parameters: {'colsample_bylevel': 0.6456234703194608, 'colsample_bytree': 0.9962944681507947, 'learning_rate': 0.13872976701661754, 'max_depth': 7, 'min_child_weight': 45, 'gamma': 0.9864402459561301, 'subsample': 0.9601754710933683, 'reg_alpha': 0.04424553259522118, 'reg_lambda': 0.32763273506112023}. Best is trial 14 with value: 38.875240325927734.\n",
      "[I 2025-02-10 19:34:33,248] Trial 354 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:34:33,648] Trial 355 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:34:34,098] Trial 356 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:34:34,522] Trial 357 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:34:34,948] Trial 358 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:34:35,403] Trial 359 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:34:35,847] Trial 360 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:34:39,875] Trial 361 pruned. Trial was pruned at iteration 15.\n",
      "[I 2025-02-10 19:34:40,280] Trial 362 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:34:40,707] Trial 363 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:34:41,511] Trial 364 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:34:41,984] Trial 365 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:34:42,395] Trial 366 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:34:42,783] Trial 367 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:34:43,224] Trial 368 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:34:43,653] Trial 369 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:34:44,059] Trial 370 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:35:26,984] Trial 371 finished with value: 38.878604888916016 and parameters: {'colsample_bylevel': 0.4863337502986841, 'colsample_bytree': 0.9039993211183657, 'learning_rate': 0.17492878386187974, 'max_depth': 7, 'min_child_weight': 45, 'gamma': 0.7829152909896554, 'subsample': 0.9286386226843859, 'reg_alpha': 7.519578143926308e-05, 'reg_lambda': 0.039207409666904544}. Best is trial 14 with value: 38.875240325927734.\n",
      "[I 2025-02-10 19:35:27,385] Trial 372 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:35:27,833] Trial 373 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:35:29,600] Trial 374 pruned. Trial was pruned at iteration 4.\n",
      "[I 2025-02-10 19:35:30,055] Trial 375 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:35:30,513] Trial 376 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:35:31,009] Trial 377 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:35:31,421] Trial 378 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:35:31,836] Trial 379 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:35:32,262] Trial 380 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:35:32,725] Trial 381 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:35:33,134] Trial 382 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:36:09,122] Trial 383 finished with value: 38.878186543782554 and parameters: {'colsample_bylevel': 0.7579582841197429, 'colsample_bytree': 0.9534759036631133, 'learning_rate': 0.19582282154982483, 'max_depth': 6, 'min_child_weight': 48, 'gamma': 0.9682225168855153, 'subsample': 0.8445601657252135, 'reg_alpha': 0.00981540327918053, 'reg_lambda': 0.548261496758974}. Best is trial 14 with value: 38.875240325927734.\n",
      "[I 2025-02-10 19:36:09,581] Trial 384 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:36:11,101] Trial 385 pruned. Trial was pruned at iteration 4.\n",
      "[I 2025-02-10 19:36:11,504] Trial 386 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:36:11,982] Trial 387 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:36:12,454] Trial 388 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:36:12,885] Trial 389 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:36:17,850] Trial 390 pruned. Trial was pruned at iteration 18.\n",
      "[I 2025-02-10 19:36:18,296] Trial 391 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:36:18,772] Trial 392 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:36:19,226] Trial 393 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:36:19,619] Trial 394 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:36:20,077] Trial 395 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:36:20,630] Trial 396 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:36:21,093] Trial 397 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:36:21,521] Trial 398 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:36:21,948] Trial 399 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:36:22,402] Trial 400 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:36:57,872] Trial 401 finished with value: 38.87948735555013 and parameters: {'colsample_bylevel': 0.602162893137318, 'colsample_bytree': 0.9410761271500059, 'learning_rate': 0.17324000423297903, 'max_depth': 8, 'min_child_weight': 39, 'gamma': 0.9356307773138985, 'subsample': 0.9544674751767382, 'reg_alpha': 0.00045923998338082687, 'reg_lambda': 0.012678462039416551}. Best is trial 14 with value: 38.875240325927734.\n",
      "[I 2025-02-10 19:37:02,892] Trial 402 pruned. Trial was pruned at iteration 18.\n",
      "[I 2025-02-10 19:37:03,263] Trial 403 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:37:03,663] Trial 404 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:37:04,104] Trial 405 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:37:04,512] Trial 406 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:37:04,971] Trial 407 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:37:05,416] Trial 408 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:37:05,892] Trial 409 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:37:06,295] Trial 410 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:37:06,729] Trial 411 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:37:11,971] Trial 412 pruned. Trial was pruned at iteration 18.\n",
      "[I 2025-02-10 19:37:12,422] Trial 413 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:37:12,848] Trial 414 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:37:13,254] Trial 415 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:37:13,704] Trial 416 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:37:14,171] Trial 417 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:37:18,545] Trial 418 pruned. Trial was pruned at iteration 8.\n",
      "[I 2025-02-10 19:37:18,994] Trial 419 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:37:21,400] Trial 420 pruned. Trial was pruned at iteration 9.\n",
      "[I 2025-02-10 19:37:21,845] Trial 421 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:37:22,290] Trial 422 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:37:22,706] Trial 423 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:37:23,137] Trial 424 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:37:23,566] Trial 425 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:37:24,029] Trial 426 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:37:24,502] Trial 427 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:37:25,047] Trial 428 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:37:25,539] Trial 429 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:37:27,067] Trial 430 pruned. Trial was pruned at iteration 5.\n",
      "[I 2025-02-10 19:37:27,518] Trial 431 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:37:27,939] Trial 432 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:37:28,371] Trial 433 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:37:28,760] Trial 434 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:37:35,087] Trial 435 pruned. Trial was pruned at iteration 24.\n",
      "[I 2025-02-10 19:37:35,498] Trial 436 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:37:35,956] Trial 437 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:37:36,462] Trial 438 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:37:36,905] Trial 439 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:37:37,348] Trial 440 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:37:37,760] Trial 441 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:37:40,715] Trial 442 pruned. Trial was pruned at iteration 10.\n",
      "[I 2025-02-10 19:37:41,183] Trial 443 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:37:41,581] Trial 444 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:37:42,008] Trial 445 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:37:42,509] Trial 446 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:38:29,613] Trial 447 finished with value: 38.87812296549479 and parameters: {'colsample_bylevel': 0.7470082841732806, 'colsample_bytree': 0.9375644147917586, 'learning_rate': 0.18700384151320715, 'max_depth': 6, 'min_child_weight': 44, 'gamma': 0.9458743592595886, 'subsample': 0.9703461289009981, 'reg_alpha': 0.00045980222757774174, 'reg_lambda': 0.00010290588752736935}. Best is trial 14 with value: 38.875240325927734.\n",
      "[I 2025-02-10 19:38:30,060] Trial 448 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:38:30,470] Trial 449 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:38:35,157] Trial 450 pruned. Trial was pruned at iteration 18.\n",
      "[I 2025-02-10 19:38:35,557] Trial 451 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:39:17,008] Trial 452 finished with value: 38.878491719563804 and parameters: {'colsample_bylevel': 0.7643078458673891, 'colsample_bytree': 0.9421873969601424, 'learning_rate': 0.1567680995429904, 'max_depth': 7, 'min_child_weight': 28, 'gamma': 0.8067893391669443, 'subsample': 0.8779109277879665, 'reg_alpha': 0.00361054680953846, 'reg_lambda': 0.7766186214073513}. Best is trial 14 with value: 38.875240325927734.\n",
      "[I 2025-02-10 19:39:17,446] Trial 453 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:39:17,829] Trial 454 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:39:18,268] Trial 455 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:39:19,377] Trial 456 pruned. Trial was pruned at iteration 3.\n",
      "[I 2025-02-10 19:39:26,941] Trial 457 pruned. Trial was pruned at iteration 22.\n",
      "[I 2025-02-10 19:39:27,394] Trial 458 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:39:27,915] Trial 459 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:40:11,089] Trial 460 finished with value: 38.8772226969401 and parameters: {'colsample_bylevel': 0.6701024921731987, 'colsample_bytree': 0.925877357224668, 'learning_rate': 0.1443684346598036, 'max_depth': 7, 'min_child_weight': 43, 'gamma': 0.7690442371762568, 'subsample': 0.8904589586690803, 'reg_alpha': 0.00031556935729863493, 'reg_lambda': 0.4467629446840608}. Best is trial 14 with value: 38.875240325927734.\n",
      "[I 2025-02-10 19:40:11,546] Trial 461 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:40:11,937] Trial 462 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:40:12,343] Trial 463 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:40:12,770] Trial 464 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:40:13,247] Trial 465 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:40:13,683] Trial 466 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:40:18,557] Trial 467 pruned. Trial was pruned at iteration 19.\n",
      "[I 2025-02-10 19:40:19,008] Trial 468 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:40:23,352] Trial 469 pruned. Trial was pruned at iteration 14.\n",
      "[I 2025-02-10 19:40:23,766] Trial 470 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:40:24,136] Trial 471 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:40:24,573] Trial 472 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:40:24,974] Trial 473 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:41:12,133] Trial 474 finished with value: 38.87765884399414 and parameters: {'colsample_bylevel': 0.6790551928796243, 'colsample_bytree': 0.9372280825212399, 'learning_rate': 0.16095140642432962, 'max_depth': 6, 'min_child_weight': 41, 'gamma': 0.921800797009182, 'subsample': 0.898722851200225, 'reg_alpha': 6.290509650301354e-05, 'reg_lambda': 0.9863056114921854}. Best is trial 14 with value: 38.875240325927734.\n",
      "[I 2025-02-10 19:41:12,638] Trial 475 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:41:13,063] Trial 476 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:41:13,579] Trial 477 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:41:14,034] Trial 478 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:41:14,477] Trial 479 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:41:14,892] Trial 480 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:41:15,356] Trial 481 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:41:16,339] Trial 482 pruned. Trial was pruned at iteration 2.\n",
      "[I 2025-02-10 19:41:16,791] Trial 483 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:41:17,203] Trial 484 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:41:17,656] Trial 485 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:41:18,610] Trial 486 pruned. Trial was pruned at iteration 2.\n",
      "[I 2025-02-10 19:41:19,068] Trial 487 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:41:19,458] Trial 488 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:41:19,935] Trial 489 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:41:20,360] Trial 490 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:41:20,836] Trial 491 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:41:21,342] Trial 492 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:41:25,761] Trial 493 pruned. Trial was pruned at iteration 16.\n",
      "[I 2025-02-10 19:41:26,171] Trial 494 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:41:26,613] Trial 495 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:41:27,103] Trial 496 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:41:27,507] Trial 497 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 19:41:34,186] Trial 498 pruned. Trial was pruned at iteration 27.\n",
      "[I 2025-02-10 19:41:34,624] Trial 499 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================\n",
      "Number of finished trials: 500\n",
      "Best trial: 14\n",
      "Best value (RMSE): 38.875240325927734\n",
      "Best hyperparameters: {'colsample_bylevel': 0.7042399860352442, 'colsample_bytree': 0.6700664404290344, 'learning_rate': 0.06431217687710553, 'max_depth': 6, 'min_child_weight': 48, 'gamma': 0.8026187053731907, 'subsample': 0.8883384798896046, 'reg_alpha': 0.00020737803353933882, 'reg_lambda': 0.00012965526480433523}\n"
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "    params = {\n",
    "        \"objective\": \"reg:squarederror\",\n",
    "        \"eval_metric\": \"rmse\",\n",
    "        \"seed\": 42,\n",
    "        \"verbosity\": 0,\n",
    "        'device': \"cuda\",\n",
    "\n",
    "        # \"grow_policy\", trial.suggest_categorical(\"grow_policy\", [\"depthwise\", \"lossguide\"]),\n",
    "        \n",
    "        \"colsample_bylevel\": trial.suggest_float(\"colsample_bylevel\", 0.3, 1.0),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.5, 1.0),\n",
    "\n",
    "        \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.25),\n",
    "\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 14),\n",
    "        \n",
    "        \"min_child_weight\": trial.suggest_int(\"min_child_weight\", 1, 50),\n",
    "\n",
    "        \"gamma\": trial.suggest_float(\"gamma\", 0.1, 1),\n",
    "\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.2, 1.0),\n",
    "\n",
    "        \"reg_alpha\": trial.suggest_loguniform(\"reg_alpha\", 1e-6, 2.0),\n",
    "        \"reg_lambda\": trial.suggest_loguniform(\"reg_lambda\", 1e-6, 1),\n",
    "        \n",
    "    }\n",
    "    rmse_list = []\n",
    "    num_boost_round_list = []\n",
    "    for i, (dtrain_fold, dvalid_fold) in enumerate(data_splits, 1):\n",
    "    \n",
    "        bst = xgb.train(\n",
    "            params=params,\n",
    "            dtrain=dtrain_fold,\n",
    "            num_boost_round=200,\n",
    "            evals=[(dtrain_fold, \"train\"), (dvalid_fold, \"validation_0\")],\n",
    "            early_stopping_rounds=20,\n",
    "            verbose_eval=False,\n",
    "            callbacks=[XGBoostPruningCallback(trial, observation_key=\"validation_0-rmse\") ]\n",
    "        )\n",
    "        y_pred = bst.predict(dvalid_fold)\n",
    "        rmse = root_mean_squared_error(dvalid_fold.get_label(), y_pred)\n",
    "        rmse_list.append(rmse)\n",
    "        num_boost_round_list.append(bst.best_iteration)\n",
    "\n",
    "    params[\"num_boost_round\"] = int(np.mean(num_boost_round_list)) \n",
    "\n",
    "    return np.mean(rmse_list)\n",
    "\n",
    "\n",
    "study = optuna.create_study(\n",
    "        storage=f\"sqlite:///..//optuna//{model_str}db.sqlite3\",\n",
    "        study_name=model_str + datetime.now().strftime(\"%Y-%m-%d_%H-%M\"),\n",
    "        direction=\"minimize\"\n",
    ")\n",
    "study.optimize(objective, n_trials=500)\n",
    "\n",
    "print(\"\\n=========================\")\n",
    "print(\"Number of finished trials:\", len(study.trials))\n",
    "print(\"Best trial:\", study.best_trial.number)\n",
    "print(\"Best value (RMSE):\", study.best_trial.value)\n",
    "print(\"Best hyperparameters:\", study.best_trial.params)\n",
    "best_params = study.best_trial.params\n",
    "best_params[\"random_state\"] = 42\n",
    "best_params[\"verbose\"] = 0\n",
    "best_params[\"eval_metric\"] = \"rmse\"\n",
    "best_params[\"device\"] = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "        \"objective\": \"reg:squarederror\",\n",
    "        \"eval_metric\": \"rmse\",\n",
    "        \"seed\": 42,\n",
    "        \"verbosity\": 0,\n",
    "        'device': \"cuda\",\n",
    "        'colsample_bylevel': 0.64,\n",
    "        'colsample_bytree': 0.76,\n",
    "        'gamma': .73,\n",
    "        'learning_rate': 0.21,\n",
    "        'max_depth': 6,\n",
    "        'min_child_weight': 20,\n",
    "        'reg_alpha': 0.47,\n",
    "        'reg_lambda': 1e-5,\n",
    "        'subsample': 0.99,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: 38.8577, 37\n",
      "Fold 2: 38.8927, 43\n",
      "Fold 3: 38.8864, 32\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "38.87893549601237"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse_list = []\n",
    "num_boost_round_list = []\n",
    "# pruning_callback = XGBoostPruningCallback(trial, observation_key=\"validation_0-rmse\") \n",
    "for i, (dtrain_fold, dvalid_fold) in enumerate(data_splits, 1):\n",
    "\n",
    "    bst = xgb.train(\n",
    "        # params=best_params,\n",
    "        params=params,\n",
    "        dtrain=dtrain_fold,\n",
    "        num_boost_round=200,\n",
    "        evals=[(dtrain_fold, \"train\"), (dvalid_fold, \"validation_0\")],\n",
    "        early_stopping_rounds=20,\n",
    "        verbose_eval=False,\n",
    "        # callbacks=[pruning_callback]\n",
    "    )\n",
    "    y_pred = bst.predict(dvalid_fold)\n",
    "    rmse = root_mean_squared_error(dvalid_fold.get_label(), y_pred)\n",
    "    rmse_list.append(rmse)\n",
    "    num_boost_round_list.append(bst.best_iteration)\n",
    "    print(f\"Fold {i}: {rmse:.4f}, {bst.best_iteration}\")\n",
    "\n",
    "best_params[\"num_boost_round\"] = int(np.mean(num_boost_round_list))\n",
    "np.mean(rmse_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[999, 999, 993]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_boost_round_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "997"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params[\"num_boost_round\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (dtrain_fold, dvalid_fold) in enumerate(data_splits, 1):\n",
    "\n",
    "    bst = xgb.train(\n",
    "        params={\"objective\": \"reg:squarederror\",\n",
    "        \"eval_metric\": \"rmse\",\n",
    "        \"seed\": 42,\n",
    "        \"verbosity\": 0,\n",
    "        'device': \"cuda\",},\n",
    "        dtrain=dtrain_fold,\n",
    "        num_boost_round=1000,\n",
    "        evals=[(dtrain_fold, \"train\"), (dvalid_fold, \"validation_0\")],\n",
    "        early_stopping_rounds=50,\n",
    "        verbose_eval=False,\n",
    "        # callbacks=[pruning_callback]\n",
    "    )\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bst.num_boosted_rounds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_encoded, test_df_encoded = preprocess_weight_capacity(train_df, test_df)\n",
    "\n",
    "train_df_encoded, test_df_encoded, encoded_cols = target_encoding(\n",
    "    train_df=train_df_encoded,\n",
    "    cat_cols=cat_cols,\n",
    "    test_df=test_df_encoded, \n",
    "    target=y_train.name,\n",
    ")\n",
    "\n",
    "dtrain = xgb.DMatrix(train_df_encoded[feature_list], label=train_df_encoded[target], enable_categorical=True)\n",
    "# dvalid = xgb.DMatrix(X_val[feature_list], label=y_val, enable_categorical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params[\"device\"] = \"cuda\"\n",
    "best_params[\"eval_metric\"] = \"rmse\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "bst = xgb.train(\n",
    "    # params=best_params,\n",
    "    params=params,\n",
    "    dtrain=dtrain,\n",
    "    num_boost_round=40,\n",
    "    # early_stopping_rounds=50,\n",
    "    verbose_eval=False,\n",
    ")\n",
    "y_pred = bst.predict(xgb.DMatrix(test_df_encoded[feature_list], enable_categorical=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving to: ..//submissions//xgb_2025-02-10_17-17.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>300000</td>\n",
       "      <td>81.793533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>300001</td>\n",
       "      <td>82.356857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>300002</td>\n",
       "      <td>82.614616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>300003</td>\n",
       "      <td>80.617020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>300004</td>\n",
       "      <td>78.095940</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id      Price\n",
       "0  300000  81.793533\n",
       "1  300001  82.356857\n",
       "2  300002  82.614616\n",
       "3  300003  80.617020\n",
       "4  300004  78.095940"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit_path = f'..//submissions//' + model_str + datetime.now().strftime(\"%Y-%m-%d_%H-%M\") + \".csv\"\n",
    "print(\"Saving to:\", submit_path)\n",
    "# y_pred.to_csv(\"submission.csv\", index=False)\n",
    "\n",
    "submit_df = test_df[['id']].copy()\n",
    "submit_df['Price'] = y_pred\n",
    "# submit_df['Price'] = np.mean(predictions, axis=0) # Average the predictions\n",
    "submit_df.to_csv(submit_path, index=False)\n",
    "# print(f\"Submission file saved as submission.csv\\n\")\n",
    "submit_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([81.63002, 83.31463, 83.826  , ..., 84.71671, 82.46941, 80.08696],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Non-CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-09 16:44:36,190] A new study created in RDB with name: xgb_2025-02-09_16-44\n",
      "[I 2025-02-10 07:28:24,380] Trial 0 finished with value: 6.236178058153393 and parameters: {'colsample_bytree': 0.39502267014535775, 'colsample_bylevel': 0.5883398341351831, 'learning_rate': 0.0014494540530035546, 'max_depth': 10, 'min_child_weight': 8, 'gamma': 0.39446214518513933, 'subsample': 0.8790552280307211, 'reg_alpha': 0.6923740870444277, 'reg_lambda': 0.49414047624922824}. Best is trial 0 with value: 6.236178058153393.\n",
      "[W 2025-02-10 07:28:36,303] Trial 1 failed with parameters: {'colsample_bytree': 0.8859267740000449, 'colsample_bylevel': 0.5864274342712049, 'learning_rate': 0.0029402949507566383, 'max_depth': 6, 'min_child_weight': 8, 'gamma': 0.5736934908980399, 'subsample': 0.8161256788238413, 'reg_alpha': 0.7279801474451931, 'reg_lambda': 5.303352980611302e-06} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/j/miniforge3/envs/ml/lib/python3.9/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_859539/3955838019.py\", line 29, in objective\n",
      "    bst = xgb.train(\n",
      "  File \"/home/j/miniforge3/envs/ml/lib/python3.9/site-packages/xgboost/core.py\", line 726, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/j/miniforge3/envs/ml/lib/python3.9/site-packages/xgboost/training.py\", line 182, in train\n",
      "    if cb_container.after_iteration(bst, i, dtrain, evals):\n",
      "  File \"/home/j/miniforge3/envs/ml/lib/python3.9/site-packages/xgboost/callback.py\", line 261, in after_iteration\n",
      "    ret = any(c.after_iteration(model, epoch, self.history) for c in self.callbacks)\n",
      "  File \"/home/j/miniforge3/envs/ml/lib/python3.9/site-packages/xgboost/callback.py\", line 261, in <genexpr>\n",
      "    ret = any(c.after_iteration(model, epoch, self.history) for c in self.callbacks)\n",
      "  File \"/home/j/miniforge3/envs/ml/lib/python3.9/site-packages/optuna_integration/xgboost/xgboost.py\", line 77, in after_iteration\n",
      "    if self._trial.should_prune():\n",
      "  File \"/home/j/miniforge3/envs/ml/lib/python3.9/site-packages/optuna/trial/_trial.py\", line 535, in should_prune\n",
      "    return self.study.pruner.prune(self.study, trial)\n",
      "  File \"/home/j/miniforge3/envs/ml/lib/python3.9/site-packages/optuna/pruners/_percentile.py\", line 173, in prune\n",
      "    completed_trials = study.get_trials(deepcopy=False, states=(TrialState.COMPLETE,))\n",
      "  File \"/home/j/miniforge3/envs/ml/lib/python3.9/site-packages/optuna/study/study.py\", line 289, in get_trials\n",
      "    return self._get_trials(deepcopy, states, use_cache=False)\n",
      "  File \"/home/j/miniforge3/envs/ml/lib/python3.9/site-packages/optuna/study/study.py\", line 309, in _get_trials\n",
      "    return self._storage.get_all_trials(self._study_id, deepcopy=deepcopy, states=states)\n",
      "  File \"/home/j/miniforge3/envs/ml/lib/python3.9/site-packages/optuna/storages/_cached_storage.py\", line 221, in get_all_trials\n",
      "    self._read_trials_from_remote_storage(study_id)\n",
      "  File \"/home/j/miniforge3/envs/ml/lib/python3.9/site-packages/optuna/storages/_cached_storage.py\", line 242, in _read_trials_from_remote_storage\n",
      "    trials = self._backend._get_trials(\n",
      "  File \"/home/j/miniforge3/envs/ml/lib/python3.9/site-packages/optuna/storages/_rdb/storage.py\", line 871, in _get_trials\n",
      "    trials = [self._build_frozen_trial_from_trial_model(trial) for trial in trial_models]\n",
      "  File \"/home/j/miniforge3/envs/ml/lib/python3.9/site-packages/optuna/storages/_rdb/storage.py\", line 871, in <listcomp>\n",
      "    trials = [self._build_frozen_trial_from_trial_model(trial) for trial in trial_models]\n",
      "  File \"/home/j/miniforge3/envs/ml/lib/python3.9/site-packages/optuna/storages/_rdb/storage.py\", line 901, in _build_frozen_trial_from_trial_model\n",
      "    distributions={\n",
      "  File \"/home/j/miniforge3/envs/ml/lib/python3.9/site-packages/optuna/storages/_rdb/storage.py\", line 902, in <dictcomp>\n",
      "    p.param_name: distributions.json_to_distribution(p.distribution_json)\n",
      "  File \"/home/j/miniforge3/envs/ml/lib/python3.9/site-packages/optuna/distributions.py\", line 589, in json_to_distribution\n",
      "    json_dict = json.loads(json_str)\n",
      "  File \"/home/j/miniforge3/envs/ml/lib/python3.9/json/__init__.py\", line 346, in loads\n",
      "    return _default_decoder.decode(s)\n",
      "  File \"/home/j/miniforge3/envs/ml/lib/python3.9/json/decoder.py\", line 337, in decode\n",
      "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
      "  File \"/home/j/miniforge3/envs/ml/lib/python3.9/json/decoder.py\", line 353, in raw_decode\n",
      "    obj, end = self.scan_once(s, idx)\n",
      "KeyboardInterrupt\n",
      "[W 2025-02-10 07:28:36,306] Trial 1 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 55\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# Create a study (using a SQLite database for persistence)\u001b[39;00m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# study_name = datetime.now().strftime(\"%Y-%m-%d_%H-%M\")\u001b[39;00m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# storage_name = f\"sqlite:///{os.path.join(optuna_dir, folder_dir, study_name)}.db\"\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# # Run the optimization for 50 trials (adjust as needed)\u001b[39;00m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m# study.optimize(objective, n_trials=50)\u001b[39;00m\n\u001b[1;32m     50\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(\n\u001b[1;32m     51\u001b[0m         storage\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msqlite:///\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mdb.sqlite3\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     52\u001b[0m         study_name\u001b[38;5;241m=\u001b[39mmodel_str \u001b[38;5;241m+\u001b[39m datetime\u001b[38;5;241m.\u001b[39mnow()\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m     53\u001b[0m         direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mminimize\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     54\u001b[0m )\n\u001b[0;32m---> 55\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m=========================\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of finished trials:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(study\u001b[38;5;241m.\u001b[39mtrials))\n",
      "File \u001b[0;32m~/miniforge3/envs/ml/lib/python3.9/site-packages/optuna/study/study.py:475\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21moptimize\u001b[39m(\n\u001b[1;32m    374\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    375\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    382\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    383\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    384\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    385\u001b[0m \n\u001b[1;32m    386\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    473\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    474\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 475\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    476\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    477\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    478\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    479\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    480\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    481\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    482\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    483\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/ml/lib/python3.9/site-packages/optuna/study/_optimize.py:63\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 63\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     76\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/miniforge3/envs/ml/lib/python3.9/site-packages/optuna/study/_optimize.py:160\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 160\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m~/miniforge3/envs/ml/lib/python3.9/site-packages/optuna/study/_optimize.py:248\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    244\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    247\u001b[0m ):\n\u001b[0;32m--> 248\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[0;32m~/miniforge3/envs/ml/lib/python3.9/site-packages/optuna/study/_optimize.py:197\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 197\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    199\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    200\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[0;32mIn[28], line 29\u001b[0m, in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m      2\u001b[0m param \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobjective\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreg:squarederror\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meval_metric\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrmse\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     25\u001b[0m     \n\u001b[1;32m     26\u001b[0m }\n\u001b[1;32m     28\u001b[0m pruning_callback \u001b[38;5;241m=\u001b[39m XGBoostPruningCallback(trial, observation_key\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidation_0-rmse\u001b[39m\u001b[38;5;124m\"\u001b[39m)    \n\u001b[0;32m---> 29\u001b[0m bst \u001b[38;5;241m=\u001b[39m \u001b[43mxgb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparam\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_boost_round\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mdvalid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvalidation_0\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mpruning_callback\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m bst\u001b[38;5;241m.\u001b[39mpredict(dvalid)\n\u001b[1;32m     39\u001b[0m rmse \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msqrt(root_mean_squared_error(y_val, y_pred))\n",
      "File \u001b[0;32m~/miniforge3/envs/ml/lib/python3.9/site-packages/xgboost/core.py:726\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    724\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[1;32m    725\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[0;32m--> 726\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/ml/lib/python3.9/site-packages/xgboost/training.py:182\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    181\u001b[0m     bst\u001b[38;5;241m.\u001b[39mupdate(dtrain, iteration\u001b[38;5;241m=\u001b[39mi, fobj\u001b[38;5;241m=\u001b[39mobj)\n\u001b[0;32m--> 182\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mcb_container\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mafter_iteration\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevals\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    183\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    185\u001b[0m bst \u001b[38;5;241m=\u001b[39m cb_container\u001b[38;5;241m.\u001b[39mafter_training(bst)\n",
      "File \u001b[0;32m~/miniforge3/envs/ml/lib/python3.9/site-packages/xgboost/callback.py:261\u001b[0m, in \u001b[0;36mCallbackContainer.after_iteration\u001b[0;34m(self, model, epoch, dtrain, evals)\u001b[0m\n\u001b[1;32m    259\u001b[0m     metric_score \u001b[38;5;241m=\u001b[39m _parse_eval_str(score)\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_history(metric_score, epoch)\n\u001b[0;32m--> 261\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43many\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mafter_iteration\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    262\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "File \u001b[0;32m~/miniforge3/envs/ml/lib/python3.9/site-packages/xgboost/callback.py:261\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    259\u001b[0m     metric_score \u001b[38;5;241m=\u001b[39m _parse_eval_str(score)\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_history(metric_score, epoch)\n\u001b[0;32m--> 261\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28many\u001b[39m(\u001b[43mc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mafter_iteration\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks)\n\u001b[1;32m    262\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "File \u001b[0;32m~/miniforge3/envs/ml/lib/python3.9/site-packages/optuna_integration/xgboost/xgboost.py:77\u001b[0m, in \u001b[0;36mXGBoostPruningCallback.after_iteration\u001b[0;34m(self, model, epoch, evals_log)\u001b[0m\n\u001b[1;32m     75\u001b[0m current_score \u001b[38;5;241m=\u001b[39m evaluation_results[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_observation_key]\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trial\u001b[38;5;241m.\u001b[39mreport(current_score, step\u001b[38;5;241m=\u001b[39mepoch)\n\u001b[0;32m---> 77\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_trial\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshould_prune\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     78\u001b[0m     message \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrial was pruned at iteration \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(epoch)\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m optuna\u001b[38;5;241m.\u001b[39mTrialPruned(message)\n",
      "File \u001b[0;32m~/miniforge3/envs/ml/lib/python3.9/site-packages/optuna/trial/_trial.py:535\u001b[0m, in \u001b[0;36mTrial.should_prune\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[1;32m    531\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrial.should_prune is not supported for multi-objective optimization.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    532\u001b[0m     )\n\u001b[1;32m    534\u001b[0m trial \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_latest_trial()\n\u001b[0;32m--> 535\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpruner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprune\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/ml/lib/python3.9/site-packages/optuna/pruners/_percentile.py:173\u001b[0m, in \u001b[0;36mPercentilePruner.prune\u001b[0;34m(self, study, trial)\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mprune\u001b[39m(\u001b[38;5;28mself\u001b[39m, study: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moptuna.study.Study\u001b[39m\u001b[38;5;124m\"\u001b[39m, trial: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moptuna.trial.FrozenTrial\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[0;32m--> 173\u001b[0m     completed_trials \u001b[38;5;241m=\u001b[39m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_trials\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdeepcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mTrialState\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCOMPLETE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    174\u001b[0m     n_trials \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(completed_trials)\n\u001b[1;32m    176\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_trials \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/miniforge3/envs/ml/lib/python3.9/site-packages/optuna/study/study.py:289\u001b[0m, in \u001b[0;36mStudy.get_trials\u001b[0;34m(self, deepcopy, states)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_trials\u001b[39m(\n\u001b[1;32m    250\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    251\u001b[0m     deepcopy: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    252\u001b[0m     states: Container[TrialState] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    253\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[FrozenTrial]:\n\u001b[1;32m    254\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return all trials in the study.\u001b[39;00m\n\u001b[1;32m    255\u001b[0m \n\u001b[1;32m    256\u001b[0m \u001b[38;5;124;03m    The returned trials are ordered by trial number.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;124;03m        A list of :class:`~optuna.trial.FrozenTrial` objects.\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 289\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_trials\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdeepcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstates\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/ml/lib/python3.9/site-packages/optuna/study/study.py:309\u001b[0m, in \u001b[0;36mStudy._get_trials\u001b[0;34m(self, deepcopy, states, use_cache)\u001b[0m\n\u001b[1;32m    306\u001b[0m         filtered_trials \u001b[38;5;241m=\u001b[39m trials\n\u001b[1;32m    307\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m copy\u001b[38;5;241m.\u001b[39mdeepcopy(filtered_trials) \u001b[38;5;28;01mif\u001b[39;00m deepcopy \u001b[38;5;28;01melse\u001b[39;00m filtered_trials\n\u001b[0;32m--> 309\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_storage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_all_trials\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_study_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdeepcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdeepcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstates\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/ml/lib/python3.9/site-packages/optuna/storages/_cached_storage.py:221\u001b[0m, in \u001b[0;36m_CachedStorage.get_all_trials\u001b[0;34m(self, study_id, deepcopy, states)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_all_trials\u001b[39m(\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    217\u001b[0m     study_id: \u001b[38;5;28mint\u001b[39m,\n\u001b[1;32m    218\u001b[0m     deepcopy: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    219\u001b[0m     states: Container[TrialState] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    220\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[FrozenTrial]:\n\u001b[0;32m--> 221\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_trials_from_remote_storage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    224\u001b[0m         study \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_studies[study_id]\n",
      "File \u001b[0;32m~/miniforge3/envs/ml/lib/python3.9/site-packages/optuna/storages/_cached_storage.py:242\u001b[0m, in \u001b[0;36m_CachedStorage._read_trials_from_remote_storage\u001b[0;34m(self, study_id)\u001b[0m\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_studies[study_id] \u001b[38;5;241m=\u001b[39m _StudyInfo()\n\u001b[1;32m    241\u001b[0m study \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_studies[study_id]\n\u001b[0;32m--> 242\u001b[0m trials \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_trials\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    243\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstudy_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    244\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    245\u001b[0m \u001b[43m    \u001b[49m\u001b[43mincluded_trial_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munfinished_trial_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    246\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrial_id_greater_than\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlast_finished_trial_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    247\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m trials:\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/ml/lib/python3.9/site-packages/optuna/storages/_rdb/storage.py:871\u001b[0m, in \u001b[0;36mRDBStorage._get_trials\u001b[0;34m(self, study_id, states, included_trial_ids, trial_id_greater_than)\u001b[0m\n\u001b[1;32m    864\u001b[0m         trial_models \u001b[38;5;241m=\u001b[39m query\u001b[38;5;241m.\u001b[39morder_by(models\u001b[38;5;241m.\u001b[39mTrialModel\u001b[38;5;241m.\u001b[39mtrial_id)\u001b[38;5;241m.\u001b[39mall()\n\u001b[1;32m    865\u001b[0m         trial_models \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    866\u001b[0m             t\n\u001b[1;32m    867\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m trial_models\n\u001b[1;32m    868\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mtrial_id \u001b[38;5;129;01min\u001b[39;00m included_trial_ids \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mtrial_id \u001b[38;5;241m>\u001b[39m trial_id_greater_than\n\u001b[1;32m    869\u001b[0m         ]\n\u001b[0;32m--> 871\u001b[0m     trials \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_frozen_trial_from_trial_model(trial) \u001b[38;5;28;01mfor\u001b[39;00m trial \u001b[38;5;129;01min\u001b[39;00m trial_models]\n\u001b[1;32m    873\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m trials\n",
      "File \u001b[0;32m~/miniforge3/envs/ml/lib/python3.9/site-packages/optuna/storages/_rdb/storage.py:871\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    864\u001b[0m         trial_models \u001b[38;5;241m=\u001b[39m query\u001b[38;5;241m.\u001b[39morder_by(models\u001b[38;5;241m.\u001b[39mTrialModel\u001b[38;5;241m.\u001b[39mtrial_id)\u001b[38;5;241m.\u001b[39mall()\n\u001b[1;32m    865\u001b[0m         trial_models \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    866\u001b[0m             t\n\u001b[1;32m    867\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m trial_models\n\u001b[1;32m    868\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mtrial_id \u001b[38;5;129;01min\u001b[39;00m included_trial_ids \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mtrial_id \u001b[38;5;241m>\u001b[39m trial_id_greater_than\n\u001b[1;32m    869\u001b[0m         ]\n\u001b[0;32m--> 871\u001b[0m     trials \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_build_frozen_trial_from_trial_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m trial \u001b[38;5;129;01min\u001b[39;00m trial_models]\n\u001b[1;32m    873\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m trials\n",
      "File \u001b[0;32m~/miniforge3/envs/ml/lib/python3.9/site-packages/optuna/storages/_rdb/storage.py:901\u001b[0m, in \u001b[0;36mRDBStorage._build_frozen_trial_from_trial_model\u001b[0;34m(self, trial)\u001b[0m\n\u001b[1;32m    884\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    886\u001b[0m params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(trial\u001b[38;5;241m.\u001b[39mparams, key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m p: p\u001b[38;5;241m.\u001b[39mparam_id)\n\u001b[1;32m    888\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m FrozenTrial(\n\u001b[1;32m    889\u001b[0m     number\u001b[38;5;241m=\u001b[39mtrial\u001b[38;5;241m.\u001b[39mnumber,\n\u001b[1;32m    890\u001b[0m     state\u001b[38;5;241m=\u001b[39mtrial\u001b[38;5;241m.\u001b[39mstate,\n\u001b[1;32m    891\u001b[0m     value\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    892\u001b[0m     values\u001b[38;5;241m=\u001b[39mvalues,\n\u001b[1;32m    893\u001b[0m     datetime_start\u001b[38;5;241m=\u001b[39mtrial\u001b[38;5;241m.\u001b[39mdatetime_start,\n\u001b[1;32m    894\u001b[0m     datetime_complete\u001b[38;5;241m=\u001b[39mtrial\u001b[38;5;241m.\u001b[39mdatetime_complete,\n\u001b[1;32m    895\u001b[0m     params\u001b[38;5;241m=\u001b[39m{\n\u001b[1;32m    896\u001b[0m         p\u001b[38;5;241m.\u001b[39mparam_name: distributions\u001b[38;5;241m.\u001b[39mjson_to_distribution(\n\u001b[1;32m    897\u001b[0m             p\u001b[38;5;241m.\u001b[39mdistribution_json\n\u001b[1;32m    898\u001b[0m         )\u001b[38;5;241m.\u001b[39mto_external_repr(p\u001b[38;5;241m.\u001b[39mparam_value)\n\u001b[1;32m    899\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m params\n\u001b[1;32m    900\u001b[0m     },\n\u001b[0;32m--> 901\u001b[0m     distributions\u001b[38;5;241m=\u001b[39m{\n\u001b[1;32m    902\u001b[0m         p\u001b[38;5;241m.\u001b[39mparam_name: distributions\u001b[38;5;241m.\u001b[39mjson_to_distribution(p\u001b[38;5;241m.\u001b[39mdistribution_json)\n\u001b[1;32m    903\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m params\n\u001b[1;32m    904\u001b[0m     },\n\u001b[1;32m    905\u001b[0m     user_attrs\u001b[38;5;241m=\u001b[39m{attr\u001b[38;5;241m.\u001b[39mkey: json\u001b[38;5;241m.\u001b[39mloads(attr\u001b[38;5;241m.\u001b[39mvalue_json) \u001b[38;5;28;01mfor\u001b[39;00m attr \u001b[38;5;129;01min\u001b[39;00m trial\u001b[38;5;241m.\u001b[39muser_attributes},\n\u001b[1;32m    906\u001b[0m     system_attrs\u001b[38;5;241m=\u001b[39m{\n\u001b[1;32m    907\u001b[0m         attr\u001b[38;5;241m.\u001b[39mkey: json\u001b[38;5;241m.\u001b[39mloads(attr\u001b[38;5;241m.\u001b[39mvalue_json) \u001b[38;5;28;01mfor\u001b[39;00m attr \u001b[38;5;129;01min\u001b[39;00m trial\u001b[38;5;241m.\u001b[39msystem_attributes\n\u001b[1;32m    908\u001b[0m     },\n\u001b[1;32m    909\u001b[0m     intermediate_values\u001b[38;5;241m=\u001b[39m{\n\u001b[1;32m    910\u001b[0m         v\u001b[38;5;241m.\u001b[39mstep: models\u001b[38;5;241m.\u001b[39mTrialIntermediateValueModel\u001b[38;5;241m.\u001b[39mstored_repr_to_intermediate_value(\n\u001b[1;32m    911\u001b[0m             v\u001b[38;5;241m.\u001b[39mintermediate_value, v\u001b[38;5;241m.\u001b[39mintermediate_value_type\n\u001b[1;32m    912\u001b[0m         )\n\u001b[1;32m    913\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m trial\u001b[38;5;241m.\u001b[39mintermediate_values\n\u001b[1;32m    914\u001b[0m     },\n\u001b[1;32m    915\u001b[0m     trial_id\u001b[38;5;241m=\u001b[39mtrial\u001b[38;5;241m.\u001b[39mtrial_id,\n\u001b[1;32m    916\u001b[0m )\n",
      "File \u001b[0;32m~/miniforge3/envs/ml/lib/python3.9/site-packages/optuna/storages/_rdb/storage.py:902\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    884\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    886\u001b[0m params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(trial\u001b[38;5;241m.\u001b[39mparams, key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m p: p\u001b[38;5;241m.\u001b[39mparam_id)\n\u001b[1;32m    888\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m FrozenTrial(\n\u001b[1;32m    889\u001b[0m     number\u001b[38;5;241m=\u001b[39mtrial\u001b[38;5;241m.\u001b[39mnumber,\n\u001b[1;32m    890\u001b[0m     state\u001b[38;5;241m=\u001b[39mtrial\u001b[38;5;241m.\u001b[39mstate,\n\u001b[1;32m    891\u001b[0m     value\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    892\u001b[0m     values\u001b[38;5;241m=\u001b[39mvalues,\n\u001b[1;32m    893\u001b[0m     datetime_start\u001b[38;5;241m=\u001b[39mtrial\u001b[38;5;241m.\u001b[39mdatetime_start,\n\u001b[1;32m    894\u001b[0m     datetime_complete\u001b[38;5;241m=\u001b[39mtrial\u001b[38;5;241m.\u001b[39mdatetime_complete,\n\u001b[1;32m    895\u001b[0m     params\u001b[38;5;241m=\u001b[39m{\n\u001b[1;32m    896\u001b[0m         p\u001b[38;5;241m.\u001b[39mparam_name: distributions\u001b[38;5;241m.\u001b[39mjson_to_distribution(\n\u001b[1;32m    897\u001b[0m             p\u001b[38;5;241m.\u001b[39mdistribution_json\n\u001b[1;32m    898\u001b[0m         )\u001b[38;5;241m.\u001b[39mto_external_repr(p\u001b[38;5;241m.\u001b[39mparam_value)\n\u001b[1;32m    899\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m params\n\u001b[1;32m    900\u001b[0m     },\n\u001b[1;32m    901\u001b[0m     distributions\u001b[38;5;241m=\u001b[39m{\n\u001b[0;32m--> 902\u001b[0m         p\u001b[38;5;241m.\u001b[39mparam_name: \u001b[43mdistributions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjson_to_distribution\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistribution_json\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    903\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m params\n\u001b[1;32m    904\u001b[0m     },\n\u001b[1;32m    905\u001b[0m     user_attrs\u001b[38;5;241m=\u001b[39m{attr\u001b[38;5;241m.\u001b[39mkey: json\u001b[38;5;241m.\u001b[39mloads(attr\u001b[38;5;241m.\u001b[39mvalue_json) \u001b[38;5;28;01mfor\u001b[39;00m attr \u001b[38;5;129;01min\u001b[39;00m trial\u001b[38;5;241m.\u001b[39muser_attributes},\n\u001b[1;32m    906\u001b[0m     system_attrs\u001b[38;5;241m=\u001b[39m{\n\u001b[1;32m    907\u001b[0m         attr\u001b[38;5;241m.\u001b[39mkey: json\u001b[38;5;241m.\u001b[39mloads(attr\u001b[38;5;241m.\u001b[39mvalue_json) \u001b[38;5;28;01mfor\u001b[39;00m attr \u001b[38;5;129;01min\u001b[39;00m trial\u001b[38;5;241m.\u001b[39msystem_attributes\n\u001b[1;32m    908\u001b[0m     },\n\u001b[1;32m    909\u001b[0m     intermediate_values\u001b[38;5;241m=\u001b[39m{\n\u001b[1;32m    910\u001b[0m         v\u001b[38;5;241m.\u001b[39mstep: models\u001b[38;5;241m.\u001b[39mTrialIntermediateValueModel\u001b[38;5;241m.\u001b[39mstored_repr_to_intermediate_value(\n\u001b[1;32m    911\u001b[0m             v\u001b[38;5;241m.\u001b[39mintermediate_value, v\u001b[38;5;241m.\u001b[39mintermediate_value_type\n\u001b[1;32m    912\u001b[0m         )\n\u001b[1;32m    913\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m trial\u001b[38;5;241m.\u001b[39mintermediate_values\n\u001b[1;32m    914\u001b[0m     },\n\u001b[1;32m    915\u001b[0m     trial_id\u001b[38;5;241m=\u001b[39mtrial\u001b[38;5;241m.\u001b[39mtrial_id,\n\u001b[1;32m    916\u001b[0m )\n",
      "File \u001b[0;32m~/miniforge3/envs/ml/lib/python3.9/site-packages/optuna/distributions.py:589\u001b[0m, in \u001b[0;36mjson_to_distribution\u001b[0;34m(json_str)\u001b[0m\n\u001b[1;32m    578\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mjson_to_distribution\u001b[39m(json_str: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BaseDistribution:\n\u001b[1;32m    579\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Deserialize a distribution in JSON format.\u001b[39;00m\n\u001b[1;32m    580\u001b[0m \n\u001b[1;32m    581\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    586\u001b[0m \n\u001b[1;32m    587\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 589\u001b[0m     json_dict \u001b[38;5;241m=\u001b[39m \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson_str\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    591\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m json_dict:\n\u001b[1;32m    592\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m json_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m CategoricalDistribution\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m:\n",
      "File \u001b[0;32m~/miniforge3/envs/ml/lib/python3.9/json/__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    341\u001b[0m     s \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mdecode(detect_encoding(s), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurrogatepass\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[0;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    348\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONDecoder\n",
      "File \u001b[0;32m~/miniforge3/envs/ml/lib/python3.9/json/decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, s, _w\u001b[38;5;241m=\u001b[39mWHITESPACE\u001b[38;5;241m.\u001b[39mmatch):\n\u001b[1;32m    333\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;124;03m    containing a JSON document).\u001b[39;00m\n\u001b[1;32m    335\u001b[0m \n\u001b[1;32m    336\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 337\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    338\u001b[0m     end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n\u001b[1;32m    339\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(s):\n",
      "File \u001b[0;32m~/miniforge3/envs/ml/lib/python3.9/json/decoder.py:353\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Decode a JSON document from ``s`` (a ``str`` beginning with\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;124;03ma JSON document) and return a 2-tuple of the Python\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;124;03mrepresentation and the index in ``s`` where the document ended.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    350\u001b[0m \n\u001b[1;32m    351\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    352\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 353\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscan_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpecting value\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, err\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "    param = {\n",
    "        \"objective\": \"reg:squarederror\",\n",
    "        \"eval_metric\": \"rmse\",\n",
    "        \"seed\": 42,\n",
    "        \"verbosity\": 0,\n",
    "        'device': \"cuda\",\n",
    "\n",
    "        # \"grow_policy\", trial.suggest_categorical(\"grow_policy\", [\"depthwise\", \"lossguide\"]),\n",
    "        \n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.1, 1.0),\n",
    "        \"colsample_bylevel\": trial.suggest_float(\"colsample_bylevel\", 0.1, 1.0),\n",
    "\n",
    "        \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.25),\n",
    "\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 14),\n",
    "        \"min_child_weight\": trial.suggest_int(\"min_child_weight\", 1, 10),\n",
    "\n",
    "        \"gamma\": trial.suggest_float(\"gamma\", 0, 1),\n",
    "\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.2, 1.0),\n",
    "\n",
    "        \"reg_alpha\": trial.suggest_loguniform(\"reg_alpha\", 0.5, 2.0),\n",
    "        \"reg_lambda\": trial.suggest_loguniform(\"reg_lambda\", 1e-6, 1),\n",
    "        \n",
    "    }\n",
    "    \n",
    "    pruning_callback = XGBoostPruningCallback(trial, observation_key=\"validation_0-rmse\")    \n",
    "    bst = xgb.train(\n",
    "        params=param,\n",
    "        dtrain=dtrain,\n",
    "        num_boost_round=1000,\n",
    "        evals=[(dtrain, \"train\"), (dvalid, \"validation_0\")],\n",
    "        early_stopping_rounds=50,\n",
    "        verbose_eval=False,\n",
    "        callbacks=[pruning_callback]\n",
    "    )\n",
    "    y_pred = bst.predict(dvalid)\n",
    "    rmse = np.sqrt(root_mean_squared_error(y_val, y_pred))\n",
    "    return rmse\n",
    "\n",
    "# Create a study (using a SQLite database for persistence)\n",
    "# study_name = datetime.now().strftime(\"%Y-%m-%d_%H-%M\")\n",
    "# storage_name = f\"sqlite:///{os.path.join(optuna_dir, folder_dir, study_name)}.db\"\n",
    "# study = optuna.create_study(study_name=study_name, storage=storage_name, direction=\"minimize\")\n",
    "\n",
    "# # Run the optimization for 50 trials (adjust as needed)\n",
    "# study.optimize(objective, n_trials=50)\n",
    "\n",
    "study = optuna.create_study(\n",
    "        storage=f\"sqlite:///{model_str}db.sqlite3\",\n",
    "        study_name=model_str + datetime.now().strftime(\"%Y-%m-%d_%H-%M\"),\n",
    "        direction=\"minimize\"\n",
    ")\n",
    "study.optimize(objective, n_trials=500)\n",
    "\n",
    "print(\"\\n=========================\")\n",
    "print(\"Number of finished trials:\", len(study.trials))\n",
    "print(\"Best trial:\", study.best_trial.number)\n",
    "print(\"Best value (RMSE):\", study.best_trial.value)\n",
    "print(\"Best hyperparameters:\", study.best_trial.params)\n",
    "best_params = study.best_trial.params\n",
    "best_params[\"random_state\"] = 42\n",
    "best_params[\"verbose\"] = 0\n",
    "best_params[\"eval_metric\"] = \"rmse\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
