{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import logging\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "import lightgbm as lgb\n",
    "import optuna\n",
    "from optuna.integration import LightGBMPruningCallback\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "optuna_dir = \"..//optuna\"\n",
    "\n",
    "test_df = pd.read_csv(r'..//data//test.csv')\n",
    "train_df = pd.read_csv(r'..//data//train.csv')\n",
    "train_extra_df = pd.read_csv(r'..//data//training_extra.csv')\n",
    "\n",
    "train_df = pd.concat([train_df, train_extra_df], ignore_index=True)\n",
    "\n",
    "train_df.columns = [\n",
    "    'id', 'brand', 'material', 'size', 'compartments', \n",
    "    'laptop_compartment', 'is_waterproof', 'style', 'color', \n",
    "    'weight_capacity', 'price'\n",
    "]\n",
    "test_df.columns = [\n",
    "    'id', 'brand', 'material', 'size', 'compartments', \n",
    "    'laptop_compartment', 'is_waterproof', 'style', 'color', \n",
    "    'weight_capacity',\n",
    "]\n",
    "\n",
    "cat_cols = train_df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "# Convert all to be the same type\n",
    "train_df[cat_cols] = train_df[cat_cols].astype('category')\n",
    "test_df[cat_cols] = test_df[cat_cols].astype('category')\n",
    "\n",
    "target = \"price\"\n",
    "X = train_df.drop(columns=[target])\n",
    "y = train_df[target]\n",
    "\n",
    "# Only keeping important columns\n",
    "model_features = [\n",
    "    'weight_capacity', 'color', 'compartments', 'brand', 'material', 'is_waterproof'\n",
    "]\n",
    "X = X[model_features]\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-05 17:35:41,606] A new study created in RDB with name: 2025-02-05_17-35-41\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A new study created in RDB with name: 2025-02-05_17-35-41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-05 17:47:23,458] Trial 0 finished with value: 38.77757827534952 and parameters: {'colsample_bytree': 0.30528771575740377, 'learning_rate': 0.023729726287148156, 'max_bin': 113784, 'min_child_samples': 41, 'n_estimators': 14347, 'num_leaves': 1194, 'reg_alpha': 1.1145243421358724, 'reg_lambda': 9.332164118064479e-06, 'subsample': 0.24379261778941813}. Best is trial 0 with value: 38.77757827534952.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 0 finished with value: 38.77757827534952 and parameters: {'colsample_bytree': 0.30528771575740377, 'learning_rate': 0.023729726287148156, 'max_bin': 113784, 'min_child_samples': 41, 'n_estimators': 14347, 'num_leaves': 1194, 'reg_alpha': 1.1145243421358724, 'reg_lambda': 9.332164118064479e-06, 'subsample': 0.24379261778941813}. Best is trial 0 with value: 38.77757827534952.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-05 18:01:25,592] Trial 1 finished with value: 38.78724723779155 and parameters: {'colsample_bytree': 0.33709912142446513, 'learning_rate': 0.016458940912505264, 'max_bin': 100185, 'min_child_samples': 65, 'n_estimators': 12938, 'num_leaves': 1089, 'reg_alpha': 0.9001090206907691, 'reg_lambda': 3.429333048648549e-06, 'subsample': 0.23508584066534363}. Best is trial 0 with value: 38.77757827534952.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1 finished with value: 38.78724723779155 and parameters: {'colsample_bytree': 0.33709912142446513, 'learning_rate': 0.016458940912505264, 'max_bin': 100185, 'min_child_samples': 65, 'n_estimators': 12938, 'num_leaves': 1089, 'reg_alpha': 0.9001090206907691, 'reg_lambda': 3.429333048648549e-06, 'subsample': 0.23508584066534363}. Best is trial 0 with value: 38.77757827534952.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-05 18:18:32,163] Trial 2 finished with value: 38.77909344152868 and parameters: {'colsample_bytree': 0.3343626633535619, 'learning_rate': 0.019351845911743795, 'max_bin': 122192, 'min_child_samples': 73, 'n_estimators': 9836, 'num_leaves': 1144, 'reg_alpha': 1.6506844483084404, 'reg_lambda': 5.611346491820717e-06, 'subsample': 0.21129545854089649}. Best is trial 0 with value: 38.77757827534952.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 2 finished with value: 38.77909344152868 and parameters: {'colsample_bytree': 0.3343626633535619, 'learning_rate': 0.019351845911743795, 'max_bin': 122192, 'min_child_samples': 73, 'n_estimators': 9836, 'num_leaves': 1144, 'reg_alpha': 1.6506844483084404, 'reg_lambda': 5.611346491820717e-06, 'subsample': 0.21129545854089649}. Best is trial 0 with value: 38.77757827534952.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-05 18:24:28,538] Trial 3 finished with value: 38.7867712914308 and parameters: {'colsample_bytree': 0.30894410491964447, 'learning_rate': 0.031247320831937157, 'max_bin': 102870, 'min_child_samples': 71, 'n_estimators': 13037, 'num_leaves': 1048, 'reg_alpha': 0.9507603627972041, 'reg_lambda': 1.2081037698154608e-06, 'subsample': 0.21583257541647793}. Best is trial 0 with value: 38.77757827534952.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 3 finished with value: 38.7867712914308 and parameters: {'colsample_bytree': 0.30894410491964447, 'learning_rate': 0.031247320831937157, 'max_bin': 102870, 'min_child_samples': 71, 'n_estimators': 13037, 'num_leaves': 1048, 'reg_alpha': 0.9507603627972041, 'reg_lambda': 1.2081037698154608e-06, 'subsample': 0.21583257541647793}. Best is trial 0 with value: 38.77757827534952.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-05 18:30:36,612] Trial 4 finished with value: 38.77911868721009 and parameters: {'colsample_bytree': 0.25815477911165036, 'learning_rate': 0.03487517017874163, 'max_bin': 101534, 'min_child_samples': 54, 'n_estimators': 12081, 'num_leaves': 1129, 'reg_alpha': 1.3735933150627126, 'reg_lambda': 2.514288618908702e-06, 'subsample': 0.22515720202511955}. Best is trial 0 with value: 38.77757827534952.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 4 finished with value: 38.77911868721009 and parameters: {'colsample_bytree': 0.25815477911165036, 'learning_rate': 0.03487517017874163, 'max_bin': 101534, 'min_child_samples': 54, 'n_estimators': 12081, 'num_leaves': 1129, 'reg_alpha': 1.3735933150627126, 'reg_lambda': 2.514288618908702e-06, 'subsample': 0.22515720202511955}. Best is trial 0 with value: 38.77757827534952.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-05 18:36:24,828] Trial 5 finished with value: 38.7814925249155 and parameters: {'colsample_bytree': 0.2584316974195693, 'learning_rate': 0.03881852000212843, 'max_bin': 124320, 'min_child_samples': 62, 'n_estimators': 9276, 'num_leaves': 1130, 'reg_alpha': 1.092373099808769, 'reg_lambda': 1.5248078287357297e-06, 'subsample': 0.22284694430199306}. Best is trial 0 with value: 38.77757827534952.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 finished with value: 38.7814925249155 and parameters: {'colsample_bytree': 0.2584316974195693, 'learning_rate': 0.03881852000212843, 'max_bin': 124320, 'min_child_samples': 62, 'n_estimators': 9276, 'num_leaves': 1130, 'reg_alpha': 1.092373099808769, 'reg_lambda': 1.5248078287357297e-06, 'subsample': 0.22284694430199306}. Best is trial 0 with value: 38.77757827534952.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-05 18:36:25,308] Trial 6 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 6 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-05 18:41:41,540] Trial 7 finished with value: 38.78356270129498 and parameters: {'colsample_bytree': 0.30268586359307637, 'learning_rate': 0.036481156097329846, 'max_bin': 123509, 'min_child_samples': 40, 'n_estimators': 9035, 'num_leaves': 997, 'reg_alpha': 0.5638804880244841, 'reg_lambda': 2.6906758960589824e-06, 'subsample': 0.23133159846304407}. Best is trial 0 with value: 38.77757827534952.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 7 finished with value: 38.78356270129498 and parameters: {'colsample_bytree': 0.30268586359307637, 'learning_rate': 0.036481156097329846, 'max_bin': 123509, 'min_child_samples': 40, 'n_estimators': 9035, 'num_leaves': 997, 'reg_alpha': 0.5638804880244841, 'reg_lambda': 2.6906758960589824e-06, 'subsample': 0.23133159846304407}. Best is trial 0 with value: 38.77757827534952.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-05 18:41:42,062] Trial 8 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 8 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-05 18:41:42,500] Trial 9 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 9 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-05 18:45:31,780] Trial 10 finished with value: 38.781761694648324 and parameters: {'colsample_bytree': 0.31850836488385714, 'learning_rate': 0.04862241462630001, 'max_bin': 109765, 'min_child_samples': 80, 'n_estimators': 14942, 'num_leaves': 906, 'reg_alpha': 0.6335404943951383, 'reg_lambda': 8.395898204542144e-06, 'subsample': 0.24715743935965093}. Best is trial 0 with value: 38.77757827534952.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10 finished with value: 38.781761694648324 and parameters: {'colsample_bytree': 0.31850836488385714, 'learning_rate': 0.04862241462630001, 'max_bin': 109765, 'min_child_samples': 80, 'n_estimators': 14942, 'num_leaves': 906, 'reg_alpha': 0.6335404943951383, 'reg_lambda': 8.395898204542144e-06, 'subsample': 0.24715743935965093}. Best is trial 0 with value: 38.77757827534952.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-05 18:45:32,302] Trial 11 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 11 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-05 18:45:32,842] Trial 12 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 12 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-05 18:45:33,320] Trial 13 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 13 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-05 18:45:33,804] Trial 14 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 14 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-05 18:45:34,289] Trial 15 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 15 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-05 18:45:34,782] Trial 16 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 16 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-05 18:45:35,267] Trial 17 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 17 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-05 18:45:35,725] Trial 18 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 18 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-05 18:45:36,194] Trial 19 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 19 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-05 18:45:36,677] Trial 20 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 20 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-05 18:51:09,416] Trial 21 finished with value: 38.782578485433945 and parameters: {'colsample_bytree': 0.2539856182100602, 'learning_rate': 0.03606992175201812, 'max_bin': 105562, 'min_child_samples': 54, 'n_estimators': 12282, 'num_leaves': 1124, 'reg_alpha': 1.3368443316186223, 'reg_lambda': 2.280770680326015e-06, 'subsample': 0.23761854751059913}. Best is trial 0 with value: 38.77757827534952.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 21 finished with value: 38.782578485433945 and parameters: {'colsample_bytree': 0.2539856182100602, 'learning_rate': 0.03606992175201812, 'max_bin': 105562, 'min_child_samples': 54, 'n_estimators': 12282, 'num_leaves': 1124, 'reg_alpha': 1.3368443316186223, 'reg_lambda': 2.280770680326015e-06, 'subsample': 0.23761854751059913}. Best is trial 0 with value: 38.77757827534952.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-05 18:57:24,474] Trial 22 finished with value: 38.77571707197482 and parameters: {'colsample_bytree': 0.2648669874990907, 'learning_rate': 0.0489613573598086, 'max_bin': 106589, 'min_child_samples': 52, 'n_estimators': 9896, 'num_leaves': 1136, 'reg_alpha': 1.4001592641689393, 'reg_lambda': 3.386290422653286e-06, 'subsample': 0.22655972442328925}. Best is trial 22 with value: 38.77571707197482.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 22 finished with value: 38.77571707197482 and parameters: {'colsample_bytree': 0.2648669874990907, 'learning_rate': 0.0489613573598086, 'max_bin': 106589, 'min_child_samples': 52, 'n_estimators': 9896, 'num_leaves': 1136, 'reg_alpha': 1.4001592641689393, 'reg_lambda': 3.386290422653286e-06, 'subsample': 0.22655972442328925}. Best is trial 22 with value: 38.77571707197482.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-05 18:57:24,970] Trial 23 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 23 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-05 19:02:07,501] Trial 24 finished with value: 38.77786569951161 and parameters: {'colsample_bytree': 0.2852131631924286, 'learning_rate': 0.049444152978732406, 'max_bin': 113624, 'min_child_samples': 44, 'n_estimators': 10061, 'num_leaves': 1084, 'reg_alpha': 1.6883401716480069, 'reg_lambda': 4.9239120647525525e-06, 'subsample': 0.20835066380743952}. Best is trial 22 with value: 38.77571707197482.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 24 finished with value: 38.77786569951161 and parameters: {'colsample_bytree': 0.2852131631924286, 'learning_rate': 0.049444152978732406, 'max_bin': 113624, 'min_child_samples': 44, 'n_estimators': 10061, 'num_leaves': 1084, 'reg_alpha': 1.6883401716480069, 'reg_lambda': 4.9239120647525525e-06, 'subsample': 0.20835066380743952}. Best is trial 22 with value: 38.77571707197482.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-05 19:06:05,754] Trial 25 finished with value: 38.781527455074276 and parameters: {'colsample_bytree': 0.28378023960981213, 'learning_rate': 0.04837166954390724, 'max_bin': 104325, 'min_child_samples': 44, 'n_estimators': 10686, 'num_leaves': 1079, 'reg_alpha': 1.9696176091852469, 'reg_lambda': 3.1071625069267153e-06, 'subsample': 0.22757795057181093}. Best is trial 22 with value: 38.77571707197482.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 25 finished with value: 38.781527455074276 and parameters: {'colsample_bytree': 0.28378023960981213, 'learning_rate': 0.04837166954390724, 'max_bin': 104325, 'min_child_samples': 44, 'n_estimators': 10686, 'num_leaves': 1079, 'reg_alpha': 1.9696176091852469, 'reg_lambda': 3.1071625069267153e-06, 'subsample': 0.22757795057181093}. Best is trial 22 with value: 38.77571707197482.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-05 19:11:13,126] Trial 26 finished with value: 38.78092709589775 and parameters: {'colsample_bytree': 0.2691279057257436, 'learning_rate': 0.04143181632674554, 'max_bin': 112562, 'min_child_samples': 43, 'n_estimators': 9648, 'num_leaves': 1020, 'reg_alpha': 0.8681473744630743, 'reg_lambda': 1.930545311401735e-06, 'subsample': 0.2193664951524819}. Best is trial 22 with value: 38.77571707197482.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 26 finished with value: 38.78092709589775 and parameters: {'colsample_bytree': 0.2691279057257436, 'learning_rate': 0.04143181632674554, 'max_bin': 112562, 'min_child_samples': 43, 'n_estimators': 9648, 'num_leaves': 1020, 'reg_alpha': 0.8681473744630743, 'reg_lambda': 1.930545311401735e-06, 'subsample': 0.2193664951524819}. Best is trial 22 with value: 38.77571707197482.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-05 19:16:09,222] Trial 27 finished with value: 38.7808936975367 and parameters: {'colsample_bytree': 0.2922707607854443, 'learning_rate': 0.044403830435202137, 'max_bin': 117280, 'min_child_samples': 51, 'n_estimators': 11499, 'num_leaves': 1111, 'reg_alpha': 1.4300131497357869, 'reg_lambda': 3.991726017837731e-06, 'subsample': 0.20712177017769903}. Best is trial 22 with value: 38.77571707197482.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 27 finished with value: 38.7808936975367 and parameters: {'colsample_bytree': 0.2922707607854443, 'learning_rate': 0.044403830435202137, 'max_bin': 117280, 'min_child_samples': 51, 'n_estimators': 11499, 'num_leaves': 1111, 'reg_alpha': 1.4300131497357869, 'reg_lambda': 3.991726017837731e-06, 'subsample': 0.20712177017769903}. Best is trial 22 with value: 38.77571707197482.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-05 19:20:16,261] Trial 28 finished with value: 38.78402258791313 and parameters: {'colsample_bytree': 0.27866441402387027, 'learning_rate': 0.04335078512654474, 'max_bin': 109042, 'min_child_samples': 47, 'n_estimators': 12593, 'num_leaves': 1181, 'reg_alpha': 1.0063932891944836, 'reg_lambda': 2.944091759044207e-06, 'subsample': 0.24418734190123711}. Best is trial 22 with value: 38.77571707197482.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 28 finished with value: 38.78402258791313 and parameters: {'colsample_bytree': 0.27866441402387027, 'learning_rate': 0.04335078512654474, 'max_bin': 109042, 'min_child_samples': 47, 'n_estimators': 12593, 'num_leaves': 1181, 'reg_alpha': 1.0063932891944836, 'reg_lambda': 2.944091759044207e-06, 'subsample': 0.24418734190123711}. Best is trial 22 with value: 38.77571707197482.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-05 19:20:16,778] Trial 29 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 29 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-05 19:25:21,466] Trial 30 finished with value: 38.77700033992332 and parameters: {'colsample_bytree': 0.2501983822920517, 'learning_rate': 0.04865973844836856, 'max_bin': 106064, 'min_child_samples': 51, 'n_estimators': 10251, 'num_leaves': 1069, 'reg_alpha': 1.2381357578363876, 'reg_lambda': 6.881531768640373e-06, 'subsample': 0.23218708907788213}. Best is trial 22 with value: 38.77571707197482.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 30 finished with value: 38.77700033992332 and parameters: {'colsample_bytree': 0.2501983822920517, 'learning_rate': 0.04865973844836856, 'max_bin': 106064, 'min_child_samples': 51, 'n_estimators': 10251, 'num_leaves': 1069, 'reg_alpha': 1.2381357578363876, 'reg_lambda': 6.881531768640373e-06, 'subsample': 0.23218708907788213}. Best is trial 22 with value: 38.77571707197482.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-05 19:29:59,518] Trial 31 finished with value: 38.77879791896796 and parameters: {'colsample_bytree': 0.2525195208907006, 'learning_rate': 0.04994113729947746, 'max_bin': 106232, 'min_child_samples': 52, 'n_estimators': 10268, 'num_leaves': 1072, 'reg_alpha': 1.2679647923228983, 'reg_lambda': 6.447723169249785e-06, 'subsample': 0.23354287501457863}. Best is trial 22 with value: 38.77571707197482.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 31 finished with value: 38.77879791896796 and parameters: {'colsample_bytree': 0.2525195208907006, 'learning_rate': 0.04994113729947746, 'max_bin': 106232, 'min_child_samples': 52, 'n_estimators': 10268, 'num_leaves': 1072, 'reg_alpha': 1.2679647923228983, 'reg_lambda': 6.447723169249785e-06, 'subsample': 0.23354287501457863}. Best is trial 22 with value: 38.77571707197482.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-05 19:34:54,658] Trial 32 finished with value: 38.78035640778735 and parameters: {'colsample_bytree': 0.26391820647886854, 'learning_rate': 0.043671263460546075, 'max_bin': 100871, 'min_child_samples': 58, 'n_estimators': 10965, 'num_leaves': 981, 'reg_alpha': 1.4656453016850102, 'reg_lambda': 8.525400012089501e-06, 'subsample': 0.22949545883180314}. Best is trial 22 with value: 38.77571707197482.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 32 finished with value: 38.78035640778735 and parameters: {'colsample_bytree': 0.26391820647886854, 'learning_rate': 0.043671263460546075, 'max_bin': 100871, 'min_child_samples': 58, 'n_estimators': 10965, 'num_leaves': 981, 'reg_alpha': 1.4656453016850102, 'reg_lambda': 8.525400012089501e-06, 'subsample': 0.22949545883180314}. Best is trial 22 with value: 38.77571707197482.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-05 19:34:55,230] Trial 33 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 33 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-05 19:34:55,741] Trial 34 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 34 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-05 19:39:51,161] Trial 35 finished with value: 38.78037230366741 and parameters: {'colsample_bytree': 0.30934949146062946, 'learning_rate': 0.04611307390070325, 'max_bin': 110810, 'min_child_samples': 44, 'n_estimators': 9561, 'num_leaves': 1094, 'reg_alpha': 1.2797332875400034, 'reg_lambda': 6.93511671255023e-06, 'subsample': 0.23699739970978353}. Best is trial 22 with value: 38.77571707197482.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 35 finished with value: 38.78037230366741 and parameters: {'colsample_bytree': 0.30934949146062946, 'learning_rate': 0.04611307390070325, 'max_bin': 110810, 'min_child_samples': 44, 'n_estimators': 9561, 'num_leaves': 1094, 'reg_alpha': 1.2797332875400034, 'reg_lambda': 6.93511671255023e-06, 'subsample': 0.23699739970978353}. Best is trial 22 with value: 38.77571707197482.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-05 19:39:51,714] Trial 36 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 36 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-05 19:39:52,171] Trial 37 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 37 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-05 19:39:52,741] Trial 38 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 38 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-05 19:39:53,234] Trial 39 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 39 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-05 19:44:52,404] Trial 40 finished with value: 38.77616724387327 and parameters: {'colsample_bytree': 0.25621717927551, 'learning_rate': 0.045694832614546224, 'max_bin': 102634, 'min_child_samples': 48, 'n_estimators': 9064, 'num_leaves': 1020, 'reg_alpha': 1.496825925427169, 'reg_lambda': 3.879622193254907e-06, 'subsample': 0.22999915374867344}. Best is trial 22 with value: 38.77571707197482.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 40 finished with value: 38.77616724387327 and parameters: {'colsample_bytree': 0.25621717927551, 'learning_rate': 0.045694832614546224, 'max_bin': 102634, 'min_child_samples': 48, 'n_estimators': 9064, 'num_leaves': 1020, 'reg_alpha': 1.496825925427169, 'reg_lambda': 3.879622193254907e-06, 'subsample': 0.22999915374867344}. Best is trial 22 with value: 38.77571707197482.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-05 19:49:18,377] Trial 41 finished with value: 38.77982964250903 and parameters: {'colsample_bytree': 0.25547042703991574, 'learning_rate': 0.0472171036062315, 'max_bin': 102706, 'min_child_samples': 48, 'n_estimators': 9001, 'num_leaves': 1026, 'reg_alpha': 1.3764090399674478, 'reg_lambda': 3.926089357959556e-06, 'subsample': 0.23077461145590197}. Best is trial 22 with value: 38.77571707197482.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 41 finished with value: 38.77982964250903 and parameters: {'colsample_bytree': 0.25547042703991574, 'learning_rate': 0.0472171036062315, 'max_bin': 102706, 'min_child_samples': 48, 'n_estimators': 9001, 'num_leaves': 1026, 'reg_alpha': 1.3764090399674478, 'reg_lambda': 3.926089357959556e-06, 'subsample': 0.23077461145590197}. Best is trial 22 with value: 38.77571707197482.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-05 19:49:18,929] Trial 42 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 42 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-05 19:54:25,561] Trial 43 finished with value: 38.77638534070512 and parameters: {'colsample_bytree': 0.29100014288305043, 'learning_rate': 0.04970607302761643, 'max_bin': 100367, 'min_child_samples': 51, 'n_estimators': 9404, 'num_leaves': 1036, 'reg_alpha': 1.7318418885071472, 'reg_lambda': 3.1708486630529034e-06, 'subsample': 0.22131169127372813}. Best is trial 22 with value: 38.77571707197482.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 43 finished with value: 38.77638534070512 and parameters: {'colsample_bytree': 0.29100014288305043, 'learning_rate': 0.04970607302761643, 'max_bin': 100367, 'min_child_samples': 51, 'n_estimators': 9404, 'num_leaves': 1036, 'reg_alpha': 1.7318418885071472, 'reg_lambda': 3.1708486630529034e-06, 'subsample': 0.22131169127372813}. Best is trial 22 with value: 38.77571707197482.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-05 19:54:33,002] Trial 44 pruned. Trial was pruned at iteration 60.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 44 pruned. Trial was pruned at iteration 60.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-05 19:54:33,448] Trial 45 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 45 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-05 19:54:33,950] Trial 46 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 46 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-05 19:54:34,469] Trial 47 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 47 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-05 19:54:34,947] Trial 48 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 48 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-05 19:54:35,464] Trial 49 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 49 pruned. Trial was pruned at iteration 0.\n"
     ]
    }
   ],
   "source": [
    "def objective(trial):    \n",
    "    # Define the hyperparameter search space\n",
    "    param = {\n",
    "        'objective': 'regression',\n",
    "        'metric': 'rmse',\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.25, .35),\n",
    "        'learning_rate': trial.suggest_loguniform('learning_rate', .01, 0.05),\n",
    "        'max_bin': trial.suggest_int('max_bin', 100000, 130000),\n",
    "        'max_depth': 10,\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 40, 80),\n",
    "        'min_split_gain': 0.5,\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 9000, 15000),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 900, 1200),\n",
    "        'reg_alpha': trial.suggest_loguniform('reg_alpha', 0.5, 2.0),\n",
    "        'reg_lambda': trial.suggest_loguniform('reg_lambda', 0.000001, 0.00001),\n",
    "        'subsample': trial.suggest_float('subsample', 0.2, 0.25),\n",
    "        'random_state': 42,\n",
    "        'early_stopping_rounds': 50,\n",
    "        'verbosity': -1,\n",
    "    }\n",
    "    \n",
    "    train_data = lgb.Dataset(X_train, label=y_train)\n",
    "    valid_data = lgb.Dataset(X_valid, label=y_valid, reference=train_data)\n",
    "    \n",
    "    # Initialize the model with these parameters\n",
    "    model = lgb.train(\n",
    "        params=param,\n",
    "        train_set=train_data,\n",
    "        num_boost_round=700,\n",
    "        valid_sets=[train_data, valid_data],\n",
    "        valid_names=['train_0', 'valid_0'],\n",
    "        callbacks=[\n",
    "            LightGBMPruningCallback(trial, \"rmse\", valid_name=\"valid_0\"),\n",
    "            lgb.log_evaluation(-1)                   # Suppress training logs\n",
    "        ]\n",
    "    )\n",
    "    y_pred = model.predict(X_valid, num_iteration=model.best_iteration)\n",
    "    rmse = np.sqrt(mean_squared_error(y_valid, y_pred))    \n",
    "    return rmse\n",
    "\n",
    "optuna.logging.get_logger(\"optuna\").addHandler(logging.StreamHandler(sys.stdout))\n",
    "study_name = datetime.now().strftime(\"%Y-%m-%d_%H-%M\")\n",
    "storage_name = f\"sqlite:///{os.path.join(optuna_dir, study_name)}.db\"\n",
    "study = optuna.create_study(study_name=study_name, storage=storage_name, direction='minimize')\n",
    "study.optimize(objective, n_trials=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):    \n",
    "    # Define the hyperparameter search space\n",
    "    param = {\n",
    "        'objective': 'regression',\n",
    "        'metric': 'rmse',\n",
    "        # 'boosting_type': boosting_type,\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 200, 1000),\n",
    "        'max_depth': trial.suggest_int('max_depth', 1, 20),\n",
    "        'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 0.5),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 50, 5000),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 5, 200),\n",
    "        'subsample': trial.suggest_float('subsample', 0.25, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.25, 1.0),\n",
    "        'max_bin': trial.suggest_int('max_bin', 50, 1000),\n",
    "        'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-8, 10.0),\n",
    "        'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-8, 10.0),\n",
    "        'min_split_gain': trial.suggest_float('min_split_gain', 0.1, 1.0),\n",
    "        'random_state': 42,\n",
    "        'early_stopping_rounds': 50,\n",
    "        'verbosity': -1,\n",
    "    }\n",
    "    \n",
    "    # For the DART boosting type, include dartâ€‘specific parameters.\n",
    "\n",
    "    train_data = lgb.Dataset(X_train, label=y_train)\n",
    "    valid_data = lgb.Dataset(X_valid, label=y_valid, reference=train_data)\n",
    "    \n",
    "    # Initialize the model with these parameters\n",
    "    model = lgb.train(param, train_data, num_boost_round=100, valid_sets=[valid_data])\n",
    "    y_pred = model.predict(X_valid, num_iteration=model.best_iteration)\n",
    "    rmse = np.sqrt(mean_squared_error(y_valid, y_pred))    \n",
    "    return rmse\n",
    "\n",
    "\n",
    "optuna.logging.get_logger(\"optuna\").addHandler(logging.StreamHandler(sys.stdout))\n",
    "study_name = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "storage_name = f\"sqlite:///{os.path.join(optuna_dir, study_name)}.db\"\n",
    "study = optuna.create_study(study_name=study_name, storage=storage_name, direction='minimize')\n",
    "study.optimize(objective, n_trials=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):    \n",
    "    # Define the hyperparameter search space\n",
    "    param = {\n",
    "        'objective': 'regression',\n",
    "        'metric': 'rmse',\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 500, 1500),\n",
    "        'max_depth': trial.suggest_int('max_depth', 6, 40),\n",
    "        'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.5),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 50, 10000),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 5, 300),\n",
    "        'subsample': trial.suggest_float('subsample', 0.05, .5),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.15, .5),\n",
    "        'max_bin': trial.suggest_int('max_bin', 500, 10000),\n",
    "        'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-8, 1.0),\n",
    "        'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-8, 1.0),\n",
    "        'min_split_gain': trial.suggest_float('min_split_gain', 0.4, 0.6),\n",
    "        'random_state': 42,\n",
    "        'early_stopping_rounds': 50,\n",
    "        'verbosity': -1,\n",
    "    }\n",
    "    \n",
    "    train_data = lgb.Dataset(X_train, label=y_train)\n",
    "    valid_data = lgb.Dataset(X_valid, label=y_valid, reference=train_data)\n",
    "    \n",
    "    # Initialize the model with these parameters\n",
    "    model = lgb.train(param, train_data, num_boost_round=200, valid_sets=[valid_data])\n",
    "    y_pred = model.predict(X_valid, num_iteration=model.best_iteration)\n",
    "    rmse = np.sqrt(mean_squared_error(y_valid, y_pred))    \n",
    "    return rmse\n",
    "\n",
    "optuna.logging.get_logger(\"optuna\").addHandler(logging.StreamHandler(sys.stdout))\n",
    "study_name = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "storage_name = f\"sqlite:///{os.path.join(optuna_dir, study_name)}.db\"\n",
    "study = optuna.create_study(study_name=study_name, storage=storage_name, direction='minimize')\n",
    "study.optimize(objective, n_trials=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):    \n",
    "    # Define the hyperparameter search space\n",
    "    param = {\n",
    "        'objective': 'regression',\n",
    "        'metric': 'rmse',\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 400, 2000),\n",
    "        'max_depth': trial.suggest_int('max_depth', 6, 12),\n",
    "        'learning_rate': trial.suggest_loguniform('learning_rate', .05, 0.15),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 4000, 20000),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 100, 300),\n",
    "        'subsample': trial.suggest_float('subsample', 0.15, .25),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.25, .35),\n",
    "        'max_bin': trial.suggest_int('max_bin', 500, 50000),\n",
    "        'reg_alpha': trial.suggest_loguniform('reg_alpha', 0.01, 1.0),\n",
    "        'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-8, .05),\n",
    "        'min_split_gain': trial.suggest_float('min_split_gain', 0.5, 0.55),\n",
    "        'random_state': 42,\n",
    "        'early_stopping_rounds': 50,\n",
    "        'verbosity': -1,\n",
    "    }\n",
    "    \n",
    "    train_data = lgb.Dataset(X_train, label=y_train)\n",
    "    valid_data = lgb.Dataset(X_valid, label=y_valid, reference=train_data)\n",
    "    \n",
    "    # Initialize the model with these parameters\n",
    "    model = lgb.train(param, train_data, num_boost_round=300, valid_sets=[valid_data])\n",
    "    y_pred = model.predict(X_valid, num_iteration=model.best_iteration)\n",
    "    rmse = np.sqrt(mean_squared_error(y_valid, y_pred))    \n",
    "    return rmse\n",
    "\n",
    "optuna.logging.get_logger(\"optuna\").addHandler(logging.StreamHandler(sys.stdout))\n",
    "study_name = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "storage_name = f\"sqlite:///{os.path.join(optuna_dir, study_name)}.db\"\n",
    "study = optuna.create_study(study_name=study_name, storage=storage_name, direction='minimize')\n",
    "study.optimize(objective, n_trials=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):    \n",
    "    # Define the hyperparameter search space\n",
    "    param = {\n",
    "        'objective': 'regression',\n",
    "        'metric': 'rmse',\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 400, 2000),\n",
    "        'max_depth': trial.suggest_int('max_depth', 6, 12),\n",
    "        'learning_rate': trial.suggest_loguniform('learning_rate', .05, 0.15),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 4000, 20000),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 20, 200),\n",
    "        'subsample': trial.suggest_float('subsample', 0.15, .25),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.25, .35),\n",
    "        'max_bin': trial.suggest_int('max_bin', 50000, 200000),\n",
    "        'reg_alpha': trial.suggest_loguniform('reg_alpha', 0.01, 1.0),\n",
    "        'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-8, .05),\n",
    "        'min_split_gain': trial.suggest_float('min_split_gain', 0.5, 0.55),\n",
    "        'random_state': 42,\n",
    "        'early_stopping_rounds': 50,\n",
    "        'verbosity': -1,\n",
    "    }\n",
    "    \n",
    "    train_data = lgb.Dataset(X_train, label=y_train)\n",
    "    valid_data = lgb.Dataset(X_valid, label=y_valid, reference=train_data)\n",
    "    \n",
    "    # Initialize the model with these parameters\n",
    "    model = lgb.train(param, train_data, num_boost_round=300, valid_sets=[valid_data])\n",
    "    y_pred = model.predict(X_valid, num_iteration=model.best_iteration)\n",
    "    rmse = np.sqrt(mean_squared_error(y_valid, y_pred))    \n",
    "    return rmse\n",
    "\n",
    "optuna.logging.get_logger(\"optuna\").addHandler(logging.StreamHandler(sys.stdout))\n",
    "study_name = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "storage_name = f\"sqlite:///{os.path.join(optuna_dir, study_name)}.db\"\n",
    "study = optuna.create_study(study_name=study_name, storage=storage_name, direction='minimize')\n",
    "study.optimize(objective, n_trials=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best trial:\")\n",
    "best_trial = study.best_trial\n",
    "print(\"  RMSE: {:.4f}\".format(best_trial.value))\n",
    "print(\"  Best hyperparameters:\")\n",
    "for key, value in best_trial.params.items():\n",
    "    print(\"    '{}': {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):    \n",
    "    # Define the hyperparameter search space\n",
    "    param = {\n",
    "        'objective': 'regression',\n",
    "        'metric': 'rmse',\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.25, .35),\n",
    "        'learning_rate': trial.suggest_loguniform('learning_rate', .005, 0.15),\n",
    "        'max_bin': trial.suggest_int('max_bin', 100000, 150000),\n",
    "        'max_depth': trial.suggest_int('max_depth', 8, 11),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 30, 70),\n",
    "        'min_split_gain': trial.suggest_float('min_split_gain', 0.5, 0.55),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 8000, 15000),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 1000, 1500),\n",
    "        'reg_alpha': trial.suggest_loguniform('reg_alpha', 0.1, 2.0),\n",
    "        'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-8, .05),\n",
    "        'subsample': trial.suggest_float('subsample', 0.2, 0.3),\n",
    "        'random_state': 42,\n",
    "        'early_stopping_rounds': 50,\n",
    "        'verbosity': -1,\n",
    "    }\n",
    "    \n",
    "    train_data = lgb.Dataset(X_train, label=y_train)\n",
    "    valid_data = lgb.Dataset(X_valid, label=y_valid, reference=train_data)\n",
    "    \n",
    "    # Initialize the model with these parameters\n",
    "    model = lgb.train(param, train_data, num_boost_round=400, valid_sets=[valid_data])\n",
    "    y_pred = model.predict(X_valid, num_iteration=model.best_iteration)\n",
    "    rmse = np.sqrt(mean_squared_error(y_valid, y_pred))    \n",
    "    return rmse\n",
    "\n",
    "optuna.logging.get_logger(\"optuna\").addHandler(logging.StreamHandler(sys.stdout))\n",
    "study_name = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "storage_name = f\"sqlite:///{os.path.join(optuna_dir, study_name)}.db\"\n",
    "study = optuna.create_study(study_name=study_name, storage=storage_name, direction='minimize')\n",
    "study.optimize(objective, n_trials=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):    \n",
    "    # Define the hyperparameter search space\n",
    "    param = {\n",
    "        'objective': 'regression',\n",
    "        'metric': 'rmse',\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.25, .35),\n",
    "        'learning_rate': trial.suggest_loguniform('learning_rate', .0005, 0.15),\n",
    "        'max_bin': trial.suggest_int('max_bin', 100000, 150000),\n",
    "        'max_depth': trial.suggest_int('max_depth', 8, 11),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 10, 70),\n",
    "        'min_split_gain': trial.suggest_float('min_split_gain', 0.5, 0.55),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 8000, 15000),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 1000, 1500),\n",
    "        'reg_alpha': trial.suggest_loguniform('reg_alpha', 0.1, 2.0),\n",
    "        'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-8, .05),\n",
    "        'subsample': trial.suggest_float('subsample', 0.2, 0.3),\n",
    "        'random_state': 42,\n",
    "        'early_stopping_rounds': 50,\n",
    "        'verbosity': -1,\n",
    "    }\n",
    "    \n",
    "    train_data = lgb.Dataset(X_train, label=y_train)\n",
    "    valid_data = lgb.Dataset(X_valid, label=y_valid, reference=train_data)\n",
    "    \n",
    "    # Initialize the model with these parameters\n",
    "    model = lgb.train(param, train_data, num_boost_round=500, valid_sets=[valid_data])\n",
    "    y_pred = model.predict(X_valid, num_iteration=model.best_iteration)\n",
    "    rmse = np.sqrt(mean_squared_error(y_valid, y_pred))    \n",
    "    return rmse\n",
    "\n",
    "optuna.logging.get_logger(\"optuna\").addHandler(logging.StreamHandler(sys.stdout))\n",
    "study_name = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "storage_name = f\"sqlite:///{os.path.join(optuna_dir, study_name)}.db\"\n",
    "study = optuna.create_study(study_name=study_name, storage=storage_name, direction='minimize')\n",
    "study.optimize(objective, n_trials=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Older stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    param = {\n",
    "        'objective': 'regression',\n",
    "        'metric': 'rmse',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'random_state': 42,\n",
    "        # Narrowed ranges for faster convergence (you can tweak these)\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 3, 512),\n",
    "        'max_depth': trial.suggest_int('max_depth', 1, 16),\n",
    "        'learning_rate': trial.suggest_loguniform('learning_rate', 1e-2, 0.5),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "        'max_bin': trial.suggest_int('max_bin', 63, 1011),\n",
    "        'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-8, 1.0),\n",
    "        'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-8, 1.0),\n",
    "        'min_split_gain': trial.suggest_float('min_split_gain', 0.0, 1.0),\n",
    "        'early_stopping_rounds': 50,\n",
    "        'verbosity': -1,\n",
    "    }\n",
    "    train_data = lgb.Dataset(X_train, label=y_train)\n",
    "    valid_data = lgb.Dataset(X_valid, label=y_valid)\n",
    "    \n",
    "    gbm = lgb.train(\n",
    "        params=param,\n",
    "        train_set=train_data,\n",
    "        num_boost_round=500,\n",
    "        valid_sets=[train_data, valid_data],\n",
    "        valid_names=['train_0', 'valid_0'],\n",
    "        callbacks=[\n",
    "            LightGBMPruningCallback(trial, \"rmse\", valid_name=\"valid_0\"),\n",
    "            lgb.log_evaluation(-1)                   # Suppress training logs\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    preds = gbm.predict(X_valid, num_iteration=gbm.best_iteration)\n",
    "    rmse = np.sqrt(mean_squared_error(y_valid, preds))\n",
    "    \n",
    "    return rmse\n",
    "\n",
    "# 6. Create and run the study\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study.trials_dataframe().sort_values(by='value').head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study.trials_dataframe().sort_values(by='value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):    \n",
    "    # Define the hyperparameter search space\n",
    "    param = {\n",
    "        'objective': 'regression',\n",
    "        'metric': 'rmse',\n",
    "        # 'boosting_type': boosting_type,\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 200, 1000),\n",
    "        'max_depth': trial.suggest_int('max_depth', 1, 20),\n",
    "        'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 0.5),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 50, 5000),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 5, 200),\n",
    "        'subsample': trial.suggest_float('subsample', 0.25, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.25, 1.0),\n",
    "        'max_bin': trial.suggest_int('max_bin', 50, 1000),\n",
    "        'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-8, 10.0),\n",
    "        'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-8, 10.0),\n",
    "        'min_split_gain': trial.suggest_float('min_split_gain', 0.1, 1.0),\n",
    "        'random_state': 42,\n",
    "        'early_stopping_rounds': 50,\n",
    "        'verbosity': -1,\n",
    "    }\n",
    "    \n",
    "    # For the DART boosting type, include dartâ€‘specific parameters.\n",
    "\n",
    "    train_data = lgb.Dataset(X_train, label=y_train)\n",
    "    valid_data = lgb.Dataset(X_valid, label=y_valid, reference=train_data)\n",
    "    \n",
    "    # Initialize the model with these parameters\n",
    "    model = lgb.train(param, train_data, num_boost_round=100, valid_sets=[valid_data])\n",
    "    y_pred = model.predict(X_valid, num_iteration=model.best_iteration)\n",
    "    rmse = np.sqrt(mean_squared_error(y_valid, y_pred))    \n",
    "    return rmse\n",
    "\n",
    "\n",
    "study_1 = optuna.create_study(direction='minimize')\n",
    "study_1.optimize(objective, n_trials=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study.trials_dataframe().sort_values(by='value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):    \n",
    "    # Define the hyperparameter search space\n",
    "    param = {\n",
    "        'objective': 'regression',\n",
    "        'metric': 'rmse',\n",
    "        # 'boosting_type': boosting_type,\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 200, 1000),\n",
    "        'max_depth': trial.suggest_int('max_depth', 1, 20),\n",
    "        'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 0.5),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 50, 5000),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 5, 200),\n",
    "        'subsample': trial.suggest_float('subsample', 0.25, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.25, 1.0),\n",
    "        'max_bin': trial.suggest_int('max_bin', 50, 1000),\n",
    "        'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-8, 10.0),\n",
    "        'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-8, 10.0),\n",
    "        'min_split_gain': trial.suggest_float('min_split_gain', 0.1, 1.0),\n",
    "        'random_state': 42,\n",
    "        'early_stopping_rounds': 50,\n",
    "        'verbosity': -1,\n",
    "    }\n",
    "    \n",
    "    # For the DART boosting type, include dartâ€‘specific parameters.\n",
    "\n",
    "    train_data = lgb.Dataset(X_train, label=y_train)\n",
    "    valid_data = lgb.Dataset(X_valid, label=y_valid, reference=train_data)\n",
    "    \n",
    "    # Initialize the model with these parameters\n",
    "    model = lgb.train(param, train_data, num_boost_round=100, valid_sets=[valid_data])\n",
    "    y_pred = model.predict(X_valid, num_iteration=model.best_iteration)\n",
    "    rmse = np.sqrt(mean_squared_error(y_valid, y_pred))    \n",
    "    return rmse\n",
    "\n",
    "\n",
    "study_1 = optuna.create_study(direction='minimize')\n",
    "study_1.optimize(objective, n_trials=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study_1.trials_dataframe().sort_values(by='value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best trial:\")\n",
    "best_trial = study_1.best_trial\n",
    "print(\"  RMSE: {:.4f}\".format(best_trial.value))\n",
    "print(\"  Best hyperparameters:\")\n",
    "for key, value in best_trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
