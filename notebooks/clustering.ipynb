{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import skew, chisquare, kruskal, ks_2samp, chi2_contingency\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.cluster import MiniBatchKMeans, AffinityPropagation\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "from sklearn.model_selection import KFold, cross_val_predict\n",
    "from sklearn.metrics import mean_squared_error, roc_auc_score\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OrdinalEncoder, FunctionTransformer\n",
    "import lightgbm as lgb\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "test_df = pd.read_csv(r'..//data//test.csv')\n",
    "train_df = pd.read_csv(r'..//data//train.csv')\n",
    "# train_extra_df = pd.read_csv(r'..//data//training_extra.csv')\n",
    "# train_df = pd.concat([train_df, train_extra_df], ignore_index=True)\n",
    "\n",
    "\n",
    "target = 'price'\n",
    "\n",
    "def prepare_data(df: pd.DataFrame, is_train: bool = True):\n",
    "    \"\"\"\n",
    "    Prepares the dataset for training or testing by renaming columns, handling missing values,\n",
    "    converting categorical and numerical features, and creating new features.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): The input dataframe (train or test).\n",
    "        is_train (bool): Indicates if the dataframe is training data (default is True).\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: The processed dataframe.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define the column names\n",
    "    columns = [\n",
    "        'id', 'brand', 'material', 'size', 'compartments', \n",
    "        'laptop_compartment', 'is_waterproof', 'style', 'color', \n",
    "        'weight_capacity'\n",
    "    ]\n",
    "    \n",
    "    if is_train:\n",
    "        columns.append('price')\n",
    "    \n",
    "    df.columns = columns\n",
    "    df = df.drop(columns='id')\n",
    "    \n",
    "    # Define the mapping for Size conversion\n",
    "    size_mapping = {\"Small\": 1, \"Medium\": 2, \"Large\": 3}\n",
    "    df[\"size_int\"] = df[\"size\"].map(size_mapping).fillna(0).astype(int)\n",
    "    \n",
    "    # Handle weight capacity\n",
    "    df['weight_capacity'] = df['weight_capacity'].fillna(0)\n",
    "    df['weight_capacity_int'] = df['weight_capacity'].astype(int)\n",
    "    df['weight_capacity_size'] = df['weight_capacity'] * df['size_int']\n",
    "    \n",
    "    # Convert categorical columns\n",
    "    df['compartments'] = df['compartments'].astype('category')\n",
    "    cat_cols = df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "    df[cat_cols] = df[cat_cols].astype('category')\n",
    "    \n",
    "    # Convert boolean columns to integer type\n",
    "    df['laptop_compartment'] = df['laptop_compartment'].cat.codes.fillna(-1).astype(int)\n",
    "    df['is_waterproof'] = df['is_waterproof'].cat.codes.fillna(-1).astype(int)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Apply function to train and test datasets\n",
    "train_df = prepare_data(train_df, is_train=True)\n",
    "test_df = prepare_data(test_df, is_train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_features = [\n",
    "    'weight_capacity', 'weight_capacity_int', 'weight_capacity_size', 'size_int', 'color', 'compartments', 'brand', 'material', 'is_waterproof'\n",
    "]\n",
    "numeric_cols = ['weight_capacity', 'weight_capacity_int', 'weight_capacity_size', 'size_int', 'is_waterproof']\n",
    "cat_cols = ['brand', 'material', 'compartments', 'color']\n",
    "\n",
    "numeric_transformer = Pipeline(\n",
    "    steps=[('scaler', StandardScaler())]\n",
    ")\n",
    "\n",
    "categorical_transformer = Pipeline(\n",
    "    steps=[('onehot', OneHotEncoder(handle_unknown='ignore', drop=None))]\n",
    ")\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_cols),\n",
    "        ('cat', categorical_transformer, cat_cols)\n",
    "    ],\n",
    "    remainder='drop'  # drop other columns not listed\n",
    ")\n",
    "\n",
    "X = train_df[model_features].copy()\n",
    "y = train_df[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MiniBatchKMeans Training & Prediction time: 0.83 seconds\n",
      "MiniBatchKMeans cluster counts:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>70538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>68946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>55846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>54823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>49847</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  count\n",
       "0      4  70538\n",
       "1      2  68946\n",
       "2      1  55846\n",
       "3      3  54823\n",
       "4      0  49847"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### MiniBatchKMeans\n",
    "model_start_time = time.time()\n",
    "kmeans_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        ('preprocessing', preprocessor),\n",
    "        ('clusterer', MiniBatchKMeans(n_clusters=5, random_state=42))\n",
    "    ]\n",
    ")\n",
    "\n",
    "kmeans_pipeline.fit(X)\n",
    "kmeans_labels = kmeans_pipeline.named_steps['clusterer'].labels_\n",
    "train_df['cluster'] = kmeans_labels\n",
    "print(f\"MiniBatchKMeans Training & Prediction time: {time.time() - model_start_time:.2f} seconds\")\n",
    "\n",
    "print(\"MiniBatchKMeans cluster counts:\")\n",
    "display(pd.Series(kmeans_labels).value_counts().reset_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_clusters(cluster_labels_dict, X, y, kf, verbose=True):\n",
    "    # LightGBM parameters\n",
    "    params = {\n",
    "        'objective': 'regression',\n",
    "        'metric': 'rmse',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'num_leaves': 31,\n",
    "        'learning_rate': 0.05,\n",
    "        'feature_fraction': 0.9,\n",
    "        'verbose': -1,\n",
    "        'force_row_wise': True\n",
    "    }\n",
    "\n",
    "    # This will store, for each clustering method, the RMSEs per model across folds\n",
    "    all_results = {}\n",
    "    # X = train_df[['cluster'] + model_features].copy()\n",
    "    \n",
    "    # Prepare a dict to accumulate fold RMSE scores for each model\n",
    "    model_scores = {name: [] for name in cluster_labels_dict.keys()}\n",
    "\n",
    "    # K-fold cross validation\n",
    "    for fold, (train_index, valid_index) in enumerate(kf.split(train_df), start=1):\n",
    "\n",
    "        X_train, X_valid = X.iloc[train_index], X.iloc[valid_index]\n",
    "        y_train, y_valid = y.iloc[train_index], y.iloc[valid_index]\n",
    "        \n",
    "        # Loop over each clustering method and its cluster labels\n",
    "        for method_name, n_clusters in cluster_labels_dict.items():\n",
    "\n",
    "            if n_clusters == 1:\n",
    "                X_train['cluster'] = 0\n",
    "                X_valid['cluster'] = 0\n",
    "            else:\n",
    "                kmeans_pipeline = Pipeline(\n",
    "                    steps=[\n",
    "                        ('preprocessing', preprocessor),\n",
    "                        ('clusterer', MiniBatchKMeans(n_clusters=n_clusters, random_state=42))\n",
    "                    ]\n",
    "                )\n",
    "                \n",
    "                kmeans_pipeline.fit(X_train)\n",
    "                kmeans_labels = kmeans_pipeline.named_steps['clusterer'].labels_\n",
    "                X_train['cluster'] = kmeans_labels\n",
    "                X_valid['cluster'] = kmeans_pipeline.predict(X_valid)\n",
    "\n",
    "            y_pred_valid = y_valid.reset_index()\n",
    "            y_pred_valid.loc[:, 'y_pred'] = 0\n",
    "            y_pred_valid = y_pred_valid.set_index('index')\n",
    "    \n",
    "            # Train a separate model for each cluster\n",
    "            for c in range(n_clusters):\n",
    "                train_cluster = X_train[X_train.cluster == c].copy()\n",
    "                val_cluster = X_valid[X_valid.cluster == c].copy()\n",
    "                \n",
    "                train_data = lgb.Dataset(train_cluster[model_features], \n",
    "                                         label=y_train[X_train.cluster == c])\n",
    "    \n",
    "                fit_model = lgb.train(\n",
    "                    params,\n",
    "                    train_data,\n",
    "                    num_boost_round=100,\n",
    "                    valid_sets=[train_data],\n",
    "                )\n",
    "                \n",
    "                y_pred_valid.loc[X_valid.cluster == c, 'y_pred'] = fit_model.predict(val_cluster[model_features], num_iteration=fit_model.best_iteration)\n",
    "    \n",
    "            # Calculate RMSE for this model across all validation samples\n",
    "            rmse = np.sqrt(mean_squared_error(y_valid, y_pred_valid['y_pred']))\n",
    "            model_scores[method_name].append(rmse)\n",
    "\n",
    "        # Summarize scores for this method\n",
    "        df_scores = pd.DataFrame(model_scores)\n",
    "        all_results[method_name] = df_scores\n",
    "\n",
    "    return all_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KMeans per-fold RMSE:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>baseline</th>\n",
       "      <th>kmeans_2</th>\n",
       "      <th>kmeans_3</th>\n",
       "      <th>kmeans_4</th>\n",
       "      <th>kmeans_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>38.913</td>\n",
       "      <td>38.927</td>\n",
       "      <td>38.933</td>\n",
       "      <td>38.954</td>\n",
       "      <td>38.968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39.040</td>\n",
       "      <td>39.057</td>\n",
       "      <td>39.064</td>\n",
       "      <td>39.064</td>\n",
       "      <td>39.078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39.016</td>\n",
       "      <td>39.022</td>\n",
       "      <td>39.038</td>\n",
       "      <td>39.052</td>\n",
       "      <td>39.080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>39.062</td>\n",
       "      <td>39.070</td>\n",
       "      <td>39.082</td>\n",
       "      <td>39.086</td>\n",
       "      <td>39.097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>39.003</td>\n",
       "      <td>39.010</td>\n",
       "      <td>39.024</td>\n",
       "      <td>39.029</td>\n",
       "      <td>39.046</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   baseline  kmeans_2  kmeans_3  kmeans_4  kmeans_5\n",
       "0    38.913    38.927    38.933    38.954    38.968\n",
       "1    39.040    39.057    39.064    39.064    39.078\n",
       "2    39.016    39.022    39.038    39.052    39.080\n",
       "3    39.062    39.070    39.082    39.086    39.097\n",
       "4    39.003    39.010    39.024    39.029    39.046"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean RMSE</th>\n",
       "      <th>Std RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>baseline</th>\n",
       "      <td>39.007</td>\n",
       "      <td>0.057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kmeans_2</th>\n",
       "      <td>39.017</td>\n",
       "      <td>0.056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kmeans_3</th>\n",
       "      <td>39.028</td>\n",
       "      <td>0.058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kmeans_4</th>\n",
       "      <td>39.037</td>\n",
       "      <td>0.051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kmeans_5</th>\n",
       "      <td>39.054</td>\n",
       "      <td>0.051</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Mean RMSE  Std RMSE\n",
       "baseline     39.007     0.057\n",
       "kmeans_2     39.017     0.056\n",
       "kmeans_3     39.028     0.058\n",
       "kmeans_4     39.037     0.051\n",
       "kmeans_5     39.054     0.051"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_labels_dict = {\n",
    "    \"baseline\": 1,\n",
    "    \"kmeans_2\": 2,\n",
    "    \"kmeans_3\": 3,\n",
    "    \"kmeans_4\": 4,\n",
    "    \"kmeans_5\": 5,\n",
    "}\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cluster_cv_results = cv_clusters(cluster_labels_dict, X, y, kf, verbose=True)\n",
    "\n",
    "# Inspect results\n",
    "result_kmeans = cluster_cv_results[\"kmeans_5\"]\n",
    "print(\"KMeans per-fold RMSE:\")\n",
    "# display(result_kmeans.round(3))\n",
    "\n",
    "# Summarize\n",
    "summary_kmeans = pd.DataFrame({\n",
    "    \"Mean RMSE\": result_kmeans.mean(),\n",
    "    \"Std RMSE\": result_kmeans.std()\n",
    "})\n",
    "summary_kmeans.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import skew, chisquare, kruskal, ks_2samp, chi2_contingency\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import KFold, cross_val_predict\n",
    "from sklearn.metrics import mean_squared_error, roc_auc_score\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OrdinalEncoder, FunctionTransformer\n",
    "import lightgbm as lgb\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
