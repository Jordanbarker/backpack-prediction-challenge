{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from backpack_predictor import prepare_data, target_encoding\n",
    "from backpack_predictor.features import target, baseline_features, feature_list, cat_cols\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from datetime import datetime\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import skew, chisquare, kruskal, ks_2samp, chi2_contingency\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "from sklearn.preprocessing import TargetEncoder\n",
    "\n",
    "# import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "from optuna.integration import LightGBMPruningCallback #XGBoostPruningCallback, CatBoostPruningCallback\n",
    "import optuna\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "test_df = pd.read_csv(r'..//data//test.csv')\n",
    "train_df = pd.read_csv(r'..//data//train.csv')\n",
    "train_extra_df = pd.read_csv(r'..//data//training_extra.csv')\n",
    "train_df = pd.concat([train_df, train_extra_df], ignore_index=True)\n",
    "\n",
    "\n",
    "# Apply function to train and test datasets\n",
    "train_df = prepare_data(train_df, is_train=True)\n",
    "test_df = prepare_data(test_df, is_train=False)\n",
    "\n",
    "X = train_df.drop(target, axis=1)\n",
    "y = train_df[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_list = ['weight_capacity_te', 'brand', 'material', 'size', 'compartments', 'style', 'color', 'laptop_compartment', 'is_waterproof']\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "data_splits = []\n",
    "\n",
    "for train_index, val_index in kf.split(train_df):\n",
    "    train_fold = train_df.iloc[train_index]\n",
    "    val_fold = train_df.iloc[val_index]\n",
    "\n",
    "    te = TargetEncoder(target_type=\"continuous\", smooth=20)\n",
    "    train_fold[\"weight_capacity_te\"] = te.fit_transform(train_fold[[\"weight_capacity\"]], train_fold[target])\n",
    "    val_fold[\"weight_capacity_te\"] = te.transform(val_fold[[\"weight_capacity\"]])\n",
    "\n",
    "    data_splits.append((train_fold, val_fold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kf = KFold(n_splits=3, shuffle=True, random_state=42)\n",
    "# data_splits = []\n",
    "# for fold, (train_index, test_index) in enumerate(kf.split(X), 1):\n",
    "\n",
    "#     X_train, X_val = X.iloc[train_index], X.iloc[test_index]\n",
    "#     y_train, y_val = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "#     X_train, X_val = preprocess_weight_capacity(pd.concat([X_train, y_train], axis=1), X_val)\n",
    "\n",
    "#     X_train, X_val, encoded_cols = target_encoding(\n",
    "#         train_df=X_train,\n",
    "#         cat_cols=cat_cols,\n",
    "#         test_df=X_val, \n",
    "#         target=y_train.name,\n",
    "#     )\n",
    "#     # X_train = X_train.drop(columns=[target])\n",
    "\n",
    "#     data_splits.append(\n",
    "#         (X_train, \n",
    "#         pd.concat([X_val[feature_list], y_val], axis=1))\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_str = \"lgb_\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-12 21:32:05,301] A new study created in RDB with name: lgb_2025-02-12_21-32\n",
      "[I 2025-02-12 21:38:30,224] Trial 0 finished with value: 38.694235802529505 and parameters: {'bagging_fraction': 0.9306369493105067, 'bagging_freq': 2, 'cat_l2': 7.551697000677804, 'extra_trees': False, 'feature_fraction': 0.6363095671758482, 'learning_rate': 0.018435740816804796, 'max_bin': 8697, 'max_depth': 253, 'min_samples_leaf': 15, 'n_estimators': 1064, 'num_leaves': 95, 'lambda_l1': 0.00010146408836271889, 'lambda_l2': 0.012296089820832188}. Best is trial 0 with value: 38.694235802529505.\n",
      "[I 2025-02-12 21:53:56,834] Trial 1 finished with value: 38.69821606950014 and parameters: {'bagging_fraction': 0.8294174481548935, 'bagging_freq': 1, 'cat_l2': 19.108688738550878, 'extra_trees': True, 'feature_fraction': 0.6980397808259541, 'learning_rate': 0.0192275349554815, 'max_bin': 5903, 'max_depth': 752, 'min_samples_leaf': 51, 'n_estimators': 1458, 'num_leaves': 134, 'lambda_l1': 0.033296097120800325, 'lambda_l2': 3.0993284839561875e-08}. Best is trial 0 with value: 38.694235802529505.\n",
      "[I 2025-02-12 21:56:09,303] Trial 2 finished with value: 38.69527560217002 and parameters: {'bagging_fraction': 0.9957311475300017, 'bagging_freq': 1, 'cat_l2': 15.24972533263119, 'extra_trees': False, 'feature_fraction': 0.752994637961745, 'learning_rate': 0.040800208846512726, 'max_bin': 2556, 'max_depth': 330, 'min_samples_leaf': 87, 'n_estimators': 6375, 'num_leaves': 117, 'lambda_l1': 1.753011463297257e-07, 'lambda_l2': 0.07199053179472242}. Best is trial 0 with value: 38.694235802529505.\n",
      "[I 2025-02-12 22:02:06,930] Trial 3 finished with value: 38.70768685732144 and parameters: {'bagging_fraction': 0.531073697101178, 'bagging_freq': 4, 'cat_l2': 9.41299647840886, 'extra_trees': True, 'feature_fraction': 0.46335828579567107, 'learning_rate': 0.022454196874719414, 'max_bin': 6037, 'max_depth': 520, 'min_samples_leaf': 12, 'n_estimators': 824, 'num_leaves': 82, 'lambda_l1': 0.005933038696504052, 'lambda_l2': 0.00012279900675471765}. Best is trial 0 with value: 38.694235802529505.\n",
      "[I 2025-02-12 22:06:26,343] Trial 4 finished with value: 38.69532510821411 and parameters: {'bagging_fraction': 0.5108681512401111, 'bagging_freq': 4, 'cat_l2': 4.788128641057206, 'extra_trees': False, 'feature_fraction': 0.7624557404673362, 'learning_rate': 0.020057916503784672, 'max_bin': 1365, 'max_depth': 481, 'min_samples_leaf': 100, 'n_estimators': 416, 'num_leaves': 139, 'lambda_l1': 1.4798971124632962e-06, 'lambda_l2': 4.531170009634348e-08}. Best is trial 0 with value: 38.694235802529505.\n",
      "[I 2025-02-12 22:06:27,302] Trial 5 pruned. Trial was pruned at iteration 2.\n",
      "[I 2025-02-12 22:06:27,860] Trial 6 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 22:06:28,524] Trial 7 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 22:06:40,833] Trial 8 pruned. Trial was pruned at iteration 102.\n",
      "[I 2025-02-12 22:06:41,345] Trial 9 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 22:06:53,986] Trial 10 pruned. Trial was pruned at iteration 196.\n",
      "[I 2025-02-12 22:09:00,463] Trial 11 finished with value: 38.69493942946366 and parameters: {'bagging_fraction': 0.9886399597766999, 'bagging_freq': 1, 'cat_l2': 14.855928096294184, 'extra_trees': False, 'feature_fraction': 0.6215682778321279, 'learning_rate': 0.04544319060309038, 'max_bin': 3788, 'max_depth': 278, 'min_samples_leaf': 93, 'n_estimators': 9534, 'num_leaves': 77, 'lambda_l1': 9.867108301046828, 'lambda_l2': 0.2717297018288516}. Best is trial 0 with value: 38.694235802529505.\n",
      "[I 2025-02-12 22:11:57,038] Trial 12 finished with value: 38.69403821556307 and parameters: {'bagging_fraction': 0.905809343762639, 'bagging_freq': 2, 'cat_l2': 13.991550341718435, 'extra_trees': False, 'feature_fraction': 0.5734117394094265, 'learning_rate': 0.04869925766949174, 'max_bin': 3934, 'max_depth': 935, 'min_samples_leaf': 5, 'n_estimators': 10131, 'num_leaves': 54, 'lambda_l1': 4.5652758550606265, 'lambda_l2': 3.6246393140342414}. Best is trial 12 with value: 38.69403821556307.\n",
      "[I 2025-02-12 22:11:57,656] Trial 13 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 22:11:58,274] Trial 14 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 22:11:58,890] Trial 15 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 22:14:49,728] Trial 16 finished with value: 38.69464243349891 and parameters: {'bagging_fraction': 0.9067965969204317, 'bagging_freq': 3, 'cat_l2': 17.094229891146554, 'extra_trees': False, 'feature_fraction': 0.6885198009301451, 'learning_rate': 0.03580767731332453, 'max_bin': 5247, 'max_depth': 982, 'min_samples_leaf': 19, 'n_estimators': 3367, 'num_leaves': 118, 'lambda_l1': 0.000763592038258741, 'lambda_l2': 3.149685118430525e-05}. Best is trial 12 with value: 38.69403821556307.\n",
      "[I 2025-02-12 22:14:50,591] Trial 17 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 22:14:55,501] Trial 18 pruned. Trial was pruned at iteration 110.\n",
      "[I 2025-02-12 22:14:56,111] Trial 19 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 22:14:56,771] Trial 20 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 22:17:33,858] Trial 21 finished with value: 38.69467405220133 and parameters: {'bagging_fraction': 0.9035406747662607, 'bagging_freq': 3, 'cat_l2': 17.027431483672693, 'extra_trees': False, 'feature_fraction': 0.6786084814004713, 'learning_rate': 0.04029886429924418, 'max_bin': 5214, 'max_depth': 994, 'min_samples_leaf': 17, 'n_estimators': 2758, 'num_leaves': 97, 'lambda_l1': 0.0004683819497391865, 'lambda_l2': 4.959431404684419e-05}. Best is trial 12 with value: 38.69403821556307.\n",
      "[I 2025-02-12 22:17:34,519] Trial 22 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 22:17:35,440] Trial 23 pruned. Trial was pruned at iteration 2.\n",
      "[I 2025-02-12 22:17:36,157] Trial 24 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 22:17:36,705] Trial 25 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 22:17:37,534] Trial 26 pruned. Trial was pruned at iteration 1.\n",
      "[I 2025-02-12 22:17:41,647] Trial 27 pruned. Trial was pruned at iteration 19.\n",
      "[I 2025-02-12 22:17:42,288] Trial 28 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 22:17:42,842] Trial 29 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 22:17:43,467] Trial 30 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 22:20:24,555] Trial 31 finished with value: 38.69478623889323 and parameters: {'bagging_fraction': 0.9266279748500886, 'bagging_freq': 3, 'cat_l2': 16.456689878677565, 'extra_trees': False, 'feature_fraction': 0.6834833269554075, 'learning_rate': 0.04236158454833465, 'max_bin': 5497, 'max_depth': 993, 'min_samples_leaf': 16, 'n_estimators': 2526, 'num_leaves': 104, 'lambda_l1': 0.00030153283994150825, 'lambda_l2': 5.454878784358404e-05}. Best is trial 12 with value: 38.69403821556307.\n",
      "[I 2025-02-12 22:22:54,943] Trial 32 finished with value: 38.69408623832458 and parameters: {'bagging_fraction': 0.9027809063208724, 'bagging_freq': 3, 'cat_l2': 15.712496226326675, 'extra_trees': False, 'feature_fraction': 0.7143360855700961, 'learning_rate': 0.04262497274071175, 'max_bin': 2837, 'max_depth': 997, 'min_samples_leaf': 18, 'n_estimators': 3838, 'num_leaves': 68, 'lambda_l1': 0.0006283202939758687, 'lambda_l2': 4.0890598187289197e-07}. Best is trial 12 with value: 38.69403821556307.\n",
      "[I 2025-02-12 22:25:03,393] Trial 33 finished with value: 38.69399133556766 and parameters: {'bagging_fraction': 0.9940962912363072, 'bagging_freq': 4, 'cat_l2': 15.625815075535801, 'extra_trees': False, 'feature_fraction': 0.7738325982941517, 'learning_rate': 0.04988438461672098, 'max_bin': 2759, 'max_depth': 935, 'min_samples_leaf': 9, 'n_estimators': 3838, 'num_leaves': 69, 'lambda_l1': 0.009883441814384133, 'lambda_l2': 3.6001066199255233e-07}. Best is trial 33 with value: 38.69399133556766.\n",
      "[I 2025-02-12 22:27:23,230] Trial 34 finished with value: 38.69392617154529 and parameters: {'bagging_fraction': 0.9979130327182998, 'bagging_freq': 4, 'cat_l2': 15.019169973887474, 'extra_trees': False, 'feature_fraction': 0.7742259585882943, 'learning_rate': 0.04975152239577477, 'max_bin': 2825, 'max_depth': 911, 'min_samples_leaf': 10, 'n_estimators': 944, 'num_leaves': 74, 'lambda_l1': 0.005942017427689793, 'lambda_l2': 1.755422984207442e-07}. Best is trial 34 with value: 38.69392617154529.\n",
      "[I 2025-02-12 22:29:28,889] Trial 35 finished with value: 38.69333109924226 and parameters: {'bagging_fraction': 0.9845855827369719, 'bagging_freq': 4, 'cat_l2': 15.56109518501091, 'extra_trees': False, 'feature_fraction': 0.7854276569810373, 'learning_rate': 0.049027872072879605, 'max_bin': 2602, 'max_depth': 920, 'min_samples_leaf': 10, 'n_estimators': 4023, 'num_leaves': 35, 'lambda_l1': 0.00512002046717473, 'lambda_l2': 3.014253881843341e-07}. Best is trial 35 with value: 38.69333109924226.\n",
      "[I 2025-02-12 22:31:33,478] Trial 36 finished with value: 38.69407262505284 and parameters: {'bagging_fraction': 0.992814538023236, 'bagging_freq': 4, 'cat_l2': 13.350206043878014, 'extra_trees': False, 'feature_fraction': 0.9066474030715639, 'learning_rate': 0.048211886263518515, 'max_bin': 2491, 'max_depth': 878, 'min_samples_leaf': 8, 'n_estimators': 5808, 'num_leaves': 31, 'lambda_l1': 0.007956460722757668, 'lambda_l2': 3.249597806971182e-07}. Best is trial 35 with value: 38.69333109924226.\n",
      "[I 2025-02-12 22:31:34,695] Trial 37 pruned. Trial was pruned at iteration 3.\n",
      "[I 2025-02-12 22:31:37,266] Trial 38 pruned. Trial was pruned at iteration 22.\n",
      "[I 2025-02-12 22:31:38,303] Trial 39 pruned. Trial was pruned at iteration 2.\n",
      "[I 2025-02-12 22:33:39,286] Trial 40 finished with value: 38.694311981595376 and parameters: {'bagging_fraction': 0.9675314826582324, 'bagging_freq': 6, 'cat_l2': 12.504981578414244, 'extra_trees': False, 'feature_fraction': 0.9450919011950591, 'learning_rate': 0.04546246257344045, 'max_bin': 2238, 'max_depth': 932, 'min_samples_leaf': 65, 'n_estimators': 8002, 'num_leaves': 59, 'lambda_l1': 0.1978684974668667, 'lambda_l2': 1.2241250039550174e-08}. Best is trial 35 with value: 38.69333109924226.\n",
      "[I 2025-02-12 22:35:35,065] Trial 41 finished with value: 38.693881321516145 and parameters: {'bagging_fraction': 0.9900724567188413, 'bagging_freq': 4, 'cat_l2': 13.232065189013754, 'extra_trees': False, 'feature_fraction': 0.9202110637860622, 'learning_rate': 0.04976962985247258, 'max_bin': 2509, 'max_depth': 874, 'min_samples_leaf': 10, 'n_estimators': 5550, 'num_leaves': 32, 'lambda_l1': 0.005886371324932342, 'lambda_l2': 4.120417242053467e-07}. Best is trial 35 with value: 38.69333109924226.\n",
      "[I 2025-02-12 22:35:35,617] Trial 42 pruned. Trial was pruned at iteration 1.\n",
      "[I 2025-02-12 22:36:44,520] Trial 43 pruned. Trial was pruned at iteration 286.\n",
      "[I 2025-02-12 22:36:45,101] Trial 44 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 22:38:44,731] Trial 45 finished with value: 38.6942283606014 and parameters: {'bagging_fraction': 0.9680146587897261, 'bagging_freq': 4, 'cat_l2': 13.10722653969174, 'extra_trees': False, 'feature_fraction': 0.8346160127406651, 'learning_rate': 0.04571041775088661, 'max_bin': 2697, 'max_depth': 794, 'min_samples_leaf': 5, 'n_estimators': 8906, 'num_leaves': 61, 'lambda_l1': 0.017568423658764647, 'lambda_l2': 3.5734359043570964e-08}. Best is trial 35 with value: 38.69333109924226.\n",
      "[I 2025-02-12 22:38:45,320] Trial 46 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 22:38:45,869] Trial 47 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 22:38:46,402] Trial 48 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 22:38:47,012] Trial 49 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 22:38:47,772] Trial 50 pruned. Trial was pruned at iteration 2.\n",
      "[I 2025-02-12 22:39:10,890] Trial 51 pruned. Trial was pruned at iteration 315.\n",
      "[I 2025-02-12 22:39:13,704] Trial 52 pruned. Trial was pruned at iteration 20.\n",
      "[I 2025-02-12 22:39:20,268] Trial 53 pruned. Trial was pruned at iteration 65.\n",
      "[I 2025-02-12 22:41:37,241] Trial 54 finished with value: 38.694164582689794 and parameters: {'bagging_fraction': 0.8895030057860439, 'bagging_freq': 5, 'cat_l2': 12.627977315751256, 'extra_trees': False, 'feature_fraction': 0.9233194798730323, 'learning_rate': 0.04318752333863148, 'max_bin': 3565, 'max_depth': 954, 'min_samples_leaf': 13, 'n_estimators': 4486, 'num_leaves': 55, 'lambda_l1': 0.0010803327413490636, 'lambda_l2': 2.050365045585699e-07}. Best is trial 35 with value: 38.69333109924226.\n",
      "[I 2025-02-12 22:41:38,212] Trial 55 pruned. Trial was pruned at iteration 1.\n",
      "[I 2025-02-12 22:41:38,934] Trial 56 pruned. Trial was pruned at iteration 1.\n",
      "[I 2025-02-12 22:43:42,424] Trial 57 finished with value: 38.69418954511924 and parameters: {'bagging_fraction': 0.9792998010431199, 'bagging_freq': 4, 'cat_l2': 14.314149550894275, 'extra_trees': False, 'feature_fraction': 0.8470219779861272, 'learning_rate': 0.04983564242111554, 'max_bin': 4487, 'max_depth': 962, 'min_samples_leaf': 7, 'n_estimators': 7313, 'num_leaves': 73, 'lambda_l1': 0.008395084310959998, 'lambda_l2': 1.18337232898854e-06}. Best is trial 35 with value: 38.69333109924226.\n",
      "[I 2025-02-12 22:43:42,924] Trial 58 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 22:43:47,056] Trial 59 pruned. Trial was pruned at iteration 27.\n",
      "[I 2025-02-12 22:43:47,805] Trial 60 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 22:43:48,436] Trial 61 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 22:44:10,615] Trial 62 pruned. Trial was pruned at iteration 208.\n",
      "[I 2025-02-12 22:44:11,211] Trial 63 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 22:44:11,922] Trial 64 pruned. Trial was pruned at iteration 1.\n",
      "[I 2025-02-12 22:44:12,488] Trial 65 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 22:44:13,123] Trial 66 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 22:44:13,767] Trial 67 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 22:44:14,547] Trial 68 pruned. Trial was pruned at iteration 1.\n",
      "[I 2025-02-12 22:44:15,125] Trial 69 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 22:44:18,631] Trial 70 pruned. Trial was pruned at iteration 22.\n",
      "[I 2025-02-12 22:44:32,791] Trial 71 pruned. Trial was pruned at iteration 112.\n",
      "[I 2025-02-12 22:44:33,393] Trial 72 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 22:44:37,509] Trial 73 pruned. Trial was pruned at iteration 21.\n",
      "[I 2025-02-12 22:44:56,094] Trial 74 pruned. Trial was pruned at iteration 152.\n",
      "[I 2025-02-12 22:44:56,654] Trial 75 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 22:44:57,213] Trial 76 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 22:44:57,757] Trial 77 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 22:45:15,706] Trial 78 pruned. Trial was pruned at iteration 100.\n",
      "[I 2025-02-12 22:45:16,213] Trial 79 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 22:45:42,116] Trial 80 pruned. Trial was pruned at iteration 315.\n",
      "[I 2025-02-12 22:46:05,601] Trial 81 pruned. Trial was pruned at iteration 208.\n",
      "[I 2025-02-12 22:46:06,370] Trial 82 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 22:48:15,192] Trial 83 finished with value: 38.69447500053477 and parameters: {'bagging_fraction': 0.9642520514842207, 'bagging_freq': 4, 'cat_l2': 15.890458867983972, 'extra_trees': False, 'feature_fraction': 0.8476269303457461, 'learning_rate': 0.047530939905509044, 'max_bin': 5144, 'max_depth': 902, 'min_samples_leaf': 8, 'n_estimators': 8462, 'num_leaves': 71, 'lambda_l1': 0.01631697862328434, 'lambda_l2': 7.471390744080928e-07}. Best is trial 35 with value: 38.69333109924226.\n",
      "[I 2025-02-12 22:48:28,598] Trial 84 pruned. Trial was pruned at iteration 90.\n",
      "[I 2025-02-12 22:50:35,158] Trial 85 finished with value: 38.6947847238377 and parameters: {'bagging_fraction': 0.911170090125925, 'bagging_freq': 4, 'cat_l2': 17.161424685438245, 'extra_trees': False, 'feature_fraction': 0.870526233440704, 'learning_rate': 0.045538728335481525, 'max_bin': 3779, 'max_depth': 863, 'min_samples_leaf': 11, 'n_estimators': 7649, 'num_leaves': 85, 'lambda_l1': 4.2748718995875286e-05, 'lambda_l2': 9.894072971888029e-08}. Best is trial 35 with value: 38.69333109924226.\n",
      "[I 2025-02-12 22:50:35,834] Trial 86 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 22:50:55,160] Trial 87 pruned. Trial was pruned at iteration 121.\n",
      "[I 2025-02-12 22:50:55,779] Trial 88 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 22:50:57,025] Trial 89 pruned. Trial was pruned at iteration 4.\n",
      "[I 2025-02-12 22:50:57,798] Trial 90 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 22:51:01,704] Trial 91 pruned. Trial was pruned at iteration 22.\n",
      "[I 2025-02-12 22:53:15,043] Trial 92 finished with value: 38.693705674133824 and parameters: {'bagging_fraction': 0.9875750177078828, 'bagging_freq': 4, 'cat_l2': 13.2162904932087, 'extra_trees': False, 'feature_fraction': 0.8527894971315355, 'learning_rate': 0.049093621424640466, 'max_bin': 3058, 'max_depth': 792, 'min_samples_leaf': 10, 'n_estimators': 8899, 'num_leaves': 45, 'lambda_l1': 0.006453932144387569, 'lambda_l2': 3.267261469734185e-08}. Best is trial 35 with value: 38.69333109924226.\n",
      "[I 2025-02-12 22:53:37,162] Trial 93 pruned. Trial was pruned at iteration 208.\n",
      "[I 2025-02-12 22:53:38,411] Trial 94 pruned. Trial was pruned at iteration 5.\n",
      "[I 2025-02-12 22:53:39,028] Trial 95 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 22:53:39,617] Trial 96 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 22:53:40,227] Trial 97 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 22:53:40,760] Trial 98 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 22:53:41,436] Trial 99 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 22:53:42,088] Trial 100 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 22:53:43,399] Trial 101 pruned. Trial was pruned at iteration 5.\n",
      "[I 2025-02-12 22:53:44,492] Trial 102 pruned. Trial was pruned at iteration 5.\n",
      "[I 2025-02-12 22:53:45,126] Trial 103 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 22:54:04,064] Trial 104 pruned. Trial was pruned at iteration 120.\n",
      "[I 2025-02-12 22:54:04,661] Trial 105 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 22:56:23,772] Trial 106 finished with value: 38.694307646293886 and parameters: {'bagging_fraction': 0.9493429153189579, 'bagging_freq': 4, 'cat_l2': 12.36372367435812, 'extra_trees': False, 'feature_fraction': 0.9393821989612724, 'learning_rate': 0.04422862521306135, 'max_bin': 2357, 'max_depth': 826, 'min_samples_leaf': 11, 'n_estimators': 6589, 'num_leaves': 82, 'lambda_l1': 0.17330215050534406, 'lambda_l2': 1.0035914778860593e-07}. Best is trial 35 with value: 38.69333109924226.\n",
      "[I 2025-02-12 22:56:24,355] Trial 107 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 22:56:47,178] Trial 108 pruned. Trial was pruned at iteration 210.\n",
      "[I 2025-02-12 22:56:48,000] Trial 109 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 22:56:48,650] Trial 110 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 22:56:49,391] Trial 111 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 22:56:50,033] Trial 112 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 22:56:50,658] Trial 113 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 22:56:51,330] Trial 114 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 22:56:52,134] Trial 115 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 22:56:52,804] Trial 116 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 22:56:53,519] Trial 117 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 22:56:54,489] Trial 118 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 22:56:55,297] Trial 119 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 22:58:58,062] Trial 120 finished with value: 38.69386283337185 and parameters: {'bagging_fraction': 0.9574124641322203, 'bagging_freq': 6, 'cat_l2': 15.954036209821789, 'extra_trees': False, 'feature_fraction': 0.9511764806845175, 'learning_rate': 0.04991160353760023, 'max_bin': 1500, 'max_depth': 66, 'min_samples_leaf': 12, 'n_estimators': 8562, 'num_leaves': 47, 'lambda_l1': 0.0023226949412215397, 'lambda_l2': 0.1787865539392393}. Best is trial 35 with value: 38.69333109924226.\n",
      "[I 2025-02-12 23:00:59,029] Trial 121 finished with value: 38.69360284980147 and parameters: {'bagging_fraction': 0.9617000786809362, 'bagging_freq': 7, 'cat_l2': 13.620090571904495, 'extra_trees': False, 'feature_fraction': 0.9692102437289668, 'learning_rate': 0.04893938981782978, 'max_bin': 1516, 'max_depth': 242, 'min_samples_leaf': 95, 'n_estimators': 543, 'num_leaves': 46, 'lambda_l1': 0.0025536165876094826, 'lambda_l2': 0.2543634882407381}. Best is trial 35 with value: 38.69333109924226.\n",
      "[I 2025-02-12 23:01:17,102] Trial 122 pruned. Trial was pruned at iteration 205.\n",
      "[I 2025-02-12 23:01:17,636] Trial 123 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:03:17,564] Trial 124 finished with value: 38.69361161773672 and parameters: {'bagging_fraction': 0.9772857597118348, 'bagging_freq': 7, 'cat_l2': 15.306829980320284, 'extra_trees': False, 'feature_fraction': 0.9543341579749172, 'learning_rate': 0.04846097389218041, 'max_bin': 1644, 'max_depth': 166, 'min_samples_leaf': 61, 'n_estimators': 511, 'num_leaves': 37, 'lambda_l1': 0.001516496186395537, 'lambda_l2': 0.2919205499046153}. Best is trial 35 with value: 38.69333109924226.\n",
      "[I 2025-02-12 23:03:19,317] Trial 125 pruned. Trial was pruned at iteration 14.\n",
      "[I 2025-02-12 23:03:27,382] Trial 126 pruned. Trial was pruned at iteration 71.\n",
      "[I 2025-02-12 23:03:46,518] Trial 127 pruned. Trial was pruned at iteration 208.\n",
      "[I 2025-02-12 23:03:47,132] Trial 128 pruned. Trial was pruned at iteration 1.\n",
      "[I 2025-02-12 23:03:47,743] Trial 129 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:03:48,449] Trial 130 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:03:49,099] Trial 131 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:03:55,859] Trial 132 pruned. Trial was pruned at iteration 59.\n",
      "[I 2025-02-12 23:04:09,998] Trial 133 pruned. Trial was pruned at iteration 121.\n",
      "[I 2025-02-12 23:04:10,670] Trial 134 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:04:11,254] Trial 135 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:04:12,573] Trial 136 pruned. Trial was pruned at iteration 5.\n",
      "[I 2025-02-12 23:06:05,844] Trial 137 finished with value: 38.69335601050386 and parameters: {'bagging_fraction': 0.9255142880764357, 'bagging_freq': 4, 'cat_l2': 15.452493934571628, 'extra_trees': False, 'feature_fraction': 0.9517394092678215, 'learning_rate': 0.04976125757350365, 'max_bin': 8180, 'max_depth': 938, 'min_samples_leaf': 89, 'n_estimators': 2493, 'num_leaves': 28, 'lambda_l1': 3.946267631077666, 'lambda_l2': 0.9291696409003609}. Best is trial 35 with value: 38.69333109924226.\n",
      "[I 2025-02-12 23:06:10,549] Trial 138 pruned. Trial was pruned at iteration 48.\n",
      "[I 2025-02-12 23:06:14,313] Trial 139 pruned. Trial was pruned at iteration 31.\n",
      "[I 2025-02-12 23:06:14,915] Trial 140 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:06:15,605] Trial 141 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:06:36,250] Trial 142 pruned. Trial was pruned at iteration 223.\n",
      "[I 2025-02-12 23:06:36,920] Trial 143 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:06:37,572] Trial 144 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:06:38,188] Trial 145 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:06:39,560] Trial 146 pruned. Trial was pruned at iteration 5.\n",
      "[I 2025-02-12 23:06:40,216] Trial 147 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:06:40,889] Trial 148 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:06:54,429] Trial 149 pruned. Trial was pruned at iteration 109.\n",
      "[I 2025-02-12 23:07:14,545] Trial 150 pruned. Trial was pruned at iteration 205.\n",
      "[I 2025-02-12 23:07:15,212] Trial 151 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:08:05,718] Trial 152 finished with value: 38.69855333245048 and parameters: {'bagging_fraction': 0.9869494616107678, 'bagging_freq': 4, 'cat_l2': 16.0872208817089, 'extra_trees': False, 'feature_fraction': 0.9707700468735112, 'learning_rate': 0.04737135381317387, 'max_bin': 8077, 'max_depth': 905, 'min_samples_leaf': 82, 'n_estimators': 65, 'num_leaves': 70, 'lambda_l1': 0.000315721767776703, 'lambda_l2': 0.21995658429001855}. Best is trial 35 with value: 38.69333109924226.\n",
      "[I 2025-02-12 23:08:06,351] Trial 153 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:08:06,969] Trial 154 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:08:07,598] Trial 155 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:08:24,530] Trial 156 pruned. Trial was pruned at iteration 105.\n",
      "[I 2025-02-12 23:08:25,237] Trial 157 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:08:25,904] Trial 158 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:08:26,532] Trial 159 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:08:27,270] Trial 160 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:08:27,964] Trial 161 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:08:28,733] Trial 162 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:08:29,440] Trial 163 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:08:41,887] Trial 164 pruned. Trial was pruned at iteration 112.\n",
      "[I 2025-02-12 23:08:58,396] Trial 165 pruned. Trial was pruned at iteration 140.\n",
      "[I 2025-02-12 23:08:59,026] Trial 166 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:08:59,777] Trial 167 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:09:00,520] Trial 168 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:09:02,003] Trial 169 pruned. Trial was pruned at iteration 5.\n",
      "[I 2025-02-12 23:09:02,798] Trial 170 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:09:03,422] Trial 171 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:10:54,493] Trial 172 finished with value: 38.69378978548595 and parameters: {'bagging_fraction': 0.9630852683262244, 'bagging_freq': 7, 'cat_l2': 12.131039221082013, 'extra_trees': False, 'feature_fraction': 0.9448820683515151, 'learning_rate': 0.04809156112700983, 'max_bin': 1826, 'max_depth': 971, 'min_samples_leaf': 68, 'n_estimators': 7614, 'num_leaves': 50, 'lambda_l1': 0.011613053635937022, 'lambda_l2': 3.312635425634065e-08}. Best is trial 35 with value: 38.69333109924226.\n",
      "[I 2025-02-12 23:10:55,117] Trial 173 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:10:55,706] Trial 174 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:10:56,295] Trial 175 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:10:56,864] Trial 176 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:11:15,942] Trial 177 pruned. Trial was pruned at iteration 223.\n",
      "[I 2025-02-12 23:11:16,595] Trial 178 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:11:38,112] Trial 179 pruned. Trial was pruned at iteration 208.\n",
      "[I 2025-02-12 23:11:38,862] Trial 180 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:11:52,329] Trial 181 pruned. Trial was pruned at iteration 119.\n",
      "[I 2025-02-12 23:11:52,948] Trial 182 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:11:53,657] Trial 183 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:11:54,516] Trial 184 pruned. Trial was pruned at iteration 1.\n",
      "[I 2025-02-12 23:11:55,168] Trial 185 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:11:55,805] Trial 186 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:11:56,316] Trial 187 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:11:57,040] Trial 188 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:11:57,687] Trial 189 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:11:58,404] Trial 190 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:12:14,612] Trial 191 pruned. Trial was pruned at iteration 114.\n",
      "[I 2025-02-12 23:12:15,258] Trial 192 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:12:37,186] Trial 193 pruned. Trial was pruned at iteration 222.\n",
      "[I 2025-02-12 23:12:55,866] Trial 194 pruned. Trial was pruned at iteration 126.\n",
      "[I 2025-02-12 23:12:56,478] Trial 195 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:12:57,236] Trial 196 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:12:57,875] Trial 197 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:12:58,555] Trial 198 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:13:16,758] Trial 199 pruned. Trial was pruned at iteration 127.\n",
      "[I 2025-02-12 23:13:17,362] Trial 200 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:13:18,047] Trial 201 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:13:18,692] Trial 202 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:13:19,331] Trial 203 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:13:19,944] Trial 204 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:13:20,790] Trial 205 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:13:21,762] Trial 206 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:13:38,345] Trial 207 pruned. Trial was pruned at iteration 117.\n",
      "[I 2025-02-12 23:13:38,953] Trial 208 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:13:39,538] Trial 209 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:13:40,650] Trial 210 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:13:41,400] Trial 211 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:13:42,178] Trial 212 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:13:42,846] Trial 213 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:13:57,667] Trial 214 pruned. Trial was pruned at iteration 111.\n",
      "[I 2025-02-12 23:14:14,967] Trial 215 pruned. Trial was pruned at iteration 117.\n",
      "[I 2025-02-12 23:14:15,619] Trial 216 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:14:16,217] Trial 217 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:14:16,802] Trial 218 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:14:17,504] Trial 219 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:14:18,519] Trial 220 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:14:32,800] Trial 221 pruned. Trial was pruned at iteration 95.\n",
      "[I 2025-02-12 23:14:33,529] Trial 222 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:14:34,252] Trial 223 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:14:49,422] Trial 224 pruned. Trial was pruned at iteration 107.\n",
      "[I 2025-02-12 23:14:50,178] Trial 225 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:15:05,333] Trial 226 pruned. Trial was pruned at iteration 88.\n",
      "[I 2025-02-12 23:15:07,049] Trial 227 pruned. Trial was pruned at iteration 5.\n",
      "[I 2025-02-12 23:15:07,743] Trial 228 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:15:08,483] Trial 229 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:15:09,205] Trial 230 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:15:09,979] Trial 231 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:15:10,694] Trial 232 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:15:11,459] Trial 233 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:15:12,040] Trial 234 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:15:12,783] Trial 235 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:15:13,526] Trial 236 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:15:29,135] Trial 237 pruned. Trial was pruned at iteration 68.\n",
      "[I 2025-02-12 23:15:29,724] Trial 238 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:15:30,415] Trial 239 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:15:48,586] Trial 240 pruned. Trial was pruned at iteration 141.\n",
      "[I 2025-02-12 23:15:49,254] Trial 241 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:15:49,923] Trial 242 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:15:50,575] Trial 243 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:15:51,190] Trial 244 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:16:04,817] Trial 245 pruned. Trial was pruned at iteration 119.\n",
      "[I 2025-02-12 23:16:05,430] Trial 246 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:16:06,189] Trial 247 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:16:06,920] Trial 248 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:16:07,728] Trial 249 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:16:17,524] Trial 250 pruned. Trial was pruned at iteration 86.\n",
      "[I 2025-02-12 23:16:18,213] Trial 251 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:16:18,907] Trial 252 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:16:19,560] Trial 253 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:16:20,280] Trial 254 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:16:21,334] Trial 255 pruned. Trial was pruned at iteration 5.\n",
      "[I 2025-02-12 23:16:21,968] Trial 256 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:16:22,669] Trial 257 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:16:23,330] Trial 258 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:16:24,043] Trial 259 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:16:24,859] Trial 260 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:16:25,531] Trial 261 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:16:26,217] Trial 262 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:16:27,030] Trial 263 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:16:43,253] Trial 264 pruned. Trial was pruned at iteration 114.\n",
      "[I 2025-02-12 23:16:43,872] Trial 265 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:16:51,777] Trial 266 pruned. Trial was pruned at iteration 70.\n",
      "[I 2025-02-12 23:16:52,421] Trial 267 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:16:59,333] Trial 268 pruned. Trial was pruned at iteration 60.\n",
      "[I 2025-02-12 23:17:00,025] Trial 269 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:17:00,826] Trial 270 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:17:02,532] Trial 271 pruned. Trial was pruned at iteration 5.\n",
      "[I 2025-02-12 23:17:03,251] Trial 272 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:17:03,944] Trial 273 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:17:04,711] Trial 274 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:17:05,445] Trial 275 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:17:06,162] Trial 276 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:17:06,854] Trial 277 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:17:07,526] Trial 278 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:17:08,101] Trial 279 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:17:08,743] Trial 280 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:17:09,362] Trial 281 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:17:10,486] Trial 282 pruned. Trial was pruned at iteration 5.\n",
      "[I 2025-02-12 23:19:12,613] Trial 283 finished with value: 38.69414710887699 and parameters: {'bagging_fraction': 0.9295288621179308, 'bagging_freq': 4, 'cat_l2': 15.926703424142838, 'extra_trees': False, 'feature_fraction': 0.9517668651564115, 'learning_rate': 0.04735282062721851, 'max_bin': 2837, 'max_depth': 845, 'min_samples_leaf': 16, 'n_estimators': 3482, 'num_leaves': 70, 'lambda_l1': 0.003751605346153941, 'lambda_l2': 3.817637036469138e-05}. Best is trial 35 with value: 38.69333109924226.\n",
      "[I 2025-02-12 23:21:12,738] Trial 284 finished with value: 38.694096380335324 and parameters: {'bagging_fraction': 0.9213616521005159, 'bagging_freq': 4, 'cat_l2': 15.926932672404293, 'extra_trees': False, 'feature_fraction': 0.9514694271500903, 'learning_rate': 0.04788266901540543, 'max_bin': 2851, 'max_depth': 820, 'min_samples_leaf': 14, 'n_estimators': 2962, 'num_leaves': 61, 'lambda_l1': 0.0037532528095785248, 'lambda_l2': 2.743812675431059e-05}. Best is trial 35 with value: 38.69333109924226.\n",
      "[I 2025-02-12 23:21:29,997] Trial 285 pruned. Trial was pruned at iteration 94.\n",
      "[I 2025-02-12 23:21:43,676] Trial 286 pruned. Trial was pruned at iteration 118.\n",
      "[I 2025-02-12 23:22:06,750] Trial 287 pruned. Trial was pruned at iteration 223.\n",
      "[I 2025-02-12 23:22:07,487] Trial 288 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:22:24,555] Trial 289 pruned. Trial was pruned at iteration 106.\n",
      "[I 2025-02-12 23:22:25,132] Trial 290 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:22:25,774] Trial 291 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:22:26,471] Trial 292 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:22:27,088] Trial 293 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:22:45,102] Trial 294 pruned. Trial was pruned at iteration 87.\n",
      "[I 2025-02-12 23:22:45,734] Trial 295 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:22:46,872] Trial 296 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:23:03,625] Trial 297 pruned. Trial was pruned at iteration 127.\n",
      "[I 2025-02-12 23:23:04,298] Trial 298 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:23:05,010] Trial 299 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:23:14,794] Trial 300 pruned. Trial was pruned at iteration 80.\n",
      "[I 2025-02-12 23:23:15,506] Trial 301 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:23:17,588] Trial 302 pruned. Trial was pruned at iteration 14.\n",
      "[I 2025-02-12 23:23:18,253] Trial 303 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:23:18,961] Trial 304 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:23:34,843] Trial 305 pruned. Trial was pruned at iteration 118.\n",
      "[I 2025-02-12 23:23:36,822] Trial 306 pruned. Trial was pruned at iteration 15.\n",
      "[I 2025-02-12 23:23:38,186] Trial 307 pruned. Trial was pruned at iteration 5.\n",
      "[I 2025-02-12 23:23:38,891] Trial 308 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:24:01,631] Trial 309 pruned. Trial was pruned at iteration 207.\n",
      "[I 2025-02-12 23:24:02,381] Trial 310 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:24:03,197] Trial 311 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:24:04,157] Trial 312 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:24:05,010] Trial 313 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:24:05,729] Trial 314 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:24:06,330] Trial 315 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:24:21,292] Trial 316 pruned. Trial was pruned at iteration 119.\n",
      "[I 2025-02-12 23:24:22,505] Trial 317 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:24:23,228] Trial 318 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:24:23,971] Trial 319 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:24:25,448] Trial 320 pruned. Trial was pruned at iteration 5.\n",
      "[I 2025-02-12 23:24:26,245] Trial 321 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:24:26,991] Trial 322 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:24:27,737] Trial 323 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:24:28,421] Trial 324 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:24:29,172] Trial 325 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:24:33,853] Trial 326 pruned. Trial was pruned at iteration 42.\n",
      "[I 2025-02-12 23:24:34,581] Trial 327 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:24:36,006] Trial 328 pruned. Trial was pruned at iteration 5.\n",
      "[I 2025-02-12 23:24:53,547] Trial 329 pruned. Trial was pruned at iteration 141.\n",
      "[I 2025-02-12 23:24:54,163] Trial 330 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:24:54,895] Trial 331 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:24:55,520] Trial 332 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:25:09,956] Trial 333 pruned. Trial was pruned at iteration 144.\n",
      "[I 2025-02-12 23:25:11,332] Trial 334 pruned. Trial was pruned at iteration 5.\n",
      "[I 2025-02-12 23:25:12,054] Trial 335 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:25:12,769] Trial 336 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:25:13,466] Trial 337 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:25:14,262] Trial 338 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:25:21,308] Trial 339 pruned. Trial was pruned at iteration 62.\n",
      "[I 2025-02-12 23:25:23,372] Trial 340 pruned. Trial was pruned at iteration 5.\n",
      "[I 2025-02-12 23:25:41,144] Trial 341 pruned. Trial was pruned at iteration 109.\n",
      "[I 2025-02-12 23:25:41,775] Trial 342 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:25:42,754] Trial 343 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:25:43,575] Trial 344 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:25:44,273] Trial 345 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:25:45,011] Trial 346 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:25:45,767] Trial 347 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:25:46,525] Trial 348 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:25:47,255] Trial 349 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:25:48,067] Trial 350 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:25:48,800] Trial 351 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:25:49,410] Trial 352 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:25:50,080] Trial 353 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:26:00,034] Trial 354 pruned. Trial was pruned at iteration 79.\n",
      "[I 2025-02-12 23:26:00,681] Trial 355 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:26:01,321] Trial 356 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:26:02,033] Trial 357 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:26:02,757] Trial 358 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:26:03,880] Trial 359 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:26:04,585] Trial 360 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:26:24,053] Trial 361 pruned. Trial was pruned at iteration 210.\n",
      "[I 2025-02-12 23:27:30,468] Trial 362 pruned. Trial was pruned at iteration 222.\n",
      "[I 2025-02-12 23:27:31,219] Trial 363 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:27:45,913] Trial 364 pruned. Trial was pruned at iteration 140.\n",
      "[I 2025-02-12 23:27:55,625] Trial 365 pruned. Trial was pruned at iteration 73.\n",
      "[I 2025-02-12 23:27:56,337] Trial 366 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:27:57,049] Trial 367 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:27:57,773] Trial 368 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:28:19,285] Trial 369 pruned. Trial was pruned at iteration 222.\n",
      "[I 2025-02-12 23:28:20,069] Trial 370 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:28:34,339] Trial 371 pruned. Trial was pruned at iteration 119.\n",
      "[I 2025-02-12 23:28:35,114] Trial 372 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:28:39,130] Trial 373 pruned. Trial was pruned at iteration 33.\n",
      "[I 2025-02-12 23:28:39,787] Trial 374 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:28:40,803] Trial 375 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:28:41,577] Trial 376 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:28:42,346] Trial 377 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:28:43,163] Trial 378 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:29:00,167] Trial 379 pruned. Trial was pruned at iteration 130.\n",
      "[I 2025-02-12 23:29:01,041] Trial 380 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:29:01,881] Trial 381 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:29:16,007] Trial 382 pruned. Trial was pruned at iteration 107.\n",
      "[I 2025-02-12 23:29:16,712] Trial 383 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:29:17,346] Trial 384 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:29:38,331] Trial 385 pruned. Trial was pruned at iteration 222.\n",
      "[I 2025-02-12 23:29:39,163] Trial 386 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:29:39,911] Trial 387 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:29:40,597] Trial 388 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:29:41,312] Trial 389 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:29:59,416] Trial 390 pruned. Trial was pruned at iteration 139.\n",
      "[I 2025-02-12 23:30:00,179] Trial 391 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:30:19,082] Trial 392 pruned. Trial was pruned at iteration 203.\n",
      "[I 2025-02-12 23:30:29,534] Trial 393 pruned. Trial was pruned at iteration 80.\n",
      "[I 2025-02-12 23:30:30,278] Trial 394 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:30:31,046] Trial 395 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:30:32,551] Trial 396 pruned. Trial was pruned at iteration 5.\n",
      "[I 2025-02-12 23:30:33,307] Trial 397 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:30:33,986] Trial 398 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:30:52,406] Trial 399 pruned. Trial was pruned at iteration 222.\n",
      "[I 2025-02-12 23:31:09,029] Trial 400 pruned. Trial was pruned at iteration 127.\n",
      "[I 2025-02-12 23:31:09,816] Trial 401 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:31:10,605] Trial 402 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:31:12,921] Trial 403 pruned. Trial was pruned at iteration 15.\n",
      "[I 2025-02-12 23:31:13,759] Trial 404 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:31:14,403] Trial 405 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:31:14,992] Trial 406 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:31:30,871] Trial 407 pruned. Trial was pruned at iteration 141.\n",
      "[I 2025-02-12 23:31:31,615] Trial 408 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:31:32,388] Trial 409 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:31:47,651] Trial 410 pruned. Trial was pruned at iteration 70.\n",
      "[I 2025-02-12 23:31:48,328] Trial 411 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:32:10,113] Trial 412 pruned. Trial was pruned at iteration 203.\n",
      "[I 2025-02-12 23:32:10,870] Trial 413 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:32:11,522] Trial 414 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:32:12,321] Trial 415 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:32:13,236] Trial 416 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:32:13,969] Trial 417 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:32:14,644] Trial 418 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:32:15,396] Trial 419 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:33:25,857] Trial 420 finished with value: 38.69738667949139 and parameters: {'bagging_fraction': 0.905066382742397, 'bagging_freq': 4, 'cat_l2': 12.999286037643511, 'extra_trees': False, 'feature_fraction': 0.9562901029156485, 'learning_rate': 0.04857716975205954, 'max_bin': 3218, 'max_depth': 803, 'min_samples_leaf': 14, 'n_estimators': 69, 'num_leaves': 151, 'lambda_l1': 0.0010717966512773143, 'lambda_l2': 1.562519513094231e-06}. Best is trial 35 with value: 38.69333109924226.\n",
      "[I 2025-02-12 23:33:26,537] Trial 421 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:33:27,264] Trial 422 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:33:43,276] Trial 423 pruned. Trial was pruned at iteration 114.\n",
      "[I 2025-02-12 23:33:44,103] Trial 424 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:33:59,496] Trial 425 pruned. Trial was pruned at iteration 111.\n",
      "[I 2025-02-12 23:34:18,088] Trial 426 pruned. Trial was pruned at iteration 203.\n",
      "[I 2025-02-12 23:34:18,772] Trial 427 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:34:19,559] Trial 428 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:34:20,338] Trial 429 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:34:25,994] Trial 430 pruned. Trial was pruned at iteration 43.\n",
      "[I 2025-02-12 23:34:26,708] Trial 431 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:34:27,466] Trial 432 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:34:28,108] Trial 433 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:34:28,752] Trial 434 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:34:29,430] Trial 435 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:34:30,086] Trial 436 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:34:30,751] Trial 437 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:34:31,750] Trial 438 pruned. Trial was pruned at iteration 5.\n",
      "[I 2025-02-12 23:34:32,491] Trial 439 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:34:33,162] Trial 440 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:34:33,867] Trial 441 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:34:35,066] Trial 442 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:34:35,888] Trial 443 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:34:37,539] Trial 444 pruned. Trial was pruned at iteration 10.\n",
      "[I 2025-02-12 23:34:38,267] Trial 445 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:34:38,950] Trial 446 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:34:39,776] Trial 447 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:34:53,866] Trial 448 pruned. Trial was pruned at iteration 107.\n",
      "[I 2025-02-12 23:34:54,580] Trial 449 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:34:55,276] Trial 450 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:34:55,960] Trial 451 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:34:56,675] Trial 452 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:35:12,733] Trial 453 pruned. Trial was pruned at iteration 93.\n",
      "[I 2025-02-12 23:37:06,165] Trial 454 finished with value: 38.69426254668237 and parameters: {'bagging_fraction': 0.9739185983518143, 'bagging_freq': 6, 'cat_l2': 16.319285606471958, 'extra_trees': False, 'feature_fraction': 0.945159752944504, 'learning_rate': 0.049844272569440365, 'max_bin': 2656, 'max_depth': 973, 'min_samples_leaf': 7, 'n_estimators': 8872, 'num_leaves': 53, 'lambda_l1': 0.9517037714542893, 'lambda_l2': 6.180904856143735e-08}. Best is trial 35 with value: 38.69333109924226.\n",
      "[I 2025-02-12 23:37:21,539] Trial 455 pruned. Trial was pruned at iteration 144.\n",
      "[I 2025-02-12 23:37:37,249] Trial 456 pruned. Trial was pruned at iteration 130.\n",
      "[I 2025-02-12 23:37:57,624] Trial 457 pruned. Trial was pruned at iteration 203.\n",
      "[I 2025-02-12 23:37:58,430] Trial 458 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:37:59,127] Trial 459 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:37:59,896] Trial 460 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:38:00,616] Trial 461 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:38:01,367] Trial 462 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:38:02,106] Trial 463 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:38:02,791] Trial 464 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:38:21,805] Trial 465 pruned. Trial was pruned at iteration 119.\n",
      "[I 2025-02-12 23:38:22,473] Trial 466 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:38:23,186] Trial 467 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:38:43,904] Trial 468 pruned. Trial was pruned at iteration 202.\n",
      "[I 2025-02-12 23:38:44,619] Trial 469 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:39:02,050] Trial 470 pruned. Trial was pruned at iteration 103.\n",
      "[I 2025-02-12 23:39:02,905] Trial 471 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:39:03,725] Trial 472 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:39:04,692] Trial 473 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:39:05,429] Trial 474 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:39:25,432] Trial 475 pruned. Trial was pruned at iteration 205.\n",
      "[I 2025-02-12 23:39:40,389] Trial 476 pruned. Trial was pruned at iteration 127.\n",
      "[I 2025-02-12 23:39:41,411] Trial 477 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:39:42,049] Trial 478 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:39:42,763] Trial 479 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:39:43,486] Trial 480 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:39:44,394] Trial 481 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:39:47,102] Trial 482 pruned. Trial was pruned at iteration 16.\n",
      "[I 2025-02-12 23:39:52,204] Trial 483 pruned. Trial was pruned at iteration 46.\n",
      "[I 2025-02-12 23:39:52,935] Trial 484 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:39:53,803] Trial 485 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:39:54,545] Trial 486 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:39:55,169] Trial 487 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:39:55,942] Trial 488 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:39:56,696] Trial 489 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:39:57,465] Trial 490 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:39:58,098] Trial 491 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:39:58,759] Trial 492 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:40:13,525] Trial 493 pruned. Trial was pruned at iteration 118.\n",
      "[I 2025-02-12 23:40:14,256] Trial 494 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:40:14,933] Trial 495 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:40:15,698] Trial 496 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:40:16,408] Trial 497 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:40:17,129] Trial 498 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-12 23:40:17,857] Trial 499 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================\n",
      "Number of finished trials: 500\n",
      "Best trial: 35\n",
      "Best value (RMSE): 38.69333109924226\n",
      "Best hyperparameters: {'bagging_fraction': 0.9845855827369719, 'bagging_freq': 4, 'cat_l2': 15.56109518501091, 'extra_trees': False, 'feature_fraction': 0.7854276569810373, 'learning_rate': 0.049027872072879605, 'max_bin': 2602, 'max_depth': 920, 'min_samples_leaf': 10, 'n_estimators': 4023, 'num_leaves': 35, 'lambda_l1': 0.00512002046717473, 'lambda_l2': 3.014253881843341e-07}\n"
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "    params = {\n",
    "        'random_state': 42,\n",
    "        'early_stopping_rounds': 50, # the {n}th accuracy on the validation set does not improve, stop training\n",
    "        'verbose': -1,  # -1: Fatal, 0: Warning, 1: Info, 2: Debug\n",
    "        'objective': 'regression',\n",
    "        'metric': 'rmse',\n",
    "        'force_row_wise': True,\n",
    "\n",
    "        # bagging_fraction is like feature_fraction, but randomly selects data without resampling\n",
    "        # bagging_freq must be non-zero to enable bagging\n",
    "        'bagging_fraction': trial.suggest_float('bagging_fraction', 0.4, 1.0),\n",
    "        'bagging_freq': trial.suggest_int('bagging_freq', 1, 7),\n",
    "\n",
    "        # default = 10.0,  used for the categorical features\n",
    "        'cat_l2':  trial.suggest_float('cat_l2', 0.01, 20),\n",
    "\n",
    "        # if set to true, when evaluating node splits LightGBM will check only one randomly-chosen threshold for each feature\n",
    "        'extra_trees': trial.suggest_categorical(\"extra_trees\", [True, False]),\n",
    "\n",
    "        # subset of features on each iteration (tree) to select\n",
    "        'feature_fraction': trial.suggest_float('feature_fraction', 0.4, 1.0),\n",
    "        # colsample_bytree is ignored when feature_fraction is set\n",
    "        # 'colsample_bytree': trial.suggest_float('colsample_bytree', 0.25, 0.35),\n",
    "\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.05, log=True),\n",
    "\n",
    "        # max number of bins that feature values will be bucketed in\n",
    "        'max_bin': trial.suggest_int('max_bin', 1, 10000),\n",
    "\n",
    "        # <= 0 means no limit. Used to deal with over-fitting when data is small. Tree still grows leaf-wise. \n",
    "        'max_depth': trial.suggest_int('max_depth', -1, 1000),  \n",
    "\n",
    "        # Very important to prevent over-fitting. Setting it to hundreds or thousands is enough for a large dataset.\n",
    "        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 5, 100),\n",
    "        'min_split_gain': 0.5,\n",
    "        \n",
    "        'n_estimators': trial.suggest_int('n_estimators', 10, 15000),\n",
    "\n",
    "        # main parameter to control the complexity of the tree model. Should be smaller than 2^max_depth\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 2, 256),\n",
    "\n",
    "        'lambda_l1': trial.suggest_float('lambda_l1', 1e-8, 10.0, log=True),\n",
    "        'lambda_l2': trial.suggest_float('lambda_l2', 1e-8, 10.0, log=True),\n",
    "\n",
    "        # subsample is ignored when bagging_fraction is set\n",
    "        # 'subsample': trial.suggest_float('subsample', 0.2, 0.25),\n",
    "        \n",
    "    }\n",
    "\n",
    "\n",
    "    rmse_list = []\n",
    "    for i, (train_fold, valid_fold) in enumerate(data_splits, 1):\n",
    "\n",
    "        train_data = lgb.Dataset(train_fold[feature_list], label=train_fold[target])\n",
    "        valid_data = lgb.Dataset(valid_fold[feature_list], label=valid_fold[target], reference=train_data)\n",
    "      \n",
    "        model = lgb.train(\n",
    "            params=params,\n",
    "            train_set=train_data,\n",
    "            valid_sets=[train_data, valid_data],\n",
    "            valid_names=['train_0', 'valid_0'],\n",
    "            callbacks=[\n",
    "                LightGBMPruningCallback(trial, \"rmse\", valid_name=\"valid_0\"),\n",
    "                lgb.log_evaluation(-1)                   # Suppress training logs\n",
    "            ]\n",
    "        )\n",
    "        y_pred = model.predict(valid_fold[feature_list], num_iteration=model.best_iteration)\n",
    "        rmse = root_mean_squared_error(valid_fold[target], y_pred)\n",
    "        rmse_list.append(rmse)\n",
    "\n",
    "    return np.mean(rmse_list)\n",
    "\n",
    "study = optuna.create_study(\n",
    "        storage=f\"sqlite:///..//optuna//{model_str}db.sqlite3\",\n",
    "        study_name=model_str + datetime.now().strftime(\"%Y-%m-%d_%H-%M\"),\n",
    "        direction=\"minimize\"\n",
    ")\n",
    "study.optimize(objective, n_trials=500)\n",
    "\n",
    "print(\"\\n=========================\")\n",
    "print(\"Number of finished trials:\", len(study.trials))\n",
    "print(\"Best trial:\", study.best_trial.number)\n",
    "print(\"Best value (RMSE):\", study.best_trial.value)\n",
    "print(\"Best hyperparameters:\", study.best_trial.params)\n",
    "best_params = study.best_trial.params\n",
    "best_params[\"random_state\"] = 42\n",
    "best_params[\"verbose\"] = 0\n",
    "best_params[\"metric\"] = \"rmse\"\n",
    "best_params[\"force_row_wise\"] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params[\"metric\"] = \"rmse\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-10 16:12:57,048] A new study created in RDB with name: lgb_2025-02-10_16-12\n",
      "[I 2025-02-10 16:14:29,880] Trial 0 finished with value: 38.881400057939125 and parameters: {'bagging_fraction': 0.840860690707638, 'bagging_freq': 4, 'feature_fraction': 0.4327437371672223, 'colsample_bytree': 0.27123178257561686, 'learning_rate': 0.01181218118543953, 'max_bin': 40397, 'max_depth': 314, 'min_samples_leaf ': 405, 'num_leaves': 95, 'lambda_l1': 7.104347070373837, 'lambda_l2': 6.756986444085797e-07, 'subsample': 0.2009042462404373}. Best is trial 0 with value: 38.881400057939125.\n",
      "[I 2025-02-10 16:17:02,880] Trial 1 finished with value: 38.87563925301222 and parameters: {'bagging_fraction': 0.8100915026859583, 'bagging_freq': 1, 'feature_fraction': 0.8341978103915103, 'colsample_bytree': 0.299271275945817, 'learning_rate': 0.015175000960921125, 'max_bin': 51190, 'max_depth': 296, 'min_samples_leaf ': 248, 'num_leaves': 205, 'lambda_l1': 0.010176531803973233, 'lambda_l2': 1.0019447772714834e-07, 'subsample': 0.20531689863629568}. Best is trial 1 with value: 38.87563925301222.\n",
      "[I 2025-02-10 16:18:37,193] Trial 2 finished with value: 38.880508546357696 and parameters: {'bagging_fraction': 0.8940287438990174, 'bagging_freq': 1, 'feature_fraction': 0.7902381602813443, 'colsample_bytree': 0.2679152006414425, 'learning_rate': 0.012079468527688738, 'max_bin': 44060, 'max_depth': 579, 'min_samples_leaf ': 578, 'num_leaves': 77, 'lambda_l1': 7.817800793329733, 'lambda_l2': 0.0037006478375611446, 'subsample': 0.2288906021911065}. Best is trial 1 with value: 38.87563925301222.\n",
      "[I 2025-02-10 16:20:06,609] Trial 3 finished with value: 38.873442350057786 and parameters: {'bagging_fraction': 0.992964653109293, 'bagging_freq': 5, 'feature_fraction': 0.8369571244222647, 'colsample_bytree': 0.3114130832251919, 'learning_rate': 0.020462955713619294, 'max_bin': 6351, 'max_depth': 40, 'min_samples_leaf ': 123, 'num_leaves': 76, 'lambda_l1': 1.768743017906015e-05, 'lambda_l2': 0.03825849348178752, 'subsample': 0.21142640534509022}. Best is trial 3 with value: 38.873442350057786.\n",
      "[I 2025-02-10 16:21:53,729] Trial 4 finished with value: 38.879809595778745 and parameters: {'bagging_fraction': 0.8261668525081944, 'bagging_freq': 1, 'feature_fraction': 0.5550728033587248, 'colsample_bytree': 0.307285218707429, 'learning_rate': 0.025010911300886573, 'max_bin': 26958, 'max_depth': 138, 'min_samples_leaf ': 963, 'num_leaves': 175, 'lambda_l1': 0.010396230932418125, 'lambda_l2': 3.472494722067177e-08, 'subsample': 0.23271739105480024}. Best is trial 3 with value: 38.873442350057786.\n",
      "[I 2025-02-10 16:23:34,071] Trial 5 finished with value: 38.874651345200654 and parameters: {'bagging_fraction': 0.8163998236961906, 'bagging_freq': 2, 'feature_fraction': 0.5240229569669733, 'colsample_bytree': 0.3311945110047566, 'learning_rate': 0.033679532874518324, 'max_bin': 41207, 'max_depth': 291, 'min_samples_leaf ': 406, 'num_leaves': 121, 'lambda_l1': 3.0066894233926984, 'lambda_l2': 1.8533456163986699e-07, 'subsample': 0.21185259529673653}. Best is trial 3 with value: 38.873442350057786.\n",
      "[I 2025-02-10 16:23:35,630] Trial 6 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 16:23:37,174] Trial 7 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 16:24:39,083] Trial 8 finished with value: 38.875295356223724 and parameters: {'bagging_fraction': 0.8245311446037096, 'bagging_freq': 1, 'feature_fraction': 0.4539442316870154, 'colsample_bytree': 0.2688051578524176, 'learning_rate': 0.04684937733243808, 'max_bin': 39468, 'max_depth': 918, 'min_samples_leaf ': 589, 'num_leaves': 71, 'lambda_l1': 0.002391941988278411, 'lambda_l2': 0.00024858227521999004, 'subsample': 0.22056297449042656}. Best is trial 3 with value: 38.873442350057786.\n",
      "[I 2025-02-10 16:24:40,597] Trial 9 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 16:24:41,698] Trial 10 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 16:25:07,745] Trial 11 pruned. Trial was pruned at iteration 128.\n",
      "[I 2025-02-10 16:25:10,943] Trial 12 pruned. Trial was pruned at iteration 28.\n",
      "[I 2025-02-10 16:25:12,442] Trial 13 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 16:25:29,542] Trial 14 pruned. Trial was pruned at iteration 131.\n",
      "[I 2025-02-10 16:26:39,747] Trial 15 finished with value: 38.87256283913718 and parameters: {'bagging_fraction': 0.965996904081626, 'bagging_freq': 2, 'feature_fraction': 0.8667457314732662, 'colsample_bytree': 0.2895870926445725, 'learning_rate': 0.049859406614844906, 'max_bin': 82068, 'max_depth': 496, 'min_samples_leaf ': 31, 'num_leaves': 123, 'lambda_l1': 0.0010762561433218514, 'lambda_l2': 0.09644256594462344, 'subsample': 0.23926406959297547}. Best is trial 15 with value: 38.87256283913718.\n",
      "[I 2025-02-10 16:27:59,094] Trial 16 finished with value: 38.87240889164817 and parameters: {'bagging_fraction': 0.9766762172926573, 'bagging_freq': 5, 'feature_fraction': 0.875313636840828, 'colsample_bytree': 0.28890475608415966, 'learning_rate': 0.043348211009500676, 'max_bin': 83398, 'max_depth': 800, 'min_samples_leaf ': 5, 'num_leaves': 155, 'lambda_l1': 0.0005200813096715688, 'lambda_l2': 0.07677488506253069, 'subsample': 0.2404837838889275}. Best is trial 16 with value: 38.87240889164817.\n",
      "[I 2025-02-10 16:29:16,284] Trial 17 finished with value: 38.87279886313705 and parameters: {'bagging_fraction': 0.9641554936335884, 'bagging_freq': 7, 'feature_fraction': 0.9829032432528372, 'colsample_bytree': 0.28493829015471495, 'learning_rate': 0.04704101582811815, 'max_bin': 96525, 'max_depth': 736, 'min_samples_leaf ': 17, 'num_leaves': 164, 'lambda_l1': 0.0011013786426625025, 'lambda_l2': 0.08853919777074547, 'subsample': 0.2419167446694408}. Best is trial 16 with value: 38.87240889164817.\n",
      "[I 2025-02-10 16:31:03,625] Trial 18 finished with value: 38.87390319146228 and parameters: {'bagging_fraction': 0.9703077734366702, 'bagging_freq': 2, 'feature_fraction': 0.8995374920131599, 'colsample_bytree': 0.28796799795612077, 'learning_rate': 0.04162390185700527, 'max_bin': 72169, 'max_depth': 767, 'min_samples_leaf ': 262, 'num_leaves': 154, 'lambda_l1': 0.05439099303053454, 'lambda_l2': 0.0017951422074961607, 'subsample': 0.2382529015680273}. Best is trial 16 with value: 38.87240889164817.\n",
      "[I 2025-02-10 16:32:29,110] Trial 19 finished with value: 38.872311238744125 and parameters: {'bagging_fraction': 0.9161394631360077, 'bagging_freq': 6, 'feature_fraction': 0.768109484739912, 'colsample_bytree': 0.2981784990377958, 'learning_rate': 0.03850635526883676, 'max_bin': 85093, 'max_depth': 503, 'min_samples_leaf ': 75, 'num_leaves': 109, 'lambda_l1': 0.0004928221993964978, 'lambda_l2': 0.2789535227470667, 'subsample': 0.24971144499130768}. Best is trial 19 with value: 38.872311238744125.\n",
      "[I 2025-02-10 16:34:24,957] Trial 20 finished with value: 38.87505629995724 and parameters: {'bagging_fraction': 0.9353931243137196, 'bagging_freq': 6, 'feature_fraction': 0.7387129053443675, 'colsample_bytree': 0.298774705616986, 'learning_rate': 0.039844328427465214, 'max_bin': 85314, 'max_depth': 580, 'min_samples_leaf ': 315, 'num_leaves': 255, 'lambda_l1': 1.3127407136303898e-06, 'lambda_l2': 0.18851025548812583, 'subsample': 0.24855805609468387}. Best is trial 19 with value: 38.872311238744125.\n",
      "[I 2025-02-10 16:35:42,433] Trial 21 finished with value: 38.872544242840256 and parameters: {'bagging_fraction': 0.9094644743109628, 'bagging_freq': 6, 'feature_fraction': 0.8709849721088809, 'colsample_bytree': 0.2799388311718406, 'learning_rate': 0.04119285574959486, 'max_bin': 81610, 'max_depth': 468, 'min_samples_leaf ': 80, 'num_leaves': 114, 'lambda_l1': 0.00036551273309386124, 'lambda_l2': 0.016152709356200935, 'subsample': 0.24162782428293758}. Best is trial 19 with value: 38.872311238744125.\n",
      "[I 2025-02-10 16:37:07,854] Trial 22 finished with value: 38.872858739687224 and parameters: {'bagging_fraction': 0.9109643630260923, 'bagging_freq': 6, 'feature_fraction': 0.764903174230542, 'colsample_bytree': 0.27970382714950853, 'learning_rate': 0.04039946350160504, 'max_bin': 85838, 'max_depth': 991, 'min_samples_leaf ': 122, 'num_leaves': 115, 'lambda_l1': 8.923201663778506e-05, 'lambda_l2': 0.015751549956032788, 'subsample': 0.24516639083838054}. Best is trial 19 with value: 38.872311238744125.\n",
      "[I 2025-02-10 16:37:09,344] Trial 23 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 16:38:43,414] Trial 24 finished with value: 38.873237113742455 and parameters: {'bagging_fraction': 0.8730085374814311, 'bagging_freq': 5, 'feature_fraction': 0.8375326217990378, 'colsample_bytree': 0.27703189647775495, 'learning_rate': 0.039476331968445307, 'max_bin': 76674, 'max_depth': 610, 'min_samples_leaf ': 80, 'num_leaves': 180, 'lambda_l1': 0.008828300349773943, 'lambda_l2': 0.3062369889157415, 'subsample': 0.243881380392886}. Best is trial 19 with value: 38.872311238744125.\n",
      "[I 2025-02-10 16:40:11,629] Trial 25 finished with value: 38.872910785595764 and parameters: {'bagging_fraction': 0.9199209306543097, 'bagging_freq': 7, 'feature_fraction': 0.736279068768551, 'colsample_bytree': 0.2962286394904347, 'learning_rate': 0.04276071219875766, 'max_bin': 90827, 'max_depth': 790, 'min_samples_leaf ': 200, 'num_leaves': 142, 'lambda_l1': 3.5524894245743117e-06, 'lambda_l2': 0.014968476390277877, 'subsample': 0.2497315015265829}. Best is trial 19 with value: 38.872311238744125.\n",
      "[I 2025-02-10 16:40:13,170] Trial 26 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 16:40:14,573] Trial 27 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 16:40:16,233] Trial 28 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 16:40:17,941] Trial 29 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 16:40:19,521] Trial 30 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 16:41:26,755] Trial 31 finished with value: 38.872627370814605 and parameters: {'bagging_fraction': 0.9790675449191159, 'bagging_freq': 5, 'feature_fraction': 0.8495878041191967, 'colsample_bytree': 0.29134792104758667, 'learning_rate': 0.04952037964013949, 'max_bin': 80172, 'max_depth': 504, 'min_samples_leaf ': 17, 'num_leaves': 109, 'lambda_l1': 0.0006321135560075602, 'lambda_l2': 0.09936334582181608, 'subsample': 0.2396358989234195}. Best is trial 19 with value: 38.872311238744125.\n",
      "[I 2025-02-10 16:41:28,398] Trial 32 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 16:41:30,039] Trial 33 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 16:42:54,840] Trial 34 finished with value: 38.874183099006096 and parameters: {'bagging_fraction': 0.8860579973718118, 'bagging_freq': 5, 'feature_fraction': 0.7918351842796817, 'colsample_bytree': 0.2618840259434571, 'learning_rate': 0.04912730785270539, 'max_bin': 90805, 'max_depth': 477, 'min_samples_leaf ': 271, 'num_leaves': 164, 'lambda_l1': 7.606867353532607e-05, 'lambda_l2': 0.11142830750012432, 'subsample': 0.22800489875755434}. Best is trial 19 with value: 38.872311238744125.\n",
      "[I 2025-02-10 16:42:56,443] Trial 35 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 16:44:18,704] Trial 36 finished with value: 38.87278966971693 and parameters: {'bagging_fraction': 0.9452349578745701, 'bagging_freq': 4, 'feature_fraction': 0.8072274131878023, 'colsample_bytree': 0.3004394621112341, 'learning_rate': 0.04475811641659714, 'max_bin': 75605, 'max_depth': 614, 'min_samples_leaf ': 125, 'num_leaves': 139, 'lambda_l1': 0.0014747108262594013, 'lambda_l2': 0.04088287668310773, 'subsample': 0.2431621383045311}. Best is trial 19 with value: 38.872311238744125.\n",
      "[I 2025-02-10 16:45:33,845] Trial 37 finished with value: 38.872712457800425 and parameters: {'bagging_fraction': 0.9624890894015004, 'bagging_freq': 7, 'feature_fraction': 0.9300488274307255, 'colsample_bytree': 0.2739014949080855, 'learning_rate': 0.04995938443357382, 'max_bin': 66240, 'max_depth': 239, 'min_samples_leaf ': 7, 'num_leaves': 116, 'lambda_l1': 1.1250893633761344e-05, 'lambda_l2': 0.33539742190717475, 'subsample': 0.24672057833521266}. Best is trial 19 with value: 38.872311238744125.\n",
      "[I 2025-02-10 16:45:35,448] Trial 38 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 16:45:36,992] Trial 39 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 16:45:38,759] Trial 40 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 16:46:55,917] Trial 41 finished with value: 38.87170486450842 and parameters: {'bagging_fraction': 0.984419079321423, 'bagging_freq': 5, 'feature_fraction': 0.8532012621795694, 'colsample_bytree': 0.2891073537877863, 'learning_rate': 0.04975002376769362, 'max_bin': 80386, 'max_depth': 502, 'min_samples_leaf ': 44, 'num_leaves': 109, 'lambda_l1': 0.0006442284100744136, 'lambda_l2': 0.08203642681030315, 'subsample': 0.23858022433058348}. Best is trial 41 with value: 38.87170486450842.\n",
      "[I 2025-02-10 16:48:13,421] Trial 42 finished with value: 38.87216555843739 and parameters: {'bagging_fraction': 0.9721623541559958, 'bagging_freq': 6, 'feature_fraction': 0.8668246676282066, 'colsample_bytree': 0.30831522327190736, 'learning_rate': 0.04536764166689039, 'max_bin': 86668, 'max_depth': 544, 'min_samples_leaf ': 54, 'num_leaves': 102, 'lambda_l1': 0.0006979548571775438, 'lambda_l2': 0.06394769056206966, 'subsample': 0.23206475048764275}. Best is trial 41 with value: 38.87170486450842.\n",
      "[I 2025-02-10 16:48:30,428] Trial 43 pruned. Trial was pruned at iteration 96.\n",
      "[I 2025-02-10 16:48:31,949] Trial 44 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 16:48:33,476] Trial 45 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 16:48:37,066] Trial 46 pruned. Trial was pruned at iteration 9.\n",
      "[I 2025-02-10 16:48:38,566] Trial 47 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 16:48:40,189] Trial 48 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 16:48:41,735] Trial 49 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 16:48:43,432] Trial 50 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 16:49:50,791] Trial 51 finished with value: 38.87275973711834 and parameters: {'bagging_fraction': 0.9723273606832333, 'bagging_freq': 5, 'feature_fraction': 0.8604369928954524, 'colsample_bytree': 0.29041805988380875, 'learning_rate': 0.04817707447625239, 'max_bin': 82621, 'max_depth': 487, 'min_samples_leaf ': 5, 'num_leaves': 121, 'lambda_l1': 0.0012501416249091199, 'lambda_l2': 0.08418858899332073, 'subsample': 0.23932635970137264}. Best is trial 41 with value: 38.87170486450842.\n",
      "[I 2025-02-10 16:51:07,093] Trial 52 finished with value: 38.87227850178483 and parameters: {'bagging_fraction': 0.9582028445612095, 'bagging_freq': 5, 'feature_fraction': 0.8725588773707901, 'colsample_bytree': 0.2965128422467639, 'learning_rate': 0.04622314853161318, 'max_bin': 87401, 'max_depth': 555, 'min_samples_leaf ': 45, 'num_leaves': 122, 'lambda_l1': 0.0009406442333179442, 'lambda_l2': 0.4434251389355839, 'subsample': 0.24412831879218092}. Best is trial 41 with value: 38.87170486450842.\n",
      "[I 2025-02-10 16:51:23,524] Trial 53 pruned. Trial was pruned at iteration 74.\n",
      "[I 2025-02-10 16:51:25,032] Trial 54 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 16:52:34,302] Trial 55 finished with value: 38.87210647060375 and parameters: {'bagging_fraction': 0.98533883652405, 'bagging_freq': 5, 'feature_fraction': 0.8478706222093338, 'colsample_bytree': 0.30905589333524885, 'learning_rate': 0.046564171940023616, 'max_bin': 18610, 'max_depth': 985, 'min_samples_leaf ': 47, 'num_leaves': 126, 'lambda_l1': 0.001853365662978104, 'lambda_l2': 0.18835857864437777, 'subsample': 0.24993928075059674}. Best is trial 41 with value: 38.87170486450842.\n",
      "[I 2025-02-10 16:53:40,284] Trial 56 finished with value: 38.87227004865471 and parameters: {'bagging_fraction': 0.9829563918175481, 'bagging_freq': 4, 'feature_fraction': 0.8374265621065186, 'colsample_bytree': 0.31121836562306454, 'learning_rate': 0.04731243097658386, 'max_bin': 22758, 'max_depth': 912, 'min_samples_leaf ': 44, 'num_leaves': 135, 'lambda_l1': 0.01566696102869155, 'lambda_l2': 0.256265167778812, 'subsample': 0.24531576187206977}. Best is trial 41 with value: 38.87170486450842.\n",
      "[I 2025-02-10 16:53:58,326] Trial 57 pruned. Trial was pruned at iteration 96.\n",
      "[I 2025-02-10 16:55:00,192] Trial 58 finished with value: 38.87256765704067 and parameters: {'bagging_fraction': 0.9960988008744308, 'bagging_freq': 4, 'feature_fraction': 0.8109848813351267, 'colsample_bytree': 0.3104429143656889, 'learning_rate': 0.046382825489052794, 'max_bin': 19873, 'max_depth': 943, 'min_samples_leaf ': 58, 'num_leaves': 131, 'lambda_l1': 0.006804426297552154, 'lambda_l2': 0.34515350187618754, 'subsample': 0.24844897358137125}. Best is trial 41 with value: 38.87170486450842.\n",
      "[I 2025-02-10 16:55:01,680] Trial 59 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 16:55:03,251] Trial 60 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 16:56:13,142] Trial 61 finished with value: 38.87273664870413 and parameters: {'bagging_fraction': 0.9760671891403822, 'bagging_freq': 5, 'feature_fraction': 0.8929272166336917, 'colsample_bytree': 0.30789635414944627, 'learning_rate': 0.04341203891137629, 'max_bin': 21503, 'max_depth': 925, 'min_samples_leaf ': 40, 'num_leaves': 133, 'lambda_l1': 0.0009153705306009744, 'lambda_l2': 0.06916776841962595, 'subsample': 0.20049405056678973}. Best is trial 41 with value: 38.87170486450842.\n",
      "[I 2025-02-10 16:57:26,872] Trial 62 finished with value: 38.87253130541811 and parameters: {'bagging_fraction': 0.999815890243517, 'bagging_freq': 5, 'feature_fraction': 0.8440569998469352, 'colsample_bytree': 0.2998336328251495, 'learning_rate': 0.04705146648367374, 'max_bin': 44333, 'max_depth': 850, 'min_samples_leaf ': 44, 'num_leaves': 161, 'lambda_l1': 0.016895681225004355, 'lambda_l2': 0.3236072918533248, 'subsample': 0.24248101429292676}. Best is trial 41 with value: 38.87170486450842.\n",
      "[I 2025-02-10 16:57:28,503] Trial 63 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 16:58:45,226] Trial 64 finished with value: 38.87265356469717 and parameters: {'bagging_fraction': 0.9887239290903254, 'bagging_freq': 5, 'feature_fraction': 0.872998321770184, 'colsample_bytree': 0.31592765117681354, 'learning_rate': 0.04515181118879105, 'max_bin': 24758, 'max_depth': 954, 'min_samples_leaf ': 6, 'num_leaves': 172, 'lambda_l1': 0.0023426810475396563, 'lambda_l2': 0.1381874266228432, 'subsample': 0.24742943477752874}. Best is trial 41 with value: 38.87170486450842.\n",
      "[I 2025-02-10 16:59:46,578] Trial 65 finished with value: 38.8727057129832 and parameters: {'bagging_fraction': 0.9459140615112926, 'bagging_freq': 4, 'feature_fraction': 0.7645964604745237, 'colsample_bytree': 0.30449139177053564, 'learning_rate': 0.04771002676476926, 'max_bin': 96226, 'max_depth': 844, 'min_samples_leaf ': 37, 'num_leaves': 108, 'lambda_l1': 0.0003762513148079797, 'lambda_l2': 0.06805453190557888, 'subsample': 0.2388871152819573}. Best is trial 41 with value: 38.87170486450842.\n",
      "[I 2025-02-10 16:59:48,242] Trial 66 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 16:59:49,917] Trial 67 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 16:59:51,457] Trial 68 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 16:59:53,010] Trial 69 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 16:59:54,578] Trial 70 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 17:01:16,102] Trial 71 finished with value: 38.87214982715102 and parameters: {'bagging_fraction': 0.9966051294951637, 'bagging_freq': 5, 'feature_fraction': 0.8450131987476635, 'colsample_bytree': 0.2988337055645749, 'learning_rate': 0.047758797245887476, 'max_bin': 73545, 'max_depth': 832, 'min_samples_leaf ': 43, 'num_leaves': 156, 'lambda_l1': 0.05513878835417552, 'lambda_l2': 0.28479075344879357, 'subsample': 0.24283229061858796}. Best is trial 41 with value: 38.87170486450842.\n",
      "[I 2025-02-10 17:02:32,285] Trial 72 finished with value: 38.87249662008074 and parameters: {'bagging_fraction': 0.9915748584849181, 'bagging_freq': 5, 'feature_fraction': 0.8715877058462551, 'colsample_bytree': 0.29787373382908267, 'learning_rate': 0.04999647801448443, 'max_bin': 73480, 'max_depth': 813, 'min_samples_leaf ': 70, 'num_leaves': 139, 'lambda_l1': 0.1063682034029316, 'lambda_l2': 0.1961916431724373, 'subsample': 0.24283412003756183}. Best is trial 41 with value: 38.87170486450842.\n",
      "[I 2025-02-10 17:02:33,992] Trial 73 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 17:02:57,455] Trial 74 pruned. Trial was pruned at iteration 89.\n",
      "[I 2025-02-10 17:02:59,032] Trial 75 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 17:03:00,928] Trial 76 pruned. Trial was pruned at iteration 1.\n",
      "[I 2025-02-10 17:03:07,930] Trial 77 pruned. Trial was pruned at iteration 24.\n",
      "[I 2025-02-10 17:03:09,619] Trial 78 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 17:04:27,457] Trial 79 finished with value: 38.872780650004835 and parameters: {'bagging_fraction': 0.9858938282107121, 'bagging_freq': 4, 'feature_fraction': 0.8015478992078047, 'colsample_bytree': 0.28943277873165646, 'learning_rate': 0.04709978246619987, 'max_bin': 74160, 'max_depth': 835, 'min_samples_leaf ': 26, 'num_leaves': 159, 'lambda_l1': 0.0007604689158031029, 'lambda_l2': 0.05215033153326054, 'subsample': 0.24218499620369374}. Best is trial 41 with value: 38.87170486450842.\n",
      "[I 2025-02-10 17:04:28,998] Trial 80 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 17:05:48,156] Trial 81 finished with value: 38.872157541914945 and parameters: {'bagging_fraction': 0.9917533249563665, 'bagging_freq': 5, 'feature_fraction': 0.8337248707929605, 'colsample_bytree': 0.2972119496214161, 'learning_rate': 0.04980705645200836, 'max_bin': 72573, 'max_depth': 745, 'min_samples_leaf ': 69, 'num_leaves': 140, 'lambda_l1': 0.0726124842728314, 'lambda_l2': 0.22582219086905625, 'subsample': 0.23432169993572394}. Best is trial 41 with value: 38.87170486450842.\n",
      "[I 2025-02-10 17:07:01,596] Trial 82 finished with value: 38.87243307651621 and parameters: {'bagging_fraction': 0.9915127426371598, 'bagging_freq': 5, 'feature_fraction': 0.8299369338419398, 'colsample_bytree': 0.3055444781275531, 'learning_rate': 0.04832021717964903, 'max_bin': 68668, 'max_depth': 783, 'min_samples_leaf ': 71, 'num_leaves': 147, 'lambda_l1': 0.0030911183992821593, 'lambda_l2': 0.24993051092348456, 'subsample': 0.2345126610446143}. Best is trial 41 with value: 38.87170486450842.\n",
      "[I 2025-02-10 17:07:03,241] Trial 83 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 17:07:05,275] Trial 84 pruned. Trial was pruned at iteration 1.\n",
      "[I 2025-02-10 17:07:07,036] Trial 85 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 17:07:08,763] Trial 86 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 17:07:12,255] Trial 87 pruned. Trial was pruned at iteration 13.\n",
      "[I 2025-02-10 17:07:13,783] Trial 88 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 17:07:15,363] Trial 89 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 17:07:17,082] Trial 90 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 17:08:35,293] Trial 91 finished with value: 38.87216838786433 and parameters: {'bagging_fraction': 0.9882699259460914, 'bagging_freq': 5, 'feature_fraction': 0.8341957310720974, 'colsample_bytree': 0.3140312081217236, 'learning_rate': 0.048452716997566835, 'max_bin': 70149, 'max_depth': 803, 'min_samples_leaf ': 76, 'num_leaves': 146, 'lambda_l1': 0.00429338190501781, 'lambda_l2': 0.26137556295540987, 'subsample': 0.23489396469355292}. Best is trial 41 with value: 38.87170486450842.\n",
      "[I 2025-02-10 17:08:36,963] Trial 92 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 17:08:38,738] Trial 93 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 17:09:56,636] Trial 94 finished with value: 38.87197045715853 and parameters: {'bagging_fraction': 0.9885301369127943, 'bagging_freq': 5, 'feature_fraction': 0.8192821200625313, 'colsample_bytree': 0.30797107426172504, 'learning_rate': 0.04629169979209874, 'max_bin': 72831, 'max_depth': 580, 'min_samples_leaf ': 31, 'num_leaves': 142, 'lambda_l1': 0.015233841012159889, 'lambda_l2': 0.4198287165213361, 'subsample': 0.23846055308225972}. Best is trial 41 with value: 38.87170486450842.\n",
      "[I 2025-02-10 17:09:58,270] Trial 95 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 17:10:09,972] Trial 96 pruned. Trial was pruned at iteration 49.\n",
      "[I 2025-02-10 17:10:11,568] Trial 97 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 17:10:13,223] Trial 98 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 17:10:27,380] Trial 99 pruned. Trial was pruned at iteration 70.\n",
      "[I 2025-02-10 17:10:28,936] Trial 100 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 17:10:30,492] Trial 101 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 17:11:52,511] Trial 102 finished with value: 38.87255091167023 and parameters: {'bagging_fraction': 0.9933682854803639, 'bagging_freq': 5, 'feature_fraction': 0.8642366012889804, 'colsample_bytree': 0.31451473268345553, 'learning_rate': 0.04674247480517362, 'max_bin': 72062, 'max_depth': 859, 'min_samples_leaf ': 53, 'num_leaves': 149, 'lambda_l1': 0.0008413501900313383, 'lambda_l2': 0.17852518045260457, 'subsample': 0.24168652482386863}. Best is trial 41 with value: 38.87170486450842.\n",
      "[I 2025-02-10 17:12:02,875] Trial 103 pruned. Trial was pruned at iteration 34.\n",
      "[I 2025-02-10 17:12:04,557] Trial 104 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 17:12:06,285] Trial 105 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 17:12:07,944] Trial 106 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 17:12:09,688] Trial 107 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 17:12:11,358] Trial 108 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 17:12:15,126] Trial 109 pruned. Trial was pruned at iteration 10.\n",
      "[I 2025-02-10 17:12:16,860] Trial 110 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 17:12:36,549] Trial 111 pruned. Trial was pruned at iteration 91.\n",
      "[I 2025-02-10 17:12:38,132] Trial 112 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 17:13:49,317] Trial 113 finished with value: 38.87223110549093 and parameters: {'bagging_fraction': 0.9927663748685898, 'bagging_freq': 5, 'feature_fraction': 0.8344447123728895, 'colsample_bytree': 0.3060544806833946, 'learning_rate': 0.049751771084580516, 'max_bin': 78874, 'max_depth': 717, 'min_samples_leaf ': 38, 'num_leaves': 139, 'lambda_l1': 0.003794258083001107, 'lambda_l2': 0.9676407644168682, 'subsample': 0.2384096397027014}. Best is trial 41 with value: 38.87170486450842.\n",
      "[I 2025-02-10 17:14:07,118] Trial 114 pruned. Trial was pruned at iteration 95.\n",
      "[I 2025-02-10 17:14:17,379] Trial 115 pruned. Trial was pruned at iteration 39.\n",
      "[I 2025-02-10 17:14:19,093] Trial 116 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 17:14:20,711] Trial 117 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 17:14:30,102] Trial 118 pruned. Trial was pruned at iteration 34.\n",
      "[I 2025-02-10 17:14:31,971] Trial 119 pruned. Trial was pruned at iteration 1.\n",
      "[I 2025-02-10 17:14:33,530] Trial 120 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 17:15:53,209] Trial 121 finished with value: 38.87239481902687 and parameters: {'bagging_fraction': 0.9921744595702763, 'bagging_freq': 5, 'feature_fraction': 0.833506511360682, 'colsample_bytree': 0.30862782825509755, 'learning_rate': 0.04836524261794644, 'max_bin': 70501, 'max_depth': 725, 'min_samples_leaf ': 69, 'num_leaves': 146, 'lambda_l1': 0.0035207141779706823, 'lambda_l2': 0.21862782108542245, 'subsample': 0.23369596815165342}. Best is trial 41 with value: 38.87170486450842.\n",
      "[I 2025-02-10 17:16:07,751] Trial 122 pruned. Trial was pruned at iteration 63.\n",
      "[I 2025-02-10 17:16:09,329] Trial 123 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 17:16:29,973] Trial 124 pruned. Trial was pruned at iteration 95.\n",
      "[I 2025-02-10 17:16:38,251] Trial 125 pruned. Trial was pruned at iteration 28.\n",
      "[I 2025-02-10 17:16:39,899] Trial 126 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 17:16:41,655] Trial 127 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 17:16:43,333] Trial 128 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 17:16:45,011] Trial 129 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 17:16:55,001] Trial 130 pruned. Trial was pruned at iteration 42.\n",
      "[I 2025-02-10 17:18:14,709] Trial 131 finished with value: 38.87220704022615 and parameters: {'bagging_fraction': 0.9923174512451893, 'bagging_freq': 5, 'feature_fraction': 0.8308566788979295, 'colsample_bytree': 0.30567117184804443, 'learning_rate': 0.047624685902870126, 'max_bin': 69692, 'max_depth': 775, 'min_samples_leaf ': 63, 'num_leaves': 147, 'lambda_l1': 0.0021034368374901573, 'lambda_l2': 0.21179699007119002, 'subsample': 0.23430987565273934}. Best is trial 41 with value: 38.87170486450842.\n",
      "[I 2025-02-10 17:18:16,634] Trial 132 pruned. Trial was pruned at iteration 1.\n",
      "[I 2025-02-10 17:19:32,939] Trial 133 finished with value: 38.87230408376073 and parameters: {'bagging_fraction': 0.9878621104331843, 'bagging_freq': 5, 'feature_fraction': 0.8789815035417615, 'colsample_bytree': 0.29784788489986724, 'learning_rate': 0.047133566419789115, 'max_bin': 73539, 'max_depth': 751, 'min_samples_leaf ': 5, 'num_leaves': 143, 'lambda_l1': 0.0026721557861852556, 'lambda_l2': 0.40417506412654386, 'subsample': 0.23890225764137238}. Best is trial 41 with value: 38.87170486450842.\n",
      "[I 2025-02-10 17:20:51,697] Trial 134 finished with value: 38.87190044914589 and parameters: {'bagging_fraction': 0.9878466165877651, 'bagging_freq': 5, 'feature_fraction': 0.8340229970719187, 'colsample_bytree': 0.2978110702205387, 'learning_rate': 0.04748838500857606, 'max_bin': 73966, 'max_depth': 734, 'min_samples_leaf ': 21, 'num_leaves': 143, 'lambda_l1': 0.0026701376748075774, 'lambda_l2': 0.9905807897235012, 'subsample': 0.23011003289564044}. Best is trial 41 with value: 38.87170486450842.\n",
      "[I 2025-02-10 17:22:12,590] Trial 135 finished with value: 38.87207243780451 and parameters: {'bagging_fraction': 0.9852275504106413, 'bagging_freq': 5, 'feature_fraction': 0.878713385620189, 'colsample_bytree': 0.29848525861573266, 'learning_rate': 0.04738863943633434, 'max_bin': 73994, 'max_depth': 741, 'min_samples_leaf ': 22, 'num_leaves': 142, 'lambda_l1': 0.002237252528884131, 'lambda_l2': 0.9597301196828134, 'subsample': 0.2301984009886817}. Best is trial 41 with value: 38.87170486450842.\n",
      "[I 2025-02-10 17:22:14,206] Trial 136 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 17:22:15,853] Trial 137 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 17:22:17,553] Trial 138 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 17:23:34,880] Trial 139 finished with value: 38.87224822815137 and parameters: {'bagging_fraction': 0.9797795624989935, 'bagging_freq': 4, 'feature_fraction': 0.942603402193528, 'colsample_bytree': 0.29870646648847793, 'learning_rate': 0.04739761018016498, 'max_bin': 75200, 'max_depth': 811, 'min_samples_leaf ': 7, 'num_leaves': 143, 'lambda_l1': 0.004797695121117316, 'lambda_l2': 0.41330726547334445, 'subsample': 0.23657449013888582}. Best is trial 41 with value: 38.87170486450842.\n",
      "[I 2025-02-10 17:23:36,558] Trial 140 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 17:23:38,246] Trial 141 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 17:24:59,360] Trial 142 finished with value: 38.872278975458094 and parameters: {'bagging_fraction': 0.9806861304649018, 'bagging_freq': 4, 'feature_fraction': 0.9413275925264972, 'colsample_bytree': 0.3038493959062312, 'learning_rate': 0.04744420313317658, 'max_bin': 70061, 'max_depth': 745, 'min_samples_leaf ': 6, 'num_leaves': 143, 'lambda_l1': 0.004767483809009547, 'lambda_l2': 0.7511535169588762, 'subsample': 0.22834685165488663}. Best is trial 41 with value: 38.87170486450842.\n",
      "[I 2025-02-10 17:26:11,236] Trial 143 finished with value: 38.87274146297636 and parameters: {'bagging_fraction': 0.9813681860077295, 'bagging_freq': 4, 'feature_fraction': 0.9313613817343576, 'colsample_bytree': 0.3015334178192824, 'learning_rate': 0.04995511750782645, 'max_bin': 71007, 'max_depth': 788, 'min_samples_leaf ': 25, 'num_leaves': 136, 'lambda_l1': 0.0051573325703952256, 'lambda_l2': 0.7108479962836715, 'subsample': 0.22886060471440234}. Best is trial 41 with value: 38.87170486450842.\n",
      "[I 2025-02-10 17:26:12,933] Trial 144 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 17:26:14,701] Trial 145 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 17:26:16,322] Trial 146 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 17:26:18,053] Trial 147 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 17:27:28,844] Trial 148 finished with value: 38.87248857932389 and parameters: {'bagging_fraction': 0.9893034264960049, 'bagging_freq': 4, 'feature_fraction': 0.9469967239123956, 'colsample_bytree': 0.3135127351301868, 'learning_rate': 0.04843071938215506, 'max_bin': 65194, 'max_depth': 896, 'min_samples_leaf ': 35, 'num_leaves': 155, 'lambda_l1': 0.05989003199529743, 'lambda_l2': 0.9978252787849213, 'subsample': 0.23406867887524296}. Best is trial 41 with value: 38.87170486450842.\n",
      "[I 2025-02-10 17:27:30,541] Trial 149 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 17:27:32,302] Trial 150 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 17:27:47,832] Trial 151 pruned. Trial was pruned at iteration 59.\n",
      "[I 2025-02-10 17:31:24,756] Trial 152 finished with value: 38.87238096120768 and parameters: {'bagging_fraction': 0.9998259502305948, 'bagging_freq': 3, 'feature_fraction': 0.8729464328397225, 'colsample_bytree': 0.3015782933325483, 'learning_rate': 0.04777633548340356, 'max_bin': 77244, 'max_depth': 758, 'min_samples_leaf ': 22, 'num_leaves': 144, 'lambda_l1': 0.001358684328368126, 'lambda_l2': 0.23884511088697521, 'subsample': 0.2365572436967146}. Best is trial 41 with value: 38.87170486450842.\n",
      "[I 2025-02-10 17:31:40,740] Trial 153 pruned. Trial was pruned at iteration 68.\n",
      "[I 2025-02-10 17:31:42,297] Trial 154 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 17:31:43,936] Trial 155 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 17:31:45,572] Trial 156 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 17:31:47,225] Trial 157 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 17:31:57,839] Trial 158 pruned. Trial was pruned at iteration 40.\n",
      "[I 2025-02-10 17:31:59,456] Trial 159 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 17:32:01,021] Trial 160 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 17:32:10,373] Trial 161 pruned. Trial was pruned at iteration 40.\n",
      "[I 2025-02-10 17:33:30,974] Trial 162 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 17:33:40,394] Trial 163 pruned. Trial was pruned at iteration 39.\n",
      "[I 2025-02-10 17:33:41,946] Trial 164 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 17:33:43,645] Trial 165 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 17:33:45,289] Trial 166 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 17:53:49,774] Trial 167 finished with value: 38.87307493789442 and parameters: {'bagging_fraction': 0.9345248730548721, 'bagging_freq': 5, 'feature_fraction': 0.8591037497580968, 'colsample_bytree': 0.29006699727216406, 'learning_rate': 0.049992654953684046, 'max_bin': 74776, 'max_depth': 495, 'min_samples_leaf ': 79, 'num_leaves': 132, 'lambda_l1': 0.0033978488970328197, 'lambda_l2': 0.1378657380238309, 'subsample': 0.23081100053937367}. Best is trial 41 with value: 38.87170486450842.\n",
      "[I 2025-02-10 17:53:51,285] Trial 168 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 17:53:52,932] Trial 169 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 17:55:45,878] Trial 170 finished with value: 38.872515887228936 and parameters: {'bagging_fraction': 0.9928685118987814, 'bagging_freq': 5, 'feature_fraction': 0.8345451620729007, 'colsample_bytree': 0.3058314182656639, 'learning_rate': 0.04795425262656979, 'max_bin': 77366, 'max_depth': 658, 'min_samples_leaf ': 60, 'num_leaves': 156, 'lambda_l1': 0.0066031684248408, 'lambda_l2': 0.27615118281663037, 'subsample': 0.24926661228635455}. Best is trial 41 with value: 38.87170486450842.\n",
      "[I 2025-02-10 17:57:02,057] Trial 171 finished with value: 38.872123487631775 and parameters: {'bagging_fraction': 0.9963933268550149, 'bagging_freq': 2, 'feature_fraction': 0.8738705619026377, 'colsample_bytree': 0.300826893306209, 'learning_rate': 0.04820784913795697, 'max_bin': 77405, 'max_depth': 760, 'min_samples_leaf ': 28, 'num_leaves': 144, 'lambda_l1': 0.001322675593141491, 'lambda_l2': 0.2055604391646719, 'subsample': 0.23616481556975394}. Best is trial 41 with value: 38.87170486450842.\n",
      "[I 2025-02-10 17:57:04,008] Trial 172 pruned. Trial was pruned at iteration 1.\n",
      "[I 2025-02-10 17:57:17,861] Trial 173 pruned. Trial was pruned at iteration 49.\n",
      "[I 2025-02-10 17:57:19,343] Trial 174 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 17:57:20,897] Trial 175 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 17:58:33,170] Trial 176 finished with value: 38.872116137287755 and parameters: {'bagging_fraction': 0.9796113560206692, 'bagging_freq': 1, 'feature_fraction': 0.9048746928648842, 'colsample_bytree': 0.3077132305914487, 'learning_rate': 0.04873210656044244, 'max_bin': 79316, 'max_depth': 685, 'min_samples_leaf ': 67, 'num_leaves': 146, 'lambda_l1': 0.11458221377918107, 'lambda_l2': 0.06177874776783632, 'subsample': 0.23335127383602403}. Best is trial 41 with value: 38.87170486450842.\n",
      "[I 2025-02-10 17:59:55,196] Trial 177 finished with value: 38.872403179586264 and parameters: {'bagging_fraction': 0.9784131582949875, 'bagging_freq': 2, 'feature_fraction': 0.9083904232511698, 'colsample_bytree': 0.3078905611364415, 'learning_rate': 0.04853960881990028, 'max_bin': 75873, 'max_depth': 682, 'min_samples_leaf ': 26, 'num_leaves': 146, 'lambda_l1': 0.0034956196779881757, 'lambda_l2': 0.06492247963853931, 'subsample': 0.23336000329419684}. Best is trial 41 with value: 38.87170486450842.\n",
      "[I 2025-02-10 17:59:56,873] Trial 178 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:00:12,538] Trial 179 pruned. Trial was pruned at iteration 78.\n",
      "[I 2025-02-10 18:00:14,095] Trial 180 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:00:24,081] Trial 181 pruned. Trial was pruned at iteration 44.\n",
      "[I 2025-02-10 18:00:25,700] Trial 182 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:00:27,251] Trial 183 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:01:30,687] Trial 184 finished with value: 38.872589031541516 and parameters: {'bagging_fraction': 0.9964522262585354, 'bagging_freq': 1, 'feature_fraction': 0.8628240365793609, 'colsample_bytree': 0.30076991525350216, 'learning_rate': 0.04827380884181114, 'max_bin': 85001, 'max_depth': 763, 'min_samples_leaf ': 41, 'num_leaves': 157, 'lambda_l1': 0.0022733840047716287, 'lambda_l2': 0.4617260743246139, 'subsample': 0.23843587313298586}. Best is trial 41 with value: 38.87170486450842.\n",
      "[I 2025-02-10 18:01:32,402] Trial 185 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:01:34,015] Trial 186 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:01:35,812] Trial 187 pruned. Trial was pruned at iteration 1.\n",
      "[I 2025-02-10 18:01:37,497] Trial 188 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:01:39,105] Trial 189 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:01:40,687] Trial 190 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:01:46,115] Trial 191 pruned. Trial was pruned at iteration 15.\n",
      "[I 2025-02-10 18:01:47,867] Trial 192 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:02:00,513] Trial 193 pruned. Trial was pruned at iteration 48.\n",
      "[I 2025-02-10 18:02:02,284] Trial 194 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:02:03,924] Trial 195 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:02:05,610] Trial 196 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:03:30,813] Trial 197 finished with value: 38.87257861658131 and parameters: {'bagging_fraction': 0.9998253515526775, 'bagging_freq': 2, 'feature_fraction': 0.9007325721618411, 'colsample_bytree': 0.3148165812997715, 'learning_rate': 0.04987356397249236, 'max_bin': 77206, 'max_depth': 741, 'min_samples_leaf ': 49, 'num_leaves': 145, 'lambda_l1': 0.07362934895847982, 'lambda_l2': 0.000792169056820141, 'subsample': 0.24994822001624348}. Best is trial 41 with value: 38.87170486450842.\n",
      "[I 2025-02-10 18:03:34,302] Trial 198 pruned. Trial was pruned at iteration 8.\n",
      "[I 2025-02-10 18:03:35,856] Trial 199 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:03:37,461] Trial 200 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:03:39,170] Trial 201 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:03:40,505] Trial 202 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:03:55,998] Trial 203 pruned. Trial was pruned at iteration 61.\n",
      "[I 2025-02-10 18:03:57,563] Trial 204 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:03:59,178] Trial 205 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:04:16,310] Trial 206 pruned. Trial was pruned at iteration 78.\n",
      "[I 2025-02-10 18:04:17,960] Trial 207 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:04:19,570] Trial 208 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:04:22,202] Trial 209 pruned. Trial was pruned at iteration 4.\n",
      "[I 2025-02-10 18:04:23,894] Trial 210 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:04:39,459] Trial 211 pruned. Trial was pruned at iteration 59.\n",
      "[I 2025-02-10 18:04:41,229] Trial 212 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:04:42,904] Trial 213 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:04:44,578] Trial 214 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:04:55,884] Trial 215 pruned. Trial was pruned at iteration 42.\n",
      "[I 2025-02-10 18:04:58,430] Trial 216 pruned. Trial was pruned at iteration 4.\n",
      "[I 2025-02-10 18:05:11,432] Trial 217 pruned. Trial was pruned at iteration 49.\n",
      "[I 2025-02-10 18:05:13,088] Trial 218 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:05:14,783] Trial 219 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:05:16,544] Trial 220 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:05:18,213] Trial 221 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:05:19,848] Trial 222 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:05:21,384] Trial 223 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:05:37,227] Trial 224 pruned. Trial was pruned at iteration 66.\n",
      "[I 2025-02-10 18:05:38,738] Trial 225 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:05:40,412] Trial 226 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:05:42,003] Trial 227 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:05:57,351] Trial 228 pruned. Trial was pruned at iteration 74.\n",
      "[I 2025-02-10 18:06:09,206] Trial 229 pruned. Trial was pruned at iteration 40.\n",
      "[I 2025-02-10 18:06:10,825] Trial 230 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:06:22,143] Trial 231 pruned. Trial was pruned at iteration 40.\n",
      "[I 2025-02-10 18:07:38,256] Trial 232 finished with value: 38.8720752132622 and parameters: {'bagging_fraction': 0.9916120353862082, 'bagging_freq': 5, 'feature_fraction': 0.8437918828995038, 'colsample_bytree': 0.3049565376903806, 'learning_rate': 0.04769758007821506, 'max_bin': 71265, 'max_depth': 748, 'min_samples_leaf ': 40, 'num_leaves': 144, 'lambda_l1': 0.006513703092067753, 'lambda_l2': 0.3507738398206449, 'subsample': 0.23518760719247372}. Best is trial 41 with value: 38.87170486450842.\n",
      "[I 2025-02-10 18:07:40,270] Trial 233 pruned. Trial was pruned at iteration 2.\n",
      "[I 2025-02-10 18:07:41,764] Trial 234 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:08:55,435] Trial 235 finished with value: 38.87252771180876 and parameters: {'bagging_fraction': 0.990887199921396, 'bagging_freq': 5, 'feature_fraction': 0.8366385042467177, 'colsample_bytree': 0.3047937133913801, 'learning_rate': 0.04996451285434722, 'max_bin': 76126, 'max_depth': 727, 'min_samples_leaf ': 46, 'num_leaves': 130, 'lambda_l1': 0.004530353552645275, 'lambda_l2': 0.44587529297726497, 'subsample': 0.2333769619168189}. Best is trial 41 with value: 38.87170486450842.\n",
      "[I 2025-02-10 18:09:12,875] Trial 236 pruned. Trial was pruned at iteration 66.\n",
      "[I 2025-02-10 18:09:14,516] Trial 237 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:09:27,115] Trial 238 pruned. Trial was pruned at iteration 49.\n",
      "[I 2025-02-10 18:09:28,764] Trial 239 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:09:30,378] Trial 240 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:09:34,241] Trial 241 pruned. Trial was pruned at iteration 9.\n",
      "[I 2025-02-10 18:09:35,881] Trial 242 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:10:56,880] Trial 243 finished with value: 38.872625329356815 and parameters: {'bagging_fraction': 0.9914313112080675, 'bagging_freq': 5, 'feature_fraction': 0.8458118516573562, 'colsample_bytree': 0.3070385115608457, 'learning_rate': 0.04992471435957114, 'max_bin': 68774, 'max_depth': 756, 'min_samples_leaf ': 23, 'num_leaves': 158, 'lambda_l1': 0.001985149103070565, 'lambda_l2': 0.5152810641150929, 'subsample': 0.2368692866419732}. Best is trial 41 with value: 38.87170486450842.\n",
      "[I 2025-02-10 18:10:58,569] Trial 244 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:11:09,029] Trial 245 pruned. Trial was pruned at iteration 36.\n",
      "[I 2025-02-10 18:11:10,728] Trial 246 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:11:12,295] Trial 247 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:11:19,750] Trial 248 pruned. Trial was pruned at iteration 23.\n",
      "[I 2025-02-10 18:11:21,350] Trial 249 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:11:22,972] Trial 250 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:11:24,544] Trial 251 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:11:26,161] Trial 252 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:11:27,746] Trial 253 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:11:29,424] Trial 254 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:11:31,135] Trial 255 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:11:32,817] Trial 256 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:11:34,327] Trial 257 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:11:35,920] Trial 258 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:11:37,377] Trial 259 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:11:47,180] Trial 260 pruned. Trial was pruned at iteration 37.\n",
      "[I 2025-02-10 18:11:48,928] Trial 261 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:11:50,560] Trial 262 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:11:52,210] Trial 263 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:11:53,963] Trial 264 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:12:07,777] Trial 265 pruned. Trial was pruned at iteration 54.\n",
      "[I 2025-02-10 18:12:09,376] Trial 266 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:12:11,059] Trial 267 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:12:12,643] Trial 268 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:13:15,857] Trial 269 finished with value: 38.87260552455731 and parameters: {'bagging_fraction': 0.9998581324245224, 'bagging_freq': 5, 'feature_fraction': 0.8201359205808229, 'colsample_bytree': 0.2992585348782513, 'learning_rate': 0.04991192200188425, 'max_bin': 74448, 'max_depth': 779, 'min_samples_leaf ': 21, 'num_leaves': 131, 'lambda_l1': 0.007546294934945045, 'lambda_l2': 0.1349162682917938, 'subsample': 0.2337740368304199}. Best is trial 41 with value: 38.87170486450842.\n",
      "[I 2025-02-10 18:13:17,396] Trial 270 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:13:18,983] Trial 271 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:13:20,601] Trial 272 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:14:19,849] Trial 273 finished with value: 38.87262656845649 and parameters: {'bagging_fraction': 0.9842367913811194, 'bagging_freq': 5, 'feature_fraction': 0.838920693621109, 'colsample_bytree': 0.3069209058712578, 'learning_rate': 0.04882683520843042, 'max_bin': 14849, 'max_depth': 686, 'min_samples_leaf ': 42, 'num_leaves': 150, 'lambda_l1': 0.05149989682379078, 'lambda_l2': 0.9822163197265441, 'subsample': 0.22999812232619407}. Best is trial 41 with value: 38.87170486450842.\n",
      "[I 2025-02-10 18:14:21,416] Trial 274 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:14:23,083] Trial 275 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:14:24,743] Trial 276 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:14:26,561] Trial 277 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:14:28,109] Trial 278 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:14:29,679] Trial 279 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:14:32,695] Trial 280 pruned. Trial was pruned at iteration 6.\n",
      "[I 2025-02-10 18:14:48,631] Trial 281 pruned. Trial was pruned at iteration 49.\n",
      "[I 2025-02-10 18:14:50,264] Trial 282 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:14:59,868] Trial 283 pruned. Trial was pruned at iteration 32.\n",
      "[I 2025-02-10 18:15:01,450] Trial 284 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:15:03,037] Trial 285 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:15:04,598] Trial 286 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:15:06,142] Trial 287 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:15:07,748] Trial 288 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:15:09,456] Trial 289 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:15:11,349] Trial 290 pruned. Trial was pruned at iteration 1.\n",
      "[I 2025-02-10 18:15:13,960] Trial 291 pruned. Trial was pruned at iteration 4.\n",
      "[I 2025-02-10 18:15:15,688] Trial 292 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:15:17,332] Trial 293 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:15:18,850] Trial 294 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:15:20,610] Trial 295 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:15:23,560] Trial 296 pruned. Trial was pruned at iteration 6.\n",
      "[I 2025-02-10 18:15:25,232] Trial 297 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:15:26,858] Trial 298 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:15:28,370] Trial 299 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:15:29,974] Trial 300 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:15:31,624] Trial 301 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:16:45,763] Trial 302 finished with value: 38.87277388357304 and parameters: {'bagging_fraction': 0.993690178097844, 'bagging_freq': 2, 'feature_fraction': 0.9345495261550872, 'colsample_bytree': 0.30323421000954204, 'learning_rate': 0.04996954151664497, 'max_bin': 87247, 'max_depth': 819, 'min_samples_leaf ': 6, 'num_leaves': 156, 'lambda_l1': 0.011069194976194406, 'lambda_l2': 0.28904551440800214, 'subsample': 0.24048624304815724}. Best is trial 41 with value: 38.87170486450842.\n",
      "[I 2025-02-10 18:16:47,481] Trial 303 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:16:49,124] Trial 304 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:16:50,750] Trial 305 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:16:52,419] Trial 306 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:16:54,075] Trial 307 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:17:02,014] Trial 308 pruned. Trial was pruned at iteration 28.\n",
      "[I 2025-02-10 18:17:03,622] Trial 309 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:17:05,350] Trial 310 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:17:06,978] Trial 311 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:17:08,737] Trial 312 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:17:10,271] Trial 313 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:17:11,874] Trial 314 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:17:13,457] Trial 315 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:17:14,996] Trial 316 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:17:16,609] Trial 317 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:17:33,625] Trial 318 pruned. Trial was pruned at iteration 67.\n",
      "[I 2025-02-10 18:17:35,123] Trial 319 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:17:36,755] Trial 320 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:17:38,379] Trial 321 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:18:54,119] Trial 322 finished with value: 38.872490222979074 and parameters: {'bagging_fraction': 0.9847943519081588, 'bagging_freq': 4, 'feature_fraction': 0.8883580336957859, 'colsample_bytree': 0.304471650788223, 'learning_rate': 0.04854010201311792, 'max_bin': 76429, 'max_depth': 755, 'min_samples_leaf ': 7, 'num_leaves': 145, 'lambda_l1': 0.008698443782226513, 'lambda_l2': 0.04487846603008186, 'subsample': 0.23628581407383228}. Best is trial 41 with value: 38.87170486450842.\n",
      "[I 2025-02-10 18:18:55,687] Trial 323 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:18:57,413] Trial 324 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:18:59,012] Trial 325 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:19:00,742] Trial 326 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:19:02,259] Trial 327 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:19:03,892] Trial 328 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:19:05,495] Trial 329 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:19:07,144] Trial 330 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:19:08,753] Trial 331 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:19:10,322] Trial 332 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:19:27,692] Trial 333 pruned. Trial was pruned at iteration 85.\n",
      "[I 2025-02-10 18:19:29,386] Trial 334 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:19:31,061] Trial 335 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:19:32,678] Trial 336 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:19:34,353] Trial 337 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:19:35,997] Trial 338 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:19:48,668] Trial 339 pruned. Trial was pruned at iteration 46.\n",
      "[I 2025-02-10 18:19:50,347] Trial 340 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:19:52,155] Trial 341 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:20:04,364] Trial 342 pruned. Trial was pruned at iteration 49.\n",
      "[I 2025-02-10 18:20:05,880] Trial 343 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:20:07,566] Trial 344 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:20:09,299] Trial 345 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:20:10,891] Trial 346 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:20:15,921] Trial 347 pruned. Trial was pruned at iteration 15.\n",
      "[I 2025-02-10 18:20:17,520] Trial 348 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:20:19,176] Trial 349 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:20:36,085] Trial 350 pruned. Trial was pruned at iteration 66.\n",
      "[I 2025-02-10 18:20:37,645] Trial 351 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:20:39,281] Trial 352 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:20:51,920] Trial 353 pruned. Trial was pruned at iteration 46.\n",
      "[I 2025-02-10 18:22:09,549] Trial 354 finished with value: 38.87162553462412 and parameters: {'bagging_fraction': 0.9780930785565459, 'bagging_freq': 5, 'feature_fraction': 0.8556426245335559, 'colsample_bytree': 0.31198557362738505, 'learning_rate': 0.04748156996966733, 'max_bin': 69779, 'max_depth': 665, 'min_samples_leaf ': 24, 'num_leaves': 148, 'lambda_l1': 0.0021556304294933115, 'lambda_l2': 0.05627364738597358, 'subsample': 0.23525313033189474}. Best is trial 354 with value: 38.87162553462412.\n",
      "[I 2025-02-10 18:22:10,999] Trial 355 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:22:12,764] Trial 356 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:22:25,364] Trial 357 pruned. Trial was pruned at iteration 49.\n",
      "[I 2025-02-10 18:22:26,946] Trial 358 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:22:36,133] Trial 359 pruned. Trial was pruned at iteration 36.\n",
      "[I 2025-02-10 18:22:37,742] Trial 360 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:22:39,233] Trial 361 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:22:49,726] Trial 362 pruned. Trial was pruned at iteration 38.\n",
      "[I 2025-02-10 18:22:51,410] Trial 363 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:22:53,080] Trial 364 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:22:54,772] Trial 365 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:22:56,555] Trial 366 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:22:58,122] Trial 367 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:22:59,818] Trial 368 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:24:02,982] Trial 369 finished with value: 38.872493166309056 and parameters: {'bagging_fraction': 0.9899988984658517, 'bagging_freq': 5, 'feature_fraction': 0.824422341138175, 'colsample_bytree': 0.2998628306728793, 'learning_rate': 0.049758544767530145, 'max_bin': 88138, 'max_depth': 621, 'min_samples_leaf ': 21, 'num_leaves': 133, 'lambda_l1': 0.032802319751152484, 'lambda_l2': 0.38552104148375654, 'subsample': 0.2395574856536135}. Best is trial 354 with value: 38.87162553462412.\n",
      "[I 2025-02-10 18:24:04,599] Trial 370 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:24:14,011] Trial 371 pruned. Trial was pruned at iteration 37.\n",
      "[I 2025-02-10 18:24:15,691] Trial 372 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:24:23,904] Trial 373 pruned. Trial was pruned at iteration 27.\n",
      "[I 2025-02-10 18:24:25,538] Trial 374 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:24:27,232] Trial 375 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:24:28,934] Trial 376 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:24:30,516] Trial 377 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:24:32,087] Trial 378 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:24:33,680] Trial 379 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:24:35,355] Trial 380 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:24:37,077] Trial 381 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:24:51,428] Trial 382 pruned. Trial was pruned at iteration 65.\n",
      "[I 2025-02-10 18:24:52,990] Trial 383 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:24:54,666] Trial 384 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:24:56,314] Trial 385 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:25:07,103] Trial 386 pruned. Trial was pruned at iteration 41.\n",
      "[I 2025-02-10 18:25:08,841] Trial 387 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:25:10,498] Trial 388 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:25:21,405] Trial 389 pruned. Trial was pruned at iteration 47.\n",
      "[I 2025-02-10 18:25:35,919] Trial 390 pruned. Trial was pruned at iteration 58.\n",
      "[I 2025-02-10 18:25:37,558] Trial 391 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:25:39,183] Trial 392 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:25:42,207] Trial 393 pruned. Trial was pruned at iteration 8.\n",
      "[I 2025-02-10 18:25:43,824] Trial 394 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:25:45,479] Trial 395 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:25:47,130] Trial 396 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:25:49,319] Trial 397 pruned. Trial was pruned at iteration 2.\n",
      "[I 2025-02-10 18:25:51,043] Trial 398 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:25:52,604] Trial 399 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:25:54,236] Trial 400 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:25:55,973] Trial 401 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:26:04,340] Trial 402 pruned. Trial was pruned at iteration 31.\n",
      "[I 2025-02-10 18:26:06,113] Trial 403 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:26:07,762] Trial 404 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:26:09,470] Trial 405 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:26:11,130] Trial 406 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:26:12,733] Trial 407 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:26:14,355] Trial 408 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:26:15,974] Trial 409 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:26:17,596] Trial 410 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:26:19,201] Trial 411 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:26:35,719] Trial 412 pruned. Trial was pruned at iteration 69.\n",
      "[I 2025-02-10 18:26:37,378] Trial 413 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:27:46,301] Trial 414 finished with value: 38.8723285459223 and parameters: {'bagging_fraction': 0.9908710064629415, 'bagging_freq': 5, 'feature_fraction': 0.8129324203586966, 'colsample_bytree': 0.3023199789330901, 'learning_rate': 0.04894005967670717, 'max_bin': 20881, 'max_depth': 63, 'min_samples_leaf ': 37, 'num_leaves': 150, 'lambda_l1': 0.0033833988286937943, 'lambda_l2': 0.9804433672473624, 'subsample': 0.23369955924810182}. Best is trial 354 with value: 38.87162553462412.\n",
      "[I 2025-02-10 18:27:52,581] Trial 415 pruned. Trial was pruned at iteration 24.\n",
      "[I 2025-02-10 18:27:55,923] Trial 416 pruned. Trial was pruned at iteration 9.\n",
      "[I 2025-02-10 18:27:58,731] Trial 417 pruned. Trial was pruned at iteration 6.\n",
      "[I 2025-02-10 18:28:00,330] Trial 418 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:28:01,978] Trial 419 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:28:09,709] Trial 420 pruned. Trial was pruned at iteration 30.\n",
      "[I 2025-02-10 18:28:11,409] Trial 421 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:28:12,983] Trial 422 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:28:27,177] Trial 423 pruned. Trial was pruned at iteration 75.\n",
      "[I 2025-02-10 18:28:28,787] Trial 424 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:28:30,337] Trial 425 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:28:45,262] Trial 426 pruned. Trial was pruned at iteration 83.\n",
      "[I 2025-02-10 18:28:46,794] Trial 427 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:28:48,331] Trial 428 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:28:49,838] Trial 429 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:28:51,475] Trial 430 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:28:53,022] Trial 431 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:28:54,780] Trial 432 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:28:56,391] Trial 433 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:28:58,109] Trial 434 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:29:09,253] Trial 435 pruned. Trial was pruned at iteration 43.\n",
      "[I 2025-02-10 18:29:11,224] Trial 436 pruned. Trial was pruned at iteration 1.\n",
      "[I 2025-02-10 18:29:12,821] Trial 437 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:29:24,652] Trial 438 pruned. Trial was pruned at iteration 44.\n",
      "[I 2025-02-10 18:29:26,244] Trial 439 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:29:35,588] Trial 440 pruned. Trial was pruned at iteration 40.\n",
      "[I 2025-02-10 18:29:37,375] Trial 441 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:29:38,891] Trial 442 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:30:47,519] Trial 443 finished with value: 38.87254225681799 and parameters: {'bagging_fraction': 0.9904941628637073, 'bagging_freq': 1, 'feature_fraction': 0.8746374141472699, 'colsample_bytree': 0.29909601170682354, 'learning_rate': 0.04785158270252196, 'max_bin': 73869, 'max_depth': 513, 'min_samples_leaf ': 38, 'num_leaves': 153, 'lambda_l1': 0.04190735493261616, 'lambda_l2': 0.12078281989778135, 'subsample': 0.23129657839807116}. Best is trial 354 with value: 38.87162553462412.\n",
      "[I 2025-02-10 18:30:49,075] Trial 444 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:30:50,745] Trial 445 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:30:52,503] Trial 446 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:30:54,237] Trial 447 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:30:55,853] Trial 448 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:31:10,627] Trial 449 pruned. Trial was pruned at iteration 58.\n",
      "[I 2025-02-10 18:31:13,301] Trial 450 pruned. Trial was pruned at iteration 4.\n",
      "[I 2025-02-10 18:31:15,009] Trial 451 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:31:16,658] Trial 452 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:31:18,281] Trial 453 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:31:19,890] Trial 454 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:31:21,516] Trial 455 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:31:23,070] Trial 456 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:31:24,729] Trial 457 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:31:26,338] Trial 458 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:31:27,867] Trial 459 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:31:29,482] Trial 460 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:31:31,113] Trial 461 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:31:32,750] Trial 462 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:31:34,468] Trial 463 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:31:38,220] Trial 464 pruned. Trial was pruned at iteration 9.\n",
      "[I 2025-02-10 18:31:39,896] Trial 465 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:31:41,622] Trial 466 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:31:43,267] Trial 467 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:31:44,929] Trial 468 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:32:55,643] Trial 469 finished with value: 38.872218088840974 and parameters: {'bagging_fraction': 0.991409308432778, 'bagging_freq': 5, 'feature_fraction': 0.8504032865711877, 'colsample_bytree': 0.3117917558193597, 'learning_rate': 0.04989993193279618, 'max_bin': 78453, 'max_depth': 565, 'min_samples_leaf ': 57, 'num_leaves': 139, 'lambda_l1': 0.0004188371555507698, 'lambda_l2': 0.4140604866391664, 'subsample': 0.24340536327813594}. Best is trial 354 with value: 38.87162553462412.\n",
      "[I 2025-02-10 18:32:57,199] Trial 470 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:32:59,528] Trial 471 pruned. Trial was pruned at iteration 3.\n",
      "[I 2025-02-10 18:33:01,177] Trial 472 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:33:02,812] Trial 473 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:33:04,330] Trial 474 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:33:05,962] Trial 475 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:33:07,621] Trial 476 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:33:09,195] Trial 477 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:33:10,888] Trial 478 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:33:12,650] Trial 479 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:33:16,148] Trial 480 pruned. Trial was pruned at iteration 8.\n",
      "[I 2025-02-10 18:33:17,753] Trial 481 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:33:20,152] Trial 482 pruned. Trial was pruned at iteration 3.\n",
      "[I 2025-02-10 18:33:29,349] Trial 483 pruned. Trial was pruned at iteration 32.\n",
      "[I 2025-02-10 18:33:31,028] Trial 484 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:33:32,720] Trial 485 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:33:36,307] Trial 486 pruned. Trial was pruned at iteration 10.\n",
      "[I 2025-02-10 18:33:37,884] Trial 487 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:33:45,374] Trial 488 pruned. Trial was pruned at iteration 26.\n",
      "[I 2025-02-10 18:33:46,991] Trial 489 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:33:48,686] Trial 490 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:34:00,908] Trial 491 pruned. Trial was pruned at iteration 49.\n",
      "[I 2025-02-10 18:34:02,573] Trial 492 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:34:04,145] Trial 493 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:34:05,830] Trial 494 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:34:08,037] Trial 495 pruned. Trial was pruned at iteration 2.\n",
      "[I 2025-02-10 18:34:16,429] Trial 496 pruned. Trial was pruned at iteration 30.\n",
      "[I 2025-02-10 18:34:18,090] Trial 497 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-02-10 18:34:28,074] Trial 498 pruned. Trial was pruned at iteration 34.\n",
      "[I 2025-02-10 18:34:29,786] Trial 499 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================\n",
      "Number of finished trials: 500\n",
      "Best trial: 354\n",
      "Best value (RMSE): 38.87162553462412\n",
      "Best hyperparameters: {'bagging_fraction': 0.9780930785565459, 'bagging_freq': 5, 'feature_fraction': 0.8556426245335559, 'colsample_bytree': 0.31198557362738505, 'learning_rate': 0.04748156996966733, 'max_bin': 69779, 'max_depth': 665, 'min_samples_leaf ': 24, 'num_leaves': 148, 'lambda_l1': 0.0021556304294933115, 'lambda_l2': 0.05627364738597358, 'subsample': 0.23525313033189474}\n"
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "    params = {\n",
    "        'random_state': 42,\n",
    "        'early_stopping_rounds': 20, # the {n}th accuracy on the validation set does not improve, stop training\n",
    "        'verbose': -1,  # -1: Fatal, 0: Warning, 1: Info, 2: Debug\n",
    "        'objective': 'regression',\n",
    "        'metric': 'rmse',\n",
    "\n",
    "        # bagging_fraction is like feature_fraction, but randomly selects data without resampling\n",
    "        # bagging_freq must be non-zero to enable bagging\n",
    "        'bagging_fraction': trial.suggest_float('bagging_fraction', 0.8, 1.0),\n",
    "        'bagging_freq': trial.suggest_int('bagging_freq', 1, 7),\n",
    "\n",
    "        # default = 10.0,  used for the categorical features\n",
    "        # 'cat_l2':  trial.suggest_float('cat_l2', 0.01, 20),\n",
    "\n",
    "        # if set to true, when evaluating node splits LightGBM will check only one randomly-chosen threshold for each feature\n",
    "        # 'extra_trees': trial.suggest_categorical(\"extra_trees\", [True, False]),\n",
    "\n",
    "        # subset of features on each iteration (tree) to select\n",
    "        'feature_fraction': trial.suggest_float('feature_fraction', 0.4, 1.0),\n",
    "        # colsample_bytree is ignored when feature_fraction is set\n",
    "        # 'colsample_bytree': trial.suggest_float('colsample_bytree', 0.25, 0.35),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.05, log=True),\n",
    "\n",
    "        # max number of bins that feature values will be bucketed in\n",
    "        'max_bin': trial.suggest_int('max_bin', 1, 100000),\n",
    "\n",
    "        # <= 0 means no limit. Used to deal with over-fitting when data is small. Tree still grows leaf-wise. \n",
    "        'max_depth': trial.suggest_int('max_depth', -1, 1000),  \n",
    "\n",
    "        # Very important to prevent over-fitting. Setting it to hundreds or thousands is enough for a large dataset.\n",
    "        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 5, 1000),\n",
    "        'min_split_gain': 0.5,\n",
    "        \n",
    "        # 'n_estimators': trial.suggest_int('n_estimators', 10, 15000),\n",
    "        'n_estimators': 200,\n",
    "\n",
    "        # main parameter to control the complexity of the tree model. Should be smaller than 2^max_depth\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 2, 256),\n",
    "\n",
    "        'lambda_l1': trial.suggest_float('lambda_l1', 1e-8, 10.0, log=True),\n",
    "        'lambda_l2': trial.suggest_float('lambda_l2', 1e-8, 1.0, log=True),\n",
    "\n",
    "        # subsample is ignored when bagging_fraction is set\n",
    "        # 'subsample': trial.suggest_float('subsample', 0.2, 0.25),\n",
    "        \n",
    "    }\n",
    "\n",
    "\n",
    "    rmse_list = []\n",
    "    for i, (train_fold, valid_fold) in enumerate(data_splits, 1):\n",
    "\n",
    "        train_data = lgb.Dataset(train_fold[feature_list], label=train_fold[target])\n",
    "        valid_data = lgb.Dataset(valid_fold[feature_list], label=valid_fold[target], reference=train_data)\n",
    "      \n",
    "        model = lgb.train(\n",
    "            params=params,\n",
    "            train_set=train_data,\n",
    "            valid_sets=[train_data, valid_data],\n",
    "            valid_names=['train_0', 'valid_0'],\n",
    "            callbacks=[\n",
    "                LightGBMPruningCallback(trial, \"rmse\", valid_name=\"valid_0\"),\n",
    "                lgb.log_evaluation(-1)                   # Suppress training logs\n",
    "            ]\n",
    "        )\n",
    "        y_pred = model.predict(valid_fold[feature_list], num_iteration=model.best_iteration)\n",
    "        rmse = root_mean_squared_error(valid_fold[target], y_pred)\n",
    "        rmse_list.append(rmse)\n",
    "\n",
    "    return np.mean(rmse_list)\n",
    "\n",
    "study = optuna.create_study(\n",
    "        storage=f\"sqlite:///..//optuna//{model_str}db.sqlite3\",\n",
    "        study_name=model_str + datetime.now().strftime(\"%Y-%m-%d_%H-%M\"),\n",
    "        direction=\"minimize\"\n",
    ")\n",
    "study.optimize(objective, n_trials=500)\n",
    "\n",
    "print(\"\\n=========================\")\n",
    "print(\"Number of finished trials:\", len(study.trials))\n",
    "print(\"Best trial:\", study.best_trial.number)\n",
    "print(\"Best value (RMSE):\", study.best_trial.value)\n",
    "print(\"Best hyperparameters:\", study.best_trial.params)\n",
    "best_params = study.best_trial.params\n",
    "best_params[\"random_state\"] = 42\n",
    "best_params[\"verbose\"] = 0\n",
    "best_params[\"metric\"] = \"rmse\"\n",
    "best_params['objective'] = 'regression'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bagging_fraction': 0.9780930785565459,\n",
       " 'bagging_freq': 5,\n",
       " 'feature_fraction': 0.8556426245335559,\n",
       " 'learning_rate': 0.04748156996966733,\n",
       " 'max_bin': 69779,\n",
       " 'max_depth': 665,\n",
       " 'num_leaves': 148,\n",
       " 'lambda_l1': 0.0021556304294933115,\n",
       " 'lambda_l2': 0.05627364738597358,\n",
       " 'random_state': 42,\n",
       " 'verbose': 0,\n",
       " 'objective': 'regression',\n",
       " 'min_samples_leaf': 24}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brand</th>\n",
       "      <th>material</th>\n",
       "      <th>size</th>\n",
       "      <th>compartments</th>\n",
       "      <th>laptop_compartment</th>\n",
       "      <th>is_waterproof</th>\n",
       "      <th>style</th>\n",
       "      <th>color</th>\n",
       "      <th>weight_capacity</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>11.611723</td>\n",
       "      <td>112.15875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>27.078537</td>\n",
       "      <td>68.88056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>16.643760</td>\n",
       "      <td>39.17320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>12.937220</td>\n",
       "      <td>80.60793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>17.749338</td>\n",
       "      <td>86.02312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3994313</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>28.098120</td>\n",
       "      <td>104.74460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3994314</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>17.379531</td>\n",
       "      <td>122.39043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3994315</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>17.037708</td>\n",
       "      <td>148.18470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3994316</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>28.783339</td>\n",
       "      <td>22.32269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3994317</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>23.076169</td>\n",
       "      <td>107.61199</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3994318 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         brand  material  size  compartments  laptop_compartment  \\\n",
       "0            3         0     1             7                  -1   \n",
       "1            3         3     0            10                  -1   \n",
       "2            4         0     0             2                  -1   \n",
       "3            2         1     0             8                  -1   \n",
       "4            0         3     1             1                  -1   \n",
       "...        ...       ...   ...           ...                 ...   \n",
       "3994313      2         3    -1             3                  -1   \n",
       "3994314      1         0     0            10                  -1   \n",
       "3994315      3         3     2            10                  -1   \n",
       "3994316      1         3    -1             2                  -1   \n",
       "3994317      4         2     1             2                  -1   \n",
       "\n",
       "         is_waterproof  style  color  weight_capacity      price  \n",
       "0                   -1      2      0        11.611723  112.15875  \n",
       "1                   -1      1      4        27.078537   68.88056  \n",
       "2                   -1      1      2        16.643760   39.17320  \n",
       "3                   -1      1      4        12.937220   80.60793  \n",
       "4                   -1      1      4        17.749338   86.02312  \n",
       "...                ...    ...    ...              ...        ...  \n",
       "3994313             -1      1      5        28.098120  104.74460  \n",
       "3994314             -1      2      5        17.379531  122.39043  \n",
       "3994315             -1      0      2        17.037708  148.18470  \n",
       "3994316             -1      0      1        28.783339   22.32269  \n",
       "3994317             -1      0      5        23.076169  107.61199  \n",
       "\n",
       "[3994318 rows x 10 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_encoded, test_df_encoded = preprocess_weight_capacity(train_df, test_df)\n",
    "\n",
    "train_df_encoded, test_df_encoded, encoded_cols = target_encoding(\n",
    "    train_df=train_df_encoded,\n",
    "    cat_cols=cat_cols,\n",
    "    test_df=test_df_encoded, \n",
    "    target=target,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = lgb.Dataset(train_df_encoded[feature_list], label=train_df_encoded[target])\n",
    "model = lgb.train(params=best_params, train_set=train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del best_params['eval_metric']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# best_params['min_samples_leaf'] = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantiles = [0.1, 0.9]  # Lower and upper bounds\n",
    "quantile_models = {}\n",
    "\n",
    "for q in quantiles:\n",
    "    quantile_params = best_params.copy()\n",
    "    quantile_params.update({\n",
    "        \"objective\": \"quantile\",\n",
    "        \"alpha\": q\n",
    "    })\n",
    "\n",
    "    train_data = lgb.Dataset(train_df_encoded[feature_list], label=train_df_encoded[target]) \n",
    "    quantile_models[q] = lgb.train(params=quantile_params, train_set=train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred: 81.86, Lower: 28.83, Upper: 134.78\n",
      "Pred: 82.75, Lower: 29.19, Upper: 135.18\n",
      "Pred: 82.41, Lower: 27.90, Upper: 136.48\n",
      "Pred: 80.79, Lower: 29.13, Upper: 134.30\n",
      "Pred: 78.58, Lower: 25.82, Upper: 133.87\n"
     ]
    }
   ],
   "source": [
    "X_test = test_df_encoded[feature_list]\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "y_lower = quantile_models[0.1].predict(X_test)\n",
    "y_upper = quantile_models[0.9].predict(X_test)\n",
    "\n",
    "# Print sample output\n",
    "for i in range(5):\n",
    "    print(f\"Pred: {y_pred[i]:.2f}, Lower: {y_lower[i]:.2f}, Upper: {y_upper[i]:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_pred</th>\n",
       "      <th>y_lower</th>\n",
       "      <th>y_upper</th>\n",
       "      <th>midpoint</th>\n",
       "      <th>quantile_width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>164459</th>\n",
       "      <td>40.794629</td>\n",
       "      <td>20.188331</td>\n",
       "      <td>96.596631</td>\n",
       "      <td>58.392481</td>\n",
       "      <td>76.408300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127511</th>\n",
       "      <td>45.020558</td>\n",
       "      <td>20.432004</td>\n",
       "      <td>97.763583</td>\n",
       "      <td>59.097794</td>\n",
       "      <td>77.331578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187325</th>\n",
       "      <td>40.921457</td>\n",
       "      <td>20.848764</td>\n",
       "      <td>103.836507</td>\n",
       "      <td>62.342635</td>\n",
       "      <td>82.987744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167616</th>\n",
       "      <td>40.962314</td>\n",
       "      <td>21.078594</td>\n",
       "      <td>106.160919</td>\n",
       "      <td>63.619756</td>\n",
       "      <td>85.082325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106540</th>\n",
       "      <td>52.789885</td>\n",
       "      <td>20.620531</td>\n",
       "      <td>105.713287</td>\n",
       "      <td>63.166909</td>\n",
       "      <td>85.092755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121583</th>\n",
       "      <td>91.360337</td>\n",
       "      <td>17.698150</td>\n",
       "      <td>142.676008</td>\n",
       "      <td>80.187079</td>\n",
       "      <td>124.977859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36044</th>\n",
       "      <td>113.610736</td>\n",
       "      <td>21.983540</td>\n",
       "      <td>147.442600</td>\n",
       "      <td>84.713070</td>\n",
       "      <td>125.459060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44639</th>\n",
       "      <td>86.131928</td>\n",
       "      <td>17.879055</td>\n",
       "      <td>143.760218</td>\n",
       "      <td>80.819636</td>\n",
       "      <td>125.881162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17915</th>\n",
       "      <td>105.529693</td>\n",
       "      <td>21.843741</td>\n",
       "      <td>148.751697</td>\n",
       "      <td>85.297719</td>\n",
       "      <td>126.907957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79908</th>\n",
       "      <td>60.727836</td>\n",
       "      <td>16.545473</td>\n",
       "      <td>144.282239</td>\n",
       "      <td>80.413856</td>\n",
       "      <td>127.736765</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            y_pred    y_lower     y_upper   midpoint  quantile_width\n",
       "164459   40.794629  20.188331   96.596631  58.392481       76.408300\n",
       "127511   45.020558  20.432004   97.763583  59.097794       77.331578\n",
       "187325   40.921457  20.848764  103.836507  62.342635       82.987744\n",
       "167616   40.962314  21.078594  106.160919  63.619756       85.082325\n",
       "106540   52.789885  20.620531  105.713287  63.166909       85.092755\n",
       "...            ...        ...         ...        ...             ...\n",
       "121583   91.360337  17.698150  142.676008  80.187079      124.977859\n",
       "36044   113.610736  21.983540  147.442600  84.713070      125.459060\n",
       "44639    86.131928  17.879055  143.760218  80.819636      125.881162\n",
       "17915   105.529693  21.843741  148.751697  85.297719      126.907957\n",
       "79908    60.727836  16.545473  144.282239  80.413856      127.736765\n",
       "\n",
       "[200000 rows x 5 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quantile_width = y_upper - y_lower\n",
    "\n",
    "results_df = pd.DataFrame({\n",
    "    \"y_pred\": y_pred,\n",
    "    \"y_lower\": y_lower,\n",
    "    \"y_upper\": y_upper,\n",
    "    \"midpoint\": (y_upper + y_lower) / 2,\n",
    "    \"quantile_width\": quantile_width\n",
    "})\n",
    "\n",
    "results_df.sort_values(by=\"quantile_width\", ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='y_lower', ylabel='Count'>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(results_df.y_lower)\n",
    "sns.histplot(results_df.y_upper)\n",
    "sns.histplot(results_df.y_pred, label='y_pred')\n",
    "sns.histplot(results_df.midpoint, label='midpoint')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(81.3754467345461, 2.1841610293828015)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.y_pred.mean(), results_df.y_pred.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(81.48431038633113, 0.9113560742149481)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.midpoint.mean(), results_df.midpoint.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving to: ..//submissions//lgb_2025-02-10_19-59.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>300000</td>\n",
       "      <td>81.805773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>300001</td>\n",
       "      <td>82.185220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>300002</td>\n",
       "      <td>82.193602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>300003</td>\n",
       "      <td>81.716690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>300004</td>\n",
       "      <td>79.843914</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id      Price\n",
       "0  300000  81.805773\n",
       "1  300001  82.185220\n",
       "2  300002  82.193602\n",
       "3  300003  81.716690\n",
       "4  300004  79.843914"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit_path = f'..//submissions//' + model_str + datetime.now().strftime(\"%Y-%m-%d_%H-%M\") + \".csv\"\n",
    "print(\"Saving to:\", submit_path)\n",
    "# y_pred.to_csv(\"submission.csv\", index=False)\n",
    "\n",
    "submit_df = test_df[['id']].copy()\n",
    "submit_df['Price'] = results_df.midpoint\n",
    "# submit_df['Price'] = np.mean(predictions, axis=0) # Average the predictions\n",
    "submit_df.to_csv(submit_path, index=False)\n",
    "# print(f\"Submission file saved as submission.csv\\n\")\n",
    "submit_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a weight based on quantile width (higher width → more weight on upper)\n",
    "weight = np.clip(quantile_width / quantile_width.max(), 0, 1)\n",
    "\n",
    "# Adjust prediction using a blend of y_pred and y_upper\n",
    "results_df[\"adjusted_pred\"] = (1 - weight) * y_pred + weight * y_upper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.82942038, 0.82979378, 0.85001023, ..., 0.84304221, 0.8390487 ,\n",
       "       0.82126352])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_pred</th>\n",
       "      <th>y_lower</th>\n",
       "      <th>y_upper</th>\n",
       "      <th>midpoint</th>\n",
       "      <th>quantile_width</th>\n",
       "      <th>adjusted_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>81.855731</td>\n",
       "      <td>28.832035</td>\n",
       "      <td>134.779511</td>\n",
       "      <td>81.805773</td>\n",
       "      <td>105.947476</td>\n",
       "      <td>125.751793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>82.752197</td>\n",
       "      <td>29.187633</td>\n",
       "      <td>135.182807</td>\n",
       "      <td>82.185220</td>\n",
       "      <td>105.995174</td>\n",
       "      <td>126.258791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>82.413418</td>\n",
       "      <td>27.904823</td>\n",
       "      <td>136.482380</td>\n",
       "      <td>82.193602</td>\n",
       "      <td>108.577557</td>\n",
       "      <td>128.372589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>80.793437</td>\n",
       "      <td>29.129325</td>\n",
       "      <td>134.304056</td>\n",
       "      <td>81.716690</td>\n",
       "      <td>105.174730</td>\n",
       "      <td>124.852521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>78.579239</td>\n",
       "      <td>25.821316</td>\n",
       "      <td>133.866512</td>\n",
       "      <td>79.843914</td>\n",
       "      <td>108.045196</td>\n",
       "      <td>125.343569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199995</th>\n",
       "      <td>79.979490</td>\n",
       "      <td>28.106667</td>\n",
       "      <td>133.651492</td>\n",
       "      <td>80.879079</td>\n",
       "      <td>105.544825</td>\n",
       "      <td>124.326957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199996</th>\n",
       "      <td>78.953991</td>\n",
       "      <td>26.177099</td>\n",
       "      <td>134.103670</td>\n",
       "      <td>80.140385</td>\n",
       "      <td>107.926571</td>\n",
       "      <td>125.550723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199997</th>\n",
       "      <td>82.737569</td>\n",
       "      <td>28.362203</td>\n",
       "      <td>136.049688</td>\n",
       "      <td>82.205946</td>\n",
       "      <td>107.687485</td>\n",
       "      <td>127.681936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199998</th>\n",
       "      <td>81.791271</td>\n",
       "      <td>28.526647</td>\n",
       "      <td>135.704015</td>\n",
       "      <td>82.115331</td>\n",
       "      <td>107.177367</td>\n",
       "      <td>127.026689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199999</th>\n",
       "      <td>81.277967</td>\n",
       "      <td>29.187130</td>\n",
       "      <td>134.092675</td>\n",
       "      <td>81.639903</td>\n",
       "      <td>104.905545</td>\n",
       "      <td>124.652760</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           y_pred    y_lower     y_upper   midpoint  quantile_width  \\\n",
       "0       81.855731  28.832035  134.779511  81.805773      105.947476   \n",
       "1       82.752197  29.187633  135.182807  82.185220      105.995174   \n",
       "2       82.413418  27.904823  136.482380  82.193602      108.577557   \n",
       "3       80.793437  29.129325  134.304056  81.716690      105.174730   \n",
       "4       78.579239  25.821316  133.866512  79.843914      108.045196   \n",
       "...           ...        ...         ...        ...             ...   \n",
       "199995  79.979490  28.106667  133.651492  80.879079      105.544825   \n",
       "199996  78.953991  26.177099  134.103670  80.140385      107.926571   \n",
       "199997  82.737569  28.362203  136.049688  82.205946      107.687485   \n",
       "199998  81.791271  28.526647  135.704015  82.115331      107.177367   \n",
       "199999  81.277967  29.187130  134.092675  81.639903      104.905545   \n",
       "\n",
       "        adjusted_pred  \n",
       "0          125.751793  \n",
       "1          126.258791  \n",
       "2          128.372589  \n",
       "3          124.852521  \n",
       "4          125.343569  \n",
       "...               ...  \n",
       "199995     124.326957  \n",
       "199996     125.550723  \n",
       "199997     127.681936  \n",
       "199998     127.026689  \n",
       "199999     124.652760  \n",
       "\n",
       "[200000 rows x 6 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_pred</th>\n",
       "      <th>y_lower</th>\n",
       "      <th>y_upper</th>\n",
       "      <th>quantile_width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [y_pred, y_lower, y_upper, quantile_width]\n",
       "Index: []"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df[results_df.y_pred != results_df.y_upper]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, (train_fold, valid_fold) in enumerate(data_splits, 1):\n",
    "\n",
    "#     train_data = lgb.Dataset(train_fold[feature_list], label=train_fold[target])\n",
    "#     valid_data = lgb.Dataset(valid_fold[feature_list], label=valid_fold[target], reference=train_data)\n",
    "    \n",
    "#     model = lgb.train(\n",
    "#         params=best_params,\n",
    "#         train_set=train_data,\n",
    "#         valid_sets=[train_data, valid_data],\n",
    "#         valid_names=['train_0', 'valid_0'],\n",
    "#         callbacks=[\n",
    "#             LightGBMPruningCallback(trial, \"rmse\", valid_name=\"valid_0\"),\n",
    "#             lgb.log_evaluation(-1)                   # Suppress training logs\n",
    "#         ]\n",
    "#     )\n",
    "#     y_pred = model.predict(valid_fold[feature_list], num_iteration=model.best_iteration)\n",
    "#     rmse = root_mean_squared_error(valid_fold[target], y_pred)\n",
    "#     rmse_list.append(rmse)\n",
    "\n",
    "# return np.mean(rmse_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
